{
    "id": "1",
    "name": "Reflective journal Entities",
    "nodeType": "section",
    "text": "week 1 – introduction to itic, pmp and project \nassigned \ndescribe i attended business meetings which are the introductory session \nfrom itic. there, i learn about company structure, company \npolicies, and organisation chart. i also able to get all the \nresources such as logins from itic. most importantly, i had a \nglimpse at the project assigned to me (in the form of a poster). \nmy understanding over the project remains on the methodology \nstage.  \ninterpret regarding the company organisation structure, organisation \nchart and policies, i already discussed in previous section. to \nre-instate, the organisation structure is discussed in the section \n6 of “organizational hierarchy chart”, where the company’s \nchart is within same section of “main offices”. as a mature \nstudent and a commerce graduate, i do not have any issue in \nunderstanding this part of the information.  \nwhen it comes to the ai-enabled essay marking tool \ndevelopment project, i felt frustrated at first since i cannot \nconnect the dot between the knowledge from my degree \ntowards my project assigned at that moment. i theorised i would \nhave to work on some dataset etl and sql as a junior staff of \nthe department.  the duties i assume would be on data \ncleansing or big sql queries.  \nevaluate it is discussed in the section “my assigned project – ai-enabled \nessay-marking tool development”. i learnt about how a small-\nmedium it company is functioned. in any companies, policies \nare critical towards the usage manner as well as security of \ncompany’s information. and from commercial perspective, \ninstead of opening up new department for subsidiary \ncompanies, the human resources are pooled and it is observed \nsubstantial cost saving can be achieved through this.  \nafter weeks of training and research, it is observed that my \ninitial hypothesis is off-track. it is not efficient since i do not have \nsoftware development background where i must spend time on \nclarification and reinforcement. my expertise from my previous \njobs lies in project management and business intelligence.  \n \n20 \nit is suggested that the connection to my master degree is more \ndistinguishable at the moment. i can understand from a software \ndevelopment perspective how the machine learning engine is \napplied from the model architecture provided.  i reckon the \napproaches of itic in managing interns are effective.  \nplan \nthe biggest takeaway for me in this week is how machine \nlearning is applied towards software development. in previous \nmachine courses we focus on understanding ml models to \ncapture the trend and model tuning, while ignoring introduction \nof ml real-life application.  \nweek 2 – determining project scope, tasks, and \nrole assigned. \ndescribe i received a detail project plan regarding the tasks, and i must \ncomplete a capabilities matrix to understand my ability and \nwhere my interest lies. i’ll also gain access towards confluence \npage for documentation, tableau training and certified scrum \nmaster (csm) courses. \ninterpret regarding the tasks from project, i learn about the project i am \ngoing to work on and did a skill assessment over myself to \nunderstand where my capabilities and interests lies. from the \nresult of the matrix, it is suggested i’ll be working on either \nfeature engineering or machine learning developer.  \nevaluate this is an efficient and effective week where i learn what are the \navailable options working in the it industry, and the matrix itself \nis easily understand and able to provide identification towards \nmy general skillsets learnt from this master’s degree. i felt more \non-track for my internship work. \nwhen i look back, i reckon that there is a huge gap for me to \nintegrate the knowledge of machine learning to product \ndevelopment, and gap between project development from \nnormal and it project. as a mature student, i worked in multiple \nproject management over marketing campaigns and \nadministration campaigns, while the scope, the resources \nhandling techniques and length of projects are completely \ndifferent from what i have experienced from my previous jobs.  \nplan \nto better perform as a machine learning developer, i reckon i \nwould have to reinforce and consolidate my knowledge, as well \nas to present some of the outcomes for the company. i initiated \nself-learning course over kaggle regarding neuron network and \ncompleted them in the same week.  \n \n \n21 \nweek 3 – project conceptualisation & competitor \nanalysis \ndescribe \ni attended business meeting in conceptualising the commercial \nproduct of essay-marking tools. the structure, solutions \nconcepts, key solution components, proposed framework and \nportal are all discussed.  \ninterpret due to my lack of understanding over the market trend of essay \nmarking tool in general, it is decided that i have to work on a \nbusiness report and presentation over the popular commercial \ntools. \nevaluate in this stage, i reckon i made a good call in terms of self-\nlearning neuron network model. it is an effective and efficient \napproach where i am able to have understanding over the \nproposed framework, which is a deep learning model. i also able \nto connect to my knowledge from ml course regarding the \nutilisation of nltk library for nlp model and tensorflow tool for \ndeep learning model. this would greatly reduces the timespan \non understanding the code and popular trend.   \na piece of puzzle that i could not comprehend was the \nconstruction of product. it is lucky that i was assigned to work on \nthe commercial analysis of the essay-marking tools. this is a \nrewarding task for me as i can effectively understand how an \nessay-marking tools (engine) is used in different commercial \nproduct, like turnitin, what are the common algorithms used in \nnlp models, how the users and data interact and what sort of \noutcome are expected. a business report and presentation for \nthe team including a comparison table were made. \nplan \nleveraging on the market intelligence i gained, i decided to \nmove forward with working on code analysis in coming tasks, \nwith focus on leveraging on the knowledge i learnt from previous \nml courses, such as clustering and neuron network.  this really \nimprove my capability over nlp model and deep learning, and \nintegrating them as a whole.    \n \n \n \n \n \n22 \nweek 4 – training (1) on nlp model trends and \napplications \ndescribe given the complexity of the project outcome, itic decided to \nextend this week as a training period for us to reinforce our \nunderstanding over nlp model.  \ninterpret it has been a difficult yet rewarding experience. i have to work \non summarizing the essay scoring note provided by the \ncompany and develop a set of presentation to showcase our \nunderstanding over nlp models.  \nit is so effective that within a short period of 1 week, i can \nunderstand current trend in nlp model and public dataset \navailable. using vectorization as a first step of nlp, review in-\ndepth some of the nlp topics such as vectorization method like \ntf-idf, word2vec, cbow. i learnt most of the vectorization \ntechniques from my degree, while it is seldom discussed about \nhow to capture the semantics of the world and model tuning. \nthis provide me a great opportunity to learn, and i hope to put \nthese skills into developing the machine learning model. \nit is identified that the main trends are to predict the next word \nusing probability as well as predict the current word.  some data \naugmentation methods such as essaygans and conventional \ngans are introduced.  \nalso, i am able to learn the commonly used evaluation metrics \nto nlp learning model – qwk (quadrated weighted kappa).  \nevaluate this week is rewarding, i made aware to understand that the \ndifficulty of the project lies in several areas, one of them is \nunderstanding the semantics as well as grading the article itself, \nand essaygans do not follow the format of a conventional \ngans. it is worth notice to put into use of identification towards \nfake essay, especially given the rise of ai-generated content like \nchatgpt. the other important take-away is that deep learning \ntuning is so complicated which required sophisticated model \nunderstanding. \nplan \nthis has been an incredible crash course over the nlp model, \nand i am thankful for this week. i also decided to further my \nknowledge by re-construction the nlp models done in previous \ncourses as well as those on open sources like kaggle to confirm \nmy personal understanding.   \n \n \n23 \n \nweek 5 – code analysis over bert model \ndescribe given recent nlp model development, itic was more inclined \nto choose the model of deep learning. i was assigned a task to \nanalyse a chosen academic article about bert model. \ninterpret understanding the job responsibility is to work on research and \nrecommendation on best model, code analysis over bert \nmodel is assigned. i downloaded the dataset from open source \nand tried to work with replicating data pre-process. once i run \nthe code, i started to get error message all along. i therefore \nspend some time in configuring and eventually found out the \nopen-source codes are written in python 2.8 hence giving out \nmuch of the error. eventually, with the help of academic essay, i \ncan product a code analysis detailing the usage of codes. a \nbusiness presentation was done and result in compliment from \nsteven. \nevaluate i have never work on code analysis before and i am unaware of \nsome best practice in this analysis, this affect the time span for \nme in preparing the code analysis report. an expected output \nlayout is presented in graph 11.  \n \ngraph 11: code analysis required output * \nstill, some takeaways from this week task are getting an in-\ndepth understanding over how bert model is utilised in essay-\nmarking tools. an approach of “meta-trained bert with in-\ncontext tuning” is discussed. the model can be divided into 3 \nmain layers.2 \n \n24 \n1) lm fine-tuning set-up: pre-trained bert model will be act \nas the base language model for automated scoring. the \ngoal of the set -up is to construct an input that include \nsemantics to the shared bert essay-scoring model and \nable to associate it with each specific item. 4 factors will \nbe included in the model. inputs has 3 initial factors, which \nare passage “pi”, question “qi”, and student response text \n“xtarget”. once inputted into the bert model, [sep] as \nthe separator j token in bert model’s vocabulary, will be \nadded between these parts to help the model differentiate \ninput text segments with different purposes. the passage \ntext will be encoded and [cls] embedding vector as the \ninput to bert model.  \n2) meta-training bert with in-context training: in-context \nlearning of a shared bert automated scoring model \nacross all items. in this session, in-context data, the \nresponse-score pair will be added into the training set.  \n \ngraph 12: illustration of meta-trained bert with in-context tuning2 \n \nplan \ni decided to work on code analysis as major tasks in this project \nto polish my skills in model development, and to fulfill my \npersonal aspiration as a machine learning developer. \n \n \n \n2  \n \n25 \nweek 6 – training (2) over current market nlp \nmodels: rnn, lstm, elmo, bert \ndescribe a second part of training focusing on the given knowledge of \nbert are consolidated and code analysis provided insightful \nfeedbacks, itic decided to develop own essay-marking tool, \nleveraging on the state-of-the-art bert model. the current \npopular usage of nlp models is discussed.  \ninterpret nlp tasks are generalised and discussed. those tasks include \npre-train stage, model tuning, and transformers phase. graph13 \nis an illustration of nlp tasks.  \n \n \n \ngraph 13: nlp tasks * \n \nall popular models with in-depth tuning knowledge are \ndiscussed in this section, including rnn, lstm, elmo, bert, \nand in-depth bert model tuning. it is worth mentioning the \ninitial thoughts on using chatgpt is rejected since after careful \nresearch it is more of a decoder then an encoder. the nature of \nour project is understanding the semantics, which required \nencoder transformer.  \n \nevaluate this week i reckon is the biggest and best training i receive so \nfar in the course of this internship and throughout this master’s \ndegree.  \nit is learnt that the model of rnn, lstm has their own \nlimitations, including the nature of word embedding that \nassigning semantics does not take into consideration of same \nword in different context (shortcoming of nltk library). rnn by \nnature is non-bidirectional and will affect accuracy.  the \nslowness in training is worst in rnn, and worst in lstm. other \nfunctional issues such as exploding gradients and dead relu \nare some issues to address by lstm. graph 14 is a simple \nillustration of rnn and lstm with one layer. this is shown that \n \n26 \nlstm although tackle the issues of rnn, while at the same time \ntraining data become more expensive. \n \ngraph 14: rnn & lstm one-layer illustration * \nalso, it is educated that the rnn does not have the ability to \nconduct pre-training which would affect accuracy. elmo is \nintroduced to train the data input separately, with left-to-right \nand right-to-left leveraging on lstms, then apply them as pre-\ntrained embeddings. in this way, we could resolve the issue of \nlacking context –awareness in rnn model by including elmo \nfrom embedding stage and achieve higher baseline accuracy in \ngeneral. graph15 is the illustration of elmo layer. \n \n \n \n \n \n \ngraph 15: elmo illustration * \nwhile ultimately, the solution seems to be bert. by nature, \nbert is less expensive to train since it is bi-directional, and it \nenables pre-training as well which tackle all the issues of the \ncurrent model. \n \n27 \n \ngraph 16: bert illustration * \n \nplan \nwith all work on the code development next time, and moving \nforward in code development, there may be a need to work on \nthe pre-determination of dataset as well since training data is \none of the essential parts of machine learning. \nweek 7 – determining model for essay marking (1) \ndescribe i attended a face-to-face meeting with stephen, masoud and \nother intern student in itic office. it is announced that our \nproject is mature to proceed to implementation stage. \ninterpret during the business meeting, it is decided that current tasks of \nessay-marking tool shall be decomposed into 3 main parts, \nwhich are essay-scoring, content summary for marker, and \nquestion generation for student based on what they write. \n \nit is discussed and determined that the first task would likely to \nbase on bert while more testing are required. the second and \nlast tasks are likely to leverage on existing api. it is important \nfor us in this week to research for suitable datasets, try to work \non essaygan to generate dataset with 3000 – 4000 essays \nsample.   \nevaluate it is an important week for this project to enter this \nimplementation stage. it is learnt that instead of treating marking \nas a complicated problem where scoring is an ordinal concept, it \nis easier to treat it as a classification problem. the way of \nthinking outside the box is great takeaway for me. i decided to \n \n28 \nwork on dataset determination. it is reported that 33 datasets \nare found via google new service of dataset search. more \ncompatible datasets with our model would be including toefl, \nielts, asap dataset and corpus dataset  \nplan \ni decided to report over the useful tool of google data search \nand available open dataset.   \nweek 8 – determining model for essay marking (2) \ndescribe after the review meeting, itic decided that start off with \nreplicating suitable bert model over simple text classification \ntask, and will proceed to move forward with customisation of \ntask over dataset.  \ninterpret i attended business meetings where it is decided that a series of \nbert code are to be replicated tested based on available bbc \ndataset. bbc datasets are a dataset with news from bbc and \ncategorized into 5 different categories, namely politics, \nbusiness, entertainment, sports and tech. dataset of first 5 rows \nof data is presented below in graph 17. since the nature of \nclassifier is equivalent, it is determined if the test result is \nsatisfactory, it is likely the model will be customised over our \nessay-marking task.  \ngraph 17: bbc dataset (first 5 rows) \n \na replication of model is conducted. it is reported that the bert \nmodel would be bert base, where it consists of 12 layers of \ntransformer encoder, 12 attention heads, 768 hidden size and \n110 parameters. the input is the content of bbc news text with \ncurrent categorization labelled, the output expected is the \ncategory they belong to.  \nevaluate it is again a rewarding week. i have to replication over the bert \nmodel on bbc dataset. the machine learning modelling skill i \nlearnt from current course will be put into use in real-world \nscenario. data exploration, manipulation and cleaning \ntechniques are also applied. also, the pytorch language is new \nso some time is spent in understanding the new language. \nleveraging on pytorch and colab notebook, a replication over \nbert base is applied towards bbc dataset. the model \nreported a 98% accuracy over the bbc dataset classification \ntask. it is determined that bert base classifier would be the \n \n29 \nmodel. below graph 18 is the initial result of the machine \nlearning model. \n \n \n \ngraph 18: bert model over bbc dataset \nthis is a rewarding week, not only i am able to learn about the \nuse of tensorflow and pytorch in training bert model, but it also \nprovides me exposure in current practice in developing a \nmachine learning model. instead of working from scratch, it is \nmore efficient to leverage on existing model, customise and \napply customisation to another dataset. \nplan \ni decided to report over meeting about the high accuracy and \nrecommended bert base model as our essay-marking model. \nnext stage is likely to be in dataset determination.  \nweek 9 – customisation of dataset & model \ntraining \ndescribe it is crucial to apply the bert base model towards a determined \ndataset and work on its classifier task to move the project \nforward. it is determined that asap dataset shall be utilised and \nwe shall investigate and start to work with customisation of \ncodes.  \ninterpret this is a challenging task to customise over asap dataset. the \noriginal dataset is a set of 28 x 12978 columns, many of the \ndata in columns are missing. \n \nit is decided that i shall apply the knowledge i gain from current \ncourse regarding machine learning to try and customise the \nmodel. first, i perform exploratory data analysis. it is found that \nthere were 8 different questions with different mark distribution. i \nthen make the call to remove the question 7 and 8 with \ncompletely different marking distribution. then i tried to conduct \n \n30 \nmachine learning techniques using bert base. below is the \ninitial result of the machine learning model.  \n \n \n \n \ngraph 19: bert model over bbc dataset \nfrom graph 18, it is reflected that there is serious overfitting \nissue with the current model. overfitting happens when the \nmodel is too generalised and fit the training data too much.it is \nobserved that there is serious overfitting issue and more data \nanalysis shall be conducted to understand how to improve \nthrough data handling and data manipulation.  \n \nevaluate performing exploratory data analysis (eda) over the asap \ndata is an interesting experience since text data is not easy to \nvisualise. it is learnt that i can calculate the tf-idf scores and \napply wordcloud tool for understanding the data. words with \nimportance in terms of context and frequency will be presented \nand easy understanding and comparison can be made.  an \nillustration of wordcloud is as below graph 20.  \n \n \n \n \n \n \n \ngraph 20: wordcloud for current training dataset  \n \n \n31 \nplan \nby working on visualisation, it is learnt that data cleaning are \nessential towards tackling the overfitting issue. due to time \nschedule, i decided to report over next business meeting \nregarding the high overfitting issue, and recommend working on \ndata cleaning for the next week. \n \nweek 10 – customisation of dataset & model \ntraining (2) \ndescribe reported in the business meeting that i have great result with \nserious overfitting issues. it is advised that more data cleaning \ntechniques shall be applied in order to ensure the quality of \ndata.   \ninterpret it is decided that text handling technique using nltk library such \nas tokenization, normalisation, applying stop words, etc. shall be \napplied. more of the text handling code will be presented in next \nsection.  \n \n \ngraph 22.1: text before handing \n \ngraph 22.2: text after handling \nthen i tried to apply the same machine learning model towards \nthe cleaned dataset. the result of dataset is as follows.  \n \n \ngraph 23: bert model over bbc dataset \nit is recognised that overfitting problem still exist while the \nmagnitude has been greatly reduced.  \n \n32 \nevaluate it is reviewed that text handling techniques based on nltk library \nis a critical part in ensuring the quality of data for text model. \ncomparing the corpus of bbc dataset and asap dataset, it is \nfound that data has been at the clean stage for bbc dataset, \nwhile not the case for asap dataset.   \nit is also argued that the classification for bbc dataset would \nexpect higher accuracy due to the nature of data. bbc dataset \n(on the left of graph 24) is more data unbiased compare to \nasap dataset (on the right of graph 24), and it consists of \ndifferent words and the tf-idf score itself has great differences \n(illustrated in graph 25).  \ngraph 24: comparison of bbc dataset category distribution and asap dataset \ncategory distribution9 \n \ngraph 25: tf-idf scores for bbc article feature after dimensionality reduction9 \n \n \n9  \n9  \n \n33 \nplan \ni decided to report my findings over next business meeting \nregarding the high overfitting issue. it is recommended that \neither continue with current model with parameter tuning, \nsearching for alternative model for current dataset or alternative \ndataset for training. \nweek 11 – parameter tuning over bert model \ndescribe since some of the initial findings are reported during the \nmeeting, it is decided that parameter tuning shall be performed \nover below learning rate and dropout.  \n• dropout: between 0.5 to 0.6  \n• lr: 1e-5, 1e-6, 1e-7, 2e-5, 2e-6, 2e-7 \ninterpret the cpu is not enough to perform parameter tuning. it is \nresolved to working with gpu for parameter tuning and training \nof model. some of the results will be presented in the next \nsection of working examples. due to gpu limit, selected \nparameters were used and the summary of result is as follows:  \nclasses dropout \nrate \nlearning \nrate \nepoch \ntraining \naccuracy \n13 \n0.5 \n1e-6 \n6 \n0.955 \n20 \n0.5 \n1e-6 \n8 \n0.989 \n20 \n0.6 \n1e-6 \n8 \n0.966 \n20 \n0.5 \n1e-7 \n10 \n0.710 \n20 \n0.5 \n1e-5 \n3 \n0.910 \nit is analysed that 20 classes with dropout rate at 0.5, learning \nrate at 1e-6 and epoch = 8 would be the best model. \nevaluate this is a week with many takeaways. first, it is learnt that \ncapacity of running deep learning model is huge, there would be \nlimited gpu constraint. also, it is discovered that changing \nparameters would result in huge differences in terms of the \naccuracy of model. however, after solving for overfitting issue \nthe underfitting issue happens.  \nplan \ni decided to report over next business meeting where it is \nnecessary to find alternative dataset for training, or should i \nmove forward in resolving the model accuracy issue. \n \n \n34 \nweek 12 – fitting corpus dataset & finding \nalternatives \ndescribe it is assigned that due to lack of fit of current model for the \nasap dataset, it is decided to work on finding alternative and \nrecommend to itic.  \ninterpret it is researched that most of the current essay-scoring model \nare leveraged on asap dataset. a summary of datasets are \nlisted in graph 26.  \n \n \n \n \n \ngraph 26: list of popular datasets in research of essay-marking10 \nit is researched that some alternative models were used. wang \net al. suggested a joint learning approach for multi-scale essay \nrepresentation leveraging on the bert transformer function. \ngraph 26 is an illustration of the model architecture. \n \ngraph 26: illustration of multi-scale essay representation model design11 \n \n10  \n11  \n \n35 \nit is also assigned that i shall look into the incorporation of \ncorpus dataset for the training of model. it is found that multiple \nxml files are required to consolidate in order to get data, while i \nfaced some technicality issue and the files and unable to \nconsolidate the file. \nevaluate it is to stress that itic would like us to work on the alternative on \ncorpus dataset, while due to some interesting discovery over \nresearch, i personally decided to work on code analysis over a \nnew model instead. it is decided that it is more important to \nsolve a problem than to work according to assigned task.  \nplan \ni am going to report my recommendations and findings over the \nmodel analysis and seek for further advise in terms of my \nupcoming assignments. \nweek 13 – wrapping up the internship experience. \ndescribe since this is the last week of my internship experience, we are \nsupposed to work on consolidating all the work and wrap up our \nfindings for smooth hand-over to itic. \ninterpret learning about that smooth transition and data documentation \nare important since everyone have their finite tenure within a \ncompany.  \nevaluate professional working style are learnt, and it is important for my \nfuture development when i will be working within a company. \nplan \ni would like to seek for employment in australia in general. i \nwould start updating my resume with my experience in itic and \ntry to leverage on all the nlp techniques i learnt and transfer \nthem to my new working environment. \n \n \n \n",
    "page": null,
    "goal": "Reflective journal Entities",
    "children": [
        {
            "id": "1.1",
            "name": "week 1",
            "nodeType": "title",
            "text": "week 1",
            "page": null,
            "goal": "week 1",
            "children": []
        },
        {
            "id": "1.2",
            "name": "week 1 –",
            "nodeType": "paragraph",
            "text": "week 1 – introduction to itic, pmp and project \nassigned \ndescribe i attended business meetings which are the introductory session \nfrom itic. there, i learn about company structure, company \npolicies, and organisation chart. i also able to get all the \nresources such as logins from itic. most importantly, i had a \nglimpse at the project assigned to me (in the form of a poster). \nmy understanding over the project remains on the methodology \nstage.  \ninterpret regarding the company organisation structure, organisation \nchart and policies, i already discussed in previous section. to \nre-instate, the organisation structure is discussed in the section \n6 of “organizational hierarchy chart”, where the company’s \nchart is within same section of “main offices”. as a mature \nstudent and a commerce graduate, i do not have any issue in \nunderstanding this part of the information.  \nwhen it comes to the ai-enabled essay marking tool \ndevelopment project, i felt frustrated at first since i cannot \nconnect the dot between the knowledge from my degree \ntowards my project assigned at that moment. i theorised i would \nhave to work on some dataset etl and sql as a junior staff of \nthe department.  the duties i assume would be on data \ncleansing or big sql queries.  \nevaluate it is discussed in the section “my assigned project – ai-enabled \nessay-marking tool development”. i learnt about how a small-\nmedium it company is functioned. in any companies, policies \nare critical towards the usage manner as well as security of \ncompany’s information. and from commercial perspective, \ninstead of opening up new department for subsidiary \ncompanies, the human resources are pooled and it is observed \nsubstantial cost saving can be achieved through this.  \nafter weeks of training and research, it is observed that my \ninitial hypothesis is off-track. it is not efficient since i do not have \nsoftware development background where i must spend time on \nclarification and reinforcement. my expertise from my previous \njobs lies in project management and business intelligence.  \n \n20 \nit is suggested that the connection to my master degree is more \ndistinguishable at the moment. i can understand from a software \ndevelopment perspective how the machine learning engine is \napplied from the model architecture provided.  i reckon the \napproaches of itic in managing interns are effective.  \nplan \nthe biggest takeaway for me in this week is how machine \nlearning is applied towards software development. in previous \nmachine courses we focus on understanding ml models to \ncapture the trend and model tuning, while ignoring introduction \nof ml real-life application.",
            "page": null,
            "goal": "week 1 – introduction to itic, pmp and project \nassigned \ndescribe i attended business meetings which are the introductory session \nfrom itic. there, i learn about company structure, company \npolicies, and organisation chart. i also able to get all the \nresources such as logins from itic. most importantly, i had a \nglimpse at the project assigned to me (in the form of a poster). \nmy understanding over the project remains on the methodology \nstage.  \ninterpret regarding the company organisation structure, organisation \nchart and policies, i already discussed in previous section. to \nre-instate, the organisation structure is discussed in the section \n6 of “organizational hierarchy chart”, where the company’s \nchart is within same section of “main offices”. as a mature \nstudent and a commerce graduate, i do not have any issue in \nunderstanding this part of the information.  \nwhen it comes to the ai-enabled essay marking tool \ndevelopment project, i felt frustrated at first since i cannot \nconnect the dot between the knowledge from my degree \ntowards my project assigned at that moment. i theorised i would \nhave to work on some dataset etl and sql as a junior staff of \nthe department.  the duties i assume would be on data \ncleansing or big sql queries.  \nevaluate it is discussed in the section “my assigned project – ai-enabled \nessay-marking tool development”. i learnt about how a small-\nmedium it company is functioned. in any companies, policies \nare critical towards the usage manner as well as security of \ncompany’s information. and from commercial perspective, \ninstead of opening up new department for subsidiary \ncompanies, the human resources are pooled and it is observed \nsubstantial cost saving can be achieved through this.  \nafter weeks of training and research, it is observed that my \ninitial hypothesis is off-track. it is not efficient since i do not have \nsoftware development background where i must spend time on \nclarification and reinforcement. my expertise from my previous \njobs lies in project management and business intelligence.  \n \n20 \nit is suggested that the connection to my master degree is more \ndistinguishable at the moment. i can understand from a software \ndevelopment perspective how the machine learning engine is \napplied from the model architecture provided.  i reckon the \napproaches of itic in managing interns are effective.  \nplan \nthe biggest takeaway for me in this week is how machine \nlearning is applied towards software development. in previous \nmachine courses we focus on understanding ml models to \ncapture the trend and model tuning, while ignoring introduction \nof ml real-life application.",
            "children": []
        },
        {
            "id": "1.3",
            "name": "week 2",
            "nodeType": "title",
            "text": "week 2",
            "page": null,
            "goal": "week 2",
            "children": []
        },
        {
            "id": "1.4",
            "name": "week 2 –",
            "nodeType": "paragraph",
            "text": "week 2 – determining project scope, tasks, and \nrole assigned. \ndescribe i received a detail project plan regarding the tasks, and i must \ncomplete a capabilities matrix to understand my ability and \nwhere my interest lies. i’ll also gain access towards confluence \npage for documentation, tableau training and certified scrum \nmaster (csm) courses. \ninterpret regarding the tasks from project, i learn about the project i am \ngoing to work on and did a skill assessment over myself to \nunderstand where my capabilities and interests lies. from the \nresult of the matrix, it is suggested i’ll be working on either \nfeature engineering or machine learning developer.  \nevaluate this is an efficient and effective week where i learn what are the \navailable options working in the it industry, and the matrix itself \nis easily understand and able to provide identification towards \nmy general skillsets learnt from this master’s degree. i felt more \non-track for my internship work. \nwhen i look back, i reckon that there is a huge gap for me to \nintegrate the knowledge of machine learning to product \ndevelopment, and gap between project development from \nnormal and it project. as a mature student, i worked in multiple \nproject management over marketing campaigns and \nadministration campaigns, while the scope, the resources \nhandling techniques and length of projects are completely \ndifferent from what i have experienced from my previous jobs.  \nplan \nto better perform as a machine learning developer, i reckon i \nwould have to reinforce and consolidate my knowledge, as well \nas to present some of the outcomes for the company. i initiated \nself-learning course over kaggle regarding neuron network and \ncompleted them in the same week.  \n \n \n21",
            "page": null,
            "goal": "week 2 – determining project scope, tasks, and \nrole assigned. \ndescribe i received a detail project plan regarding the tasks, and i must \ncomplete a capabilities matrix to understand my ability and \nwhere my interest lies. i’ll also gain access towards confluence \npage for documentation, tableau training and certified scrum \nmaster (csm) courses. \ninterpret regarding the tasks from project, i learn about the project i am \ngoing to work on and did a skill assessment over myself to \nunderstand where my capabilities and interests lies. from the \nresult of the matrix, it is suggested i’ll be working on either \nfeature engineering or machine learning developer.  \nevaluate this is an efficient and effective week where i learn what are the \navailable options working in the it industry, and the matrix itself \nis easily understand and able to provide identification towards \nmy general skillsets learnt from this master’s degree. i felt more \non-track for my internship work. \nwhen i look back, i reckon that there is a huge gap for me to \nintegrate the knowledge of machine learning to product \ndevelopment, and gap between project development from \nnormal and it project. as a mature student, i worked in multiple \nproject management over marketing campaigns and \nadministration campaigns, while the scope, the resources \nhandling techniques and length of projects are completely \ndifferent from what i have experienced from my previous jobs.  \nplan \nto better perform as a machine learning developer, i reckon i \nwould have to reinforce and consolidate my knowledge, as well \nas to present some of the outcomes for the company. i initiated \nself-learning course over kaggle regarding neuron network and \ncompleted them in the same week.  \n \n \n21",
            "children": []
        },
        {
            "id": "1.5",
            "name": "week 3",
            "nodeType": "title",
            "text": "week 3",
            "page": null,
            "goal": "week 3",
            "children": []
        },
        {
            "id": "1.6",
            "name": "week 3 –",
            "nodeType": "paragraph",
            "text": "week 3 – project conceptualisation & competitor \nanalysis \ndescribe \ni attended business meeting in conceptualising the commercial \nproduct of essay-marking tools. the structure, solutions \nconcepts, key solution components, proposed framework and \nportal are all discussed.  \ninterpret due to my lack of understanding over the market trend of essay \nmarking tool in general, it is decided that i have to work on a \nbusiness report and presentation over the popular commercial \ntools. \nevaluate in this stage, i reckon i made a good call in terms of self-\nlearning neuron network model. it is an effective and efficient \napproach where i am able to have understanding over the \nproposed framework, which is a deep learning model. i also able \nto connect to my knowledge from ml course regarding the \nutilisation of nltk library for nlp model and tensorflow tool for \ndeep learning model. this would greatly reduces the timespan \non understanding the code and popular trend.   \na piece of puzzle that i could not comprehend was the \nconstruction of product. it is lucky that i was assigned to work on \nthe commercial analysis of the essay-marking tools. this is a \nrewarding task for me as i can effectively understand how an \nessay-marking tools (engine) is used in different commercial \nproduct, like turnitin, what are the common algorithms used in \nnlp models, how the users and data interact and what sort of \noutcome are expected. a business report and presentation for \nthe team including a comparison table were made. \nplan \nleveraging on the market intelligence i gained, i decided to \nmove forward with working on code analysis in coming tasks, \nwith focus on leveraging on the knowledge i learnt from previous \nml courses, such as clustering and neuron network.  this really \nimprove my capability over nlp model and deep learning, and \nintegrating them as a whole.    \n \n \n \n \n \n22",
            "page": null,
            "goal": "week 3 – project conceptualisation & competitor \nanalysis \ndescribe \ni attended business meeting in conceptualising the commercial \nproduct of essay-marking tools. the structure, solutions \nconcepts, key solution components, proposed framework and \nportal are all discussed.  \ninterpret due to my lack of understanding over the market trend of essay \nmarking tool in general, it is decided that i have to work on a \nbusiness report and presentation over the popular commercial \ntools. \nevaluate in this stage, i reckon i made a good call in terms of self-\nlearning neuron network model. it is an effective and efficient \napproach where i am able to have understanding over the \nproposed framework, which is a deep learning model. i also able \nto connect to my knowledge from ml course regarding the \nutilisation of nltk library for nlp model and tensorflow tool for \ndeep learning model. this would greatly reduces the timespan \non understanding the code and popular trend.   \na piece of puzzle that i could not comprehend was the \nconstruction of product. it is lucky that i was assigned to work on \nthe commercial analysis of the essay-marking tools. this is a \nrewarding task for me as i can effectively understand how an \nessay-marking tools (engine) is used in different commercial \nproduct, like turnitin, what are the common algorithms used in \nnlp models, how the users and data interact and what sort of \noutcome are expected. a business report and presentation for \nthe team including a comparison table were made. \nplan \nleveraging on the market intelligence i gained, i decided to \nmove forward with working on code analysis in coming tasks, \nwith focus on leveraging on the knowledge i learnt from previous \nml courses, such as clustering and neuron network.  this really \nimprove my capability over nlp model and deep learning, and \nintegrating them as a whole.    \n \n \n \n \n \n22",
            "children": []
        },
        {
            "id": "1.7",
            "name": "week 4",
            "nodeType": "title",
            "text": "week 4",
            "page": null,
            "goal": "week 4",
            "children": []
        },
        {
            "id": "1.8",
            "name": "week 4 –",
            "nodeType": "paragraph",
            "text": "week 4 – training (1) on nlp model trends and \napplications \ndescribe given the complexity of the project outcome, itic decided to \nextend this week as a training period for us to reinforce our \nunderstanding over nlp model.  \ninterpret it has been a difficult yet rewarding experience. i have to work \non summarizing the essay scoring note provided by the \ncompany and develop a set of presentation to showcase our \nunderstanding over nlp models.  \nit is so effective that within a short period of 1 week, i can \nunderstand current trend in nlp model and public dataset \navailable. using vectorization as a first step of nlp, review in-\ndepth some of the nlp topics such as vectorization method like \ntf-idf, word2vec, cbow. i learnt most of the vectorization \ntechniques from my degree, while it is seldom discussed about \nhow to capture the semantics of the world and model tuning. \nthis provide me a great opportunity to learn, and i hope to put \nthese skills into developing the machine learning model. \nit is identified that the main trends are to predict the next word \nusing probability as well as predict the current word.  some data \naugmentation methods such as essaygans and conventional \ngans are introduced.  \nalso, i am able to learn the commonly used evaluation metrics \nto nlp learning model – qwk (quadrated weighted kappa).  \nevaluate this week is rewarding, i made aware to understand that the \ndifficulty of the project lies in several areas, one of them is \nunderstanding the semantics as well as grading the article itself, \nand essaygans do not follow the format of a conventional \ngans. it is worth notice to put into use of identification towards \nfake essay, especially given the rise of ai-generated content like \nchatgpt. the other important take-away is that deep learning \ntuning is so complicated which required sophisticated model \nunderstanding. \nplan \nthis has been an incredible crash course over the nlp model, \nand i am thankful for this week. i also decided to further my \nknowledge by re-construction the nlp models done in previous \ncourses as well as those on open sources like kaggle to confirm \nmy personal understanding.   \n \n \n23",
            "page": null,
            "goal": "week 4 – training (1) on nlp model trends and \napplications \ndescribe given the complexity of the project outcome, itic decided to \nextend this week as a training period for us to reinforce our \nunderstanding over nlp model.  \ninterpret it has been a difficult yet rewarding experience. i have to work \non summarizing the essay scoring note provided by the \ncompany and develop a set of presentation to showcase our \nunderstanding over nlp models.  \nit is so effective that within a short period of 1 week, i can \nunderstand current trend in nlp model and public dataset \navailable. using vectorization as a first step of nlp, review in-\ndepth some of the nlp topics such as vectorization method like \ntf-idf, word2vec, cbow. i learnt most of the vectorization \ntechniques from my degree, while it is seldom discussed about \nhow to capture the semantics of the world and model tuning. \nthis provide me a great opportunity to learn, and i hope to put \nthese skills into developing the machine learning model. \nit is identified that the main trends are to predict the next word \nusing probability as well as predict the current word.  some data \naugmentation methods such as essaygans and conventional \ngans are introduced.  \nalso, i am able to learn the commonly used evaluation metrics \nto nlp learning model – qwk (quadrated weighted kappa).  \nevaluate this week is rewarding, i made aware to understand that the \ndifficulty of the project lies in several areas, one of them is \nunderstanding the semantics as well as grading the article itself, \nand essaygans do not follow the format of a conventional \ngans. it is worth notice to put into use of identification towards \nfake essay, especially given the rise of ai-generated content like \nchatgpt. the other important take-away is that deep learning \ntuning is so complicated which required sophisticated model \nunderstanding. \nplan \nthis has been an incredible crash course over the nlp model, \nand i am thankful for this week. i also decided to further my \nknowledge by re-construction the nlp models done in previous \ncourses as well as those on open sources like kaggle to confirm \nmy personal understanding.   \n \n \n23",
            "children": []
        },
        {
            "id": "1.9",
            "name": "week 5",
            "nodeType": "title",
            "text": "week 5",
            "page": null,
            "goal": "week 5",
            "children": []
        },
        {
            "id": "1.10",
            "name": "week 5 –",
            "nodeType": "paragraph",
            "text": "week 5 – code analysis over bert model \ndescribe given recent nlp model development, itic was more inclined \nto choose the model of deep learning. i was assigned a task to \nanalyse a chosen academic article about bert model. \ninterpret understanding the job responsibility is to work on research and \nrecommendation on best model, code analysis over bert \nmodel is assigned. i downloaded the dataset from open source \nand tried to work with replicating data pre-process. once i run \nthe code, i started to get error message all along. i therefore \nspend some time in configuring and eventually found out the \nopen-source codes are written in python 2.8 hence giving out \nmuch of the error. eventually, with the help of academic essay, i \ncan product a code analysis detailing the usage of codes. a \nbusiness presentation was done and result in compliment from \nsteven. \nevaluate i have never work on code analysis before and i am unaware of \nsome best practice in this analysis, this affect the time span for \nme in preparing the code analysis report. an expected output \nlayout is presented in graph 11.  \n \ngraph 11: code analysis required output * \nstill, some takeaways from this week task are getting an in-\ndepth understanding over how bert model is utilised in essay-\nmarking tools. an approach of “meta-trained bert with in-\ncontext tuning” is discussed. the model can be divided into 3 \nmain layers.2 \n \n24 \n1) lm fine-tuning set-up: pre-trained bert model will be act \nas the base language model for automated scoring. the \ngoal of the set -up is to construct an input that include \nsemantics to the shared bert essay-scoring model and \nable to associate it with each specific item. 4 factors will \nbe included in the model. inputs has 3 initial factors, which \nare passage “pi”, question “qi”, and student response text \n“xtarget”. once inputted into the bert model, [sep] as \nthe separator j token in bert model’s vocabulary, will be \nadded between these parts to help the model differentiate \ninput text segments with different purposes. the passage \ntext will be encoded and [cls] embedding vector as the \ninput to bert model.  \n2) meta-training bert with in-context training: in-context \nlearning of a shared bert automated scoring model \nacross all items. in this session, in-context data, the \nresponse-score pair will be added into the training set.  \n \ngraph 12: illustration of meta-trained bert with in-context tuning2 \n \nplan \ni decided to work on code analysis as major tasks in this project \nto polish my skills in model development, and to fulfill my \npersonal aspiration as a machine learning developer. \n \n \n \n2  \n \n25",
            "page": null,
            "goal": "week 5 – code analysis over bert model \ndescribe given recent nlp model development, itic was more inclined \nto choose the model of deep learning. i was assigned a task to \nanalyse a chosen academic article about bert model. \ninterpret understanding the job responsibility is to work on research and \nrecommendation on best model, code analysis over bert \nmodel is assigned. i downloaded the dataset from open source \nand tried to work with replicating data pre-process. once i run \nthe code, i started to get error message all along. i therefore \nspend some time in configuring and eventually found out the \nopen-source codes are written in python 2.8 hence giving out \nmuch of the error. eventually, with the help of academic essay, i \ncan product a code analysis detailing the usage of codes. a \nbusiness presentation was done and result in compliment from \nsteven. \nevaluate i have never work on code analysis before and i am unaware of \nsome best practice in this analysis, this affect the time span for \nme in preparing the code analysis report. an expected output \nlayout is presented in graph 11.  \n \ngraph 11: code analysis required output * \nstill, some takeaways from this week task are getting an in-\ndepth understanding over how bert model is utilised in essay-\nmarking tools. an approach of “meta-trained bert with in-\ncontext tuning” is discussed. the model can be divided into 3 \nmain layers.2 \n \n24 \n1) lm fine-tuning set-up: pre-trained bert model will be act \nas the base language model for automated scoring. the \ngoal of the set -up is to construct an input that include \nsemantics to the shared bert essay-scoring model and \nable to associate it with each specific item. 4 factors will \nbe included in the model. inputs has 3 initial factors, which \nare passage “pi”, question “qi”, and student response text \n“xtarget”. once inputted into the bert model, [sep] as \nthe separator j token in bert model’s vocabulary, will be \nadded between these parts to help the model differentiate \ninput text segments with different purposes. the passage \ntext will be encoded and [cls] embedding vector as the \ninput to bert model.  \n2) meta-training bert with in-context training: in-context \nlearning of a shared bert automated scoring model \nacross all items. in this session, in-context data, the \nresponse-score pair will be added into the training set.  \n \ngraph 12: illustration of meta-trained bert with in-context tuning2 \n \nplan \ni decided to work on code analysis as major tasks in this project \nto polish my skills in model development, and to fulfill my \npersonal aspiration as a machine learning developer. \n \n \n \n2  \n \n25",
            "children": []
        },
        {
            "id": "1.11",
            "name": "week 6",
            "nodeType": "title",
            "text": "week 6",
            "page": null,
            "goal": "week 6",
            "children": []
        },
        {
            "id": "1.12",
            "name": "week 6 –",
            "nodeType": "paragraph",
            "text": "week 6 – training (2) over current market nlp \nmodels: rnn, lstm, elmo, bert \ndescribe a second part of training focusing on the given knowledge of \nbert are consolidated and code analysis provided insightful \nfeedbacks, itic decided to develop own essay-marking tool, \nleveraging on the state-of-the-art bert model. the current \npopular usage of nlp models is discussed.  \ninterpret nlp tasks are generalised and discussed. those tasks include \npre-train stage, model tuning, and transformers phase. graph13 \nis an illustration of nlp tasks.  \n \n \n \ngraph 13: nlp tasks * \n \nall popular models with in-depth tuning knowledge are \ndiscussed in this section, including rnn, lstm, elmo, bert, \nand in-depth bert model tuning. it is worth mentioning the \ninitial thoughts on using chatgpt is rejected since after careful \nresearch it is more of a decoder then an encoder. the nature of \nour project is understanding the semantics, which required \nencoder transformer.  \n \nevaluate this week i reckon is the biggest and best training i receive so \nfar in the course of this internship and throughout this master’s \ndegree.  \nit is learnt that the model of rnn, lstm has their own \nlimitations, including the nature of word embedding that \nassigning semantics does not take into consideration of same \nword in different context (shortcoming of nltk library). rnn by \nnature is non-bidirectional and will affect accuracy.  the \nslowness in training is worst in rnn, and worst in lstm. other \nfunctional issues such as exploding gradients and dead relu \nare some issues to address by lstm. graph 14 is a simple \nillustration of rnn and lstm with one layer. this is shown that \n \n26 \nlstm although tackle the issues of rnn, while at the same time \ntraining data become more expensive. \n \ngraph 14: rnn & lstm one-layer illustration * \nalso, it is educated that the rnn does not have the ability to \nconduct pre-training which would affect accuracy. elmo is \nintroduced to train the data input separately, with left-to-right \nand right-to-left leveraging on lstms, then apply them as pre-\ntrained embeddings. in this way, we could resolve the issue of \nlacking context –awareness in rnn model by including elmo \nfrom embedding stage and achieve higher baseline accuracy in \ngeneral. graph15 is the illustration of elmo layer. \n \n \n \n \n \n \ngraph 15: elmo illustration * \nwhile ultimately, the solution seems to be bert. by nature, \nbert is less expensive to train since it is bi-directional, and it \nenables pre-training as well which tackle all the issues of the \ncurrent model. \n \n27 \n \ngraph 16: bert illustration * \n \nplan \nwith all work on the code development next time, and moving \nforward in code development, there may be a need to work on \nthe pre-determination of dataset as well since training data is \none of the essential parts of machine learning.",
            "page": null,
            "goal": "week 6 – training (2) over current market nlp \nmodels: rnn, lstm, elmo, bert \ndescribe a second part of training focusing on the given knowledge of \nbert are consolidated and code analysis provided insightful \nfeedbacks, itic decided to develop own essay-marking tool, \nleveraging on the state-of-the-art bert model. the current \npopular usage of nlp models is discussed.  \ninterpret nlp tasks are generalised and discussed. those tasks include \npre-train stage, model tuning, and transformers phase. graph13 \nis an illustration of nlp tasks.  \n \n \n \ngraph 13: nlp tasks * \n \nall popular models with in-depth tuning knowledge are \ndiscussed in this section, including rnn, lstm, elmo, bert, \nand in-depth bert model tuning. it is worth mentioning the \ninitial thoughts on using chatgpt is rejected since after careful \nresearch it is more of a decoder then an encoder. the nature of \nour project is understanding the semantics, which required \nencoder transformer.  \n \nevaluate this week i reckon is the biggest and best training i receive so \nfar in the course of this internship and throughout this master’s \ndegree.  \nit is learnt that the model of rnn, lstm has their own \nlimitations, including the nature of word embedding that \nassigning semantics does not take into consideration of same \nword in different context (shortcoming of nltk library). rnn by \nnature is non-bidirectional and will affect accuracy.  the \nslowness in training is worst in rnn, and worst in lstm. other \nfunctional issues such as exploding gradients and dead relu \nare some issues to address by lstm. graph 14 is a simple \nillustration of rnn and lstm with one layer. this is shown that \n \n26 \nlstm although tackle the issues of rnn, while at the same time \ntraining data become more expensive. \n \ngraph 14: rnn & lstm one-layer illustration * \nalso, it is educated that the rnn does not have the ability to \nconduct pre-training which would affect accuracy. elmo is \nintroduced to train the data input separately, with left-to-right \nand right-to-left leveraging on lstms, then apply them as pre-\ntrained embeddings. in this way, we could resolve the issue of \nlacking context –awareness in rnn model by including elmo \nfrom embedding stage and achieve higher baseline accuracy in \ngeneral. graph15 is the illustration of elmo layer. \n \n \n \n \n \n \ngraph 15: elmo illustration * \nwhile ultimately, the solution seems to be bert. by nature, \nbert is less expensive to train since it is bi-directional, and it \nenables pre-training as well which tackle all the issues of the \ncurrent model. \n \n27 \n \ngraph 16: bert illustration * \n \nplan \nwith all work on the code development next time, and moving \nforward in code development, there may be a need to work on \nthe pre-determination of dataset as well since training data is \none of the essential parts of machine learning.",
            "children": []
        },
        {
            "id": "1.13",
            "name": "week 7",
            "nodeType": "title",
            "text": "week 7",
            "page": null,
            "goal": "week 7",
            "children": []
        },
        {
            "id": "1.14",
            "name": "week 7 –",
            "nodeType": "paragraph",
            "text": "week 7 – determining model for essay marking (1) \ndescribe i attended a face-to-face meeting with stephen, masoud and \nother intern student in itic office. it is announced that our \nproject is mature to proceed to implementation stage. \ninterpret during the business meeting, it is decided that current tasks of \nessay-marking tool shall be decomposed into 3 main parts, \nwhich are essay-scoring, content summary for marker, and \nquestion generation for student based on what they write. \n \nit is discussed and determined that the first task would likely to \nbase on bert while more testing are required. the second and \nlast tasks are likely to leverage on existing api. it is important \nfor us in this week to research for suitable datasets, try to work \non essaygan to generate dataset with 3000 – 4000 essays \nsample.   \nevaluate it is an important week for this project to enter this \nimplementation stage. it is learnt that instead of treating marking \nas a complicated problem where scoring is an ordinal concept, it \nis easier to treat it as a classification problem. the way of \nthinking outside the box is great takeaway for me. i decided to \n \n28 \nwork on dataset determination. it is reported that 33 datasets \nare found via google new service of dataset search. more \ncompatible datasets with our model would be including toefl, \nielts, asap dataset and corpus dataset  \nplan \ni decided to report over the useful tool of google data search \nand available open dataset.",
            "page": null,
            "goal": "week 7 – determining model for essay marking (1) \ndescribe i attended a face-to-face meeting with stephen, masoud and \nother intern student in itic office. it is announced that our \nproject is mature to proceed to implementation stage. \ninterpret during the business meeting, it is decided that current tasks of \nessay-marking tool shall be decomposed into 3 main parts, \nwhich are essay-scoring, content summary for marker, and \nquestion generation for student based on what they write. \n \nit is discussed and determined that the first task would likely to \nbase on bert while more testing are required. the second and \nlast tasks are likely to leverage on existing api. it is important \nfor us in this week to research for suitable datasets, try to work \non essaygan to generate dataset with 3000 – 4000 essays \nsample.   \nevaluate it is an important week for this project to enter this \nimplementation stage. it is learnt that instead of treating marking \nas a complicated problem where scoring is an ordinal concept, it \nis easier to treat it as a classification problem. the way of \nthinking outside the box is great takeaway for me. i decided to \n \n28 \nwork on dataset determination. it is reported that 33 datasets \nare found via google new service of dataset search. more \ncompatible datasets with our model would be including toefl, \nielts, asap dataset and corpus dataset  \nplan \ni decided to report over the useful tool of google data search \nand available open dataset.",
            "children": []
        },
        {
            "id": "1.15",
            "name": "week 8",
            "nodeType": "title",
            "text": "week 8",
            "page": null,
            "goal": "week 8",
            "children": []
        },
        {
            "id": "1.16",
            "name": "week 8 –",
            "nodeType": "paragraph",
            "text": "week 8 – determining model for essay marking (2) \ndescribe after the review meeting, itic decided that start off with \nreplicating suitable bert model over simple text classification \ntask, and will proceed to move forward with customisation of \ntask over dataset.  \ninterpret i attended business meetings where it is decided that a series of \nbert code are to be replicated tested based on available bbc \ndataset. bbc datasets are a dataset with news from bbc and \ncategorized into 5 different categories, namely politics, \nbusiness, entertainment, sports and tech. dataset of first 5 rows \nof data is presented below in graph 17. since the nature of \nclassifier is equivalent, it is determined if the test result is \nsatisfactory, it is likely the model will be customised over our \nessay-marking task.  \ngraph 17: bbc dataset (first 5 rows) \n \na replication of model is conducted. it is reported that the bert \nmodel would be bert base, where it consists of 12 layers of \ntransformer encoder, 12 attention heads, 768 hidden size and \n110 parameters. the input is the content of bbc news text with \ncurrent categorization labelled, the output expected is the \ncategory they belong to.  \nevaluate it is again a rewarding week. i have to replication over the bert \nmodel on bbc dataset. the machine learning modelling skill i \nlearnt from current course will be put into use in real-world \nscenario. data exploration, manipulation and cleaning \ntechniques are also applied. also, the pytorch language is new \nso some time is spent in understanding the new language. \nleveraging on pytorch and colab notebook, a replication over \nbert base is applied towards bbc dataset. the model \nreported a 98% accuracy over the bbc dataset classification \ntask. it is determined that bert base classifier would be the \n \n29 \nmodel. below graph 18 is the initial result of the machine \nlearning model. \n \n \n \ngraph 18: bert model over bbc dataset \nthis is a rewarding week, not only i am able to learn about the \nuse of tensorflow and pytorch in training bert model, but it also \nprovides me exposure in current practice in developing a \nmachine learning model. instead of working from scratch, it is \nmore efficient to leverage on existing model, customise and \napply customisation to another dataset. \nplan \ni decided to report over meeting about the high accuracy and \nrecommended bert base model as our essay-marking model. \nnext stage is likely to be in dataset determination.",
            "page": null,
            "goal": "week 8 – determining model for essay marking (2) \ndescribe after the review meeting, itic decided that start off with \nreplicating suitable bert model over simple text classification \ntask, and will proceed to move forward with customisation of \ntask over dataset.  \ninterpret i attended business meetings where it is decided that a series of \nbert code are to be replicated tested based on available bbc \ndataset. bbc datasets are a dataset with news from bbc and \ncategorized into 5 different categories, namely politics, \nbusiness, entertainment, sports and tech. dataset of first 5 rows \nof data is presented below in graph 17. since the nature of \nclassifier is equivalent, it is determined if the test result is \nsatisfactory, it is likely the model will be customised over our \nessay-marking task.  \ngraph 17: bbc dataset (first 5 rows) \n \na replication of model is conducted. it is reported that the bert \nmodel would be bert base, where it consists of 12 layers of \ntransformer encoder, 12 attention heads, 768 hidden size and \n110 parameters. the input is the content of bbc news text with \ncurrent categorization labelled, the output expected is the \ncategory they belong to.  \nevaluate it is again a rewarding week. i have to replication over the bert \nmodel on bbc dataset. the machine learning modelling skill i \nlearnt from current course will be put into use in real-world \nscenario. data exploration, manipulation and cleaning \ntechniques are also applied. also, the pytorch language is new \nso some time is spent in understanding the new language. \nleveraging on pytorch and colab notebook, a replication over \nbert base is applied towards bbc dataset. the model \nreported a 98% accuracy over the bbc dataset classification \ntask. it is determined that bert base classifier would be the \n \n29 \nmodel. below graph 18 is the initial result of the machine \nlearning model. \n \n \n \ngraph 18: bert model over bbc dataset \nthis is a rewarding week, not only i am able to learn about the \nuse of tensorflow and pytorch in training bert model, but it also \nprovides me exposure in current practice in developing a \nmachine learning model. instead of working from scratch, it is \nmore efficient to leverage on existing model, customise and \napply customisation to another dataset. \nplan \ni decided to report over meeting about the high accuracy and \nrecommended bert base model as our essay-marking model. \nnext stage is likely to be in dataset determination.",
            "children": []
        },
        {
            "id": "1.17",
            "name": "week 9",
            "nodeType": "title",
            "text": "week 9",
            "page": null,
            "goal": "week 9",
            "children": []
        },
        {
            "id": "1.18",
            "name": "week 9 –",
            "nodeType": "paragraph",
            "text": "week 9 – customisation of dataset & model \ntraining \ndescribe it is crucial to apply the bert base model towards a determined \ndataset and work on its classifier task to move the project \nforward. it is determined that asap dataset shall be utilised and \nwe shall investigate and start to work with customisation of \ncodes.  \ninterpret this is a challenging task to customise over asap dataset. the \noriginal dataset is a set of 28 x 12978 columns, many of the \ndata in columns are missing. \n \nit is decided that i shall apply the knowledge i gain from current \ncourse regarding machine learning to try and customise the \nmodel. first, i perform exploratory data analysis. it is found that \nthere were 8 different questions with different mark distribution. i \nthen make the call to remove the question 7 and 8 with \ncompletely different marking distribution. then i tried to conduct \n \n30 \nmachine learning techniques using bert base. below is the \ninitial result of the machine learning model.  \n \n \n \n \ngraph 19: bert model over bbc dataset \nfrom graph 18, it is reflected that there is serious overfitting \nissue with the current model. overfitting happens when the \nmodel is too generalised and fit the training data too much.it is \nobserved that there is serious overfitting issue and more data \nanalysis shall be conducted to understand how to improve \nthrough data handling and data manipulation.  \n \nevaluate performing exploratory data analysis (eda) over the asap \ndata is an interesting experience since text data is not easy to \nvisualise. it is learnt that i can calculate the tf-idf scores and \napply wordcloud tool for understanding the data. words with \nimportance in terms of context and frequency will be presented \nand easy understanding and comparison can be made.  an \nillustration of wordcloud is as below graph 20.  \n \n \n \n \n \n \n \ngraph 20: wordcloud for current training dataset  \n \n \n31 \nplan \nby working on visualisation, it is learnt that data cleaning are \nessential towards tackling the overfitting issue. due to time \nschedule, i decided to report over next business meeting \nregarding the high overfitting issue, and recommend working on \ndata cleaning for the next week.",
            "page": null,
            "goal": "week 9 – customisation of dataset & model \ntraining \ndescribe it is crucial to apply the bert base model towards a determined \ndataset and work on its classifier task to move the project \nforward. it is determined that asap dataset shall be utilised and \nwe shall investigate and start to work with customisation of \ncodes.  \ninterpret this is a challenging task to customise over asap dataset. the \noriginal dataset is a set of 28 x 12978 columns, many of the \ndata in columns are missing. \n \nit is decided that i shall apply the knowledge i gain from current \ncourse regarding machine learning to try and customise the \nmodel. first, i perform exploratory data analysis. it is found that \nthere were 8 different questions with different mark distribution. i \nthen make the call to remove the question 7 and 8 with \ncompletely different marking distribution. then i tried to conduct \n \n30 \nmachine learning techniques using bert base. below is the \ninitial result of the machine learning model.  \n \n \n \n \ngraph 19: bert model over bbc dataset \nfrom graph 18, it is reflected that there is serious overfitting \nissue with the current model. overfitting happens when the \nmodel is too generalised and fit the training data too much.it is \nobserved that there is serious overfitting issue and more data \nanalysis shall be conducted to understand how to improve \nthrough data handling and data manipulation.  \n \nevaluate performing exploratory data analysis (eda) over the asap \ndata is an interesting experience since text data is not easy to \nvisualise. it is learnt that i can calculate the tf-idf scores and \napply wordcloud tool for understanding the data. words with \nimportance in terms of context and frequency will be presented \nand easy understanding and comparison can be made.  an \nillustration of wordcloud is as below graph 20.  \n \n \n \n \n \n \n \ngraph 20: wordcloud for current training dataset  \n \n \n31 \nplan \nby working on visualisation, it is learnt that data cleaning are \nessential towards tackling the overfitting issue. due to time \nschedule, i decided to report over next business meeting \nregarding the high overfitting issue, and recommend working on \ndata cleaning for the next week.",
            "children": []
        },
        {
            "id": "1.19",
            "name": "week 10",
            "nodeType": "title",
            "text": "week 10",
            "page": null,
            "goal": "week 10",
            "children": []
        },
        {
            "id": "1.20",
            "name": "week 10 –",
            "nodeType": "paragraph",
            "text": "week 10 – customisation of dataset & model \ntraining (2) \ndescribe reported in the business meeting that i have great result with \nserious overfitting issues. it is advised that more data cleaning \ntechniques shall be applied in order to ensure the quality of \ndata.   \ninterpret it is decided that text handling technique using nltk library such \nas tokenization, normalisation, applying stop words, etc. shall be \napplied. more of the text handling code will be presented in next \nsection.  \n \n \ngraph 22.1: text before handing \n \ngraph 22.2: text after handling \nthen i tried to apply the same machine learning model towards \nthe cleaned dataset. the result of dataset is as follows.  \n \n \ngraph 23: bert model over bbc dataset \nit is recognised that overfitting problem still exist while the \nmagnitude has been greatly reduced.  \n \n32 \nevaluate it is reviewed that text handling techniques based on nltk library \nis a critical part in ensuring the quality of data for text model. \ncomparing the corpus of bbc dataset and asap dataset, it is \nfound that data has been at the clean stage for bbc dataset, \nwhile not the case for asap dataset.   \nit is also argued that the classification for bbc dataset would \nexpect higher accuracy due to the nature of data. bbc dataset \n(on the left of graph 24) is more data unbiased compare to \nasap dataset (on the right of graph 24), and it consists of \ndifferent words and the tf-idf score itself has great differences \n(illustrated in graph 25).  \ngraph 24: comparison of bbc dataset category distribution and asap dataset \ncategory distribution9 \n \ngraph 25: tf-idf scores for bbc article feature after dimensionality reduction9 \n \n \n9  \n9  \n \n33 \nplan \ni decided to report my findings over next business meeting \nregarding the high overfitting issue. it is recommended that \neither continue with current model with parameter tuning, \nsearching for alternative model for current dataset or alternative \ndataset for training.",
            "page": null,
            "goal": "week 10 – customisation of dataset & model \ntraining (2) \ndescribe reported in the business meeting that i have great result with \nserious overfitting issues. it is advised that more data cleaning \ntechniques shall be applied in order to ensure the quality of \ndata.   \ninterpret it is decided that text handling technique using nltk library such \nas tokenization, normalisation, applying stop words, etc. shall be \napplied. more of the text handling code will be presented in next \nsection.  \n \n \ngraph 22.1: text before handing \n \ngraph 22.2: text after handling \nthen i tried to apply the same machine learning model towards \nthe cleaned dataset. the result of dataset is as follows.  \n \n \ngraph 23: bert model over bbc dataset \nit is recognised that overfitting problem still exist while the \nmagnitude has been greatly reduced.  \n \n32 \nevaluate it is reviewed that text handling techniques based on nltk library \nis a critical part in ensuring the quality of data for text model. \ncomparing the corpus of bbc dataset and asap dataset, it is \nfound that data has been at the clean stage for bbc dataset, \nwhile not the case for asap dataset.   \nit is also argued that the classification for bbc dataset would \nexpect higher accuracy due to the nature of data. bbc dataset \n(on the left of graph 24) is more data unbiased compare to \nasap dataset (on the right of graph 24), and it consists of \ndifferent words and the tf-idf score itself has great differences \n(illustrated in graph 25).  \ngraph 24: comparison of bbc dataset category distribution and asap dataset \ncategory distribution9 \n \ngraph 25: tf-idf scores for bbc article feature after dimensionality reduction9 \n \n \n9  \n9  \n \n33 \nplan \ni decided to report my findings over next business meeting \nregarding the high overfitting issue. it is recommended that \neither continue with current model with parameter tuning, \nsearching for alternative model for current dataset or alternative \ndataset for training.",
            "children": []
        },
        {
            "id": "1.21",
            "name": "week 11",
            "nodeType": "title",
            "text": "week 11",
            "page": null,
            "goal": "week 11",
            "children": []
        },
        {
            "id": "1.22",
            "name": "week 11 –",
            "nodeType": "paragraph",
            "text": "week 11 – parameter tuning over bert model \ndescribe since some of the initial findings are reported during the \nmeeting, it is decided that parameter tuning shall be performed \nover below learning rate and dropout.  \n• dropout: between 0.5 to 0.6  \n• lr: 1e-5, 1e-6, 1e-7, 2e-5, 2e-6, 2e-7 \ninterpret the cpu is not enough to perform parameter tuning. it is \nresolved to working with gpu for parameter tuning and training \nof model. some of the results will be presented in the next \nsection of working examples. due to gpu limit, selected \nparameters were used and the summary of result is as follows:  \nclasses dropout \nrate \nlearning \nrate \nepoch \ntraining \naccuracy \n13 \n0.5 \n1e-6 \n6 \n0.955 \n20 \n0.5 \n1e-6 \n8 \n0.989 \n20 \n0.6 \n1e-6 \n8 \n0.966 \n20 \n0.5 \n1e-7 \n10 \n0.710 \n20 \n0.5 \n1e-5 \n3 \n0.910 \nit is analysed that 20 classes with dropout rate at 0.5, learning \nrate at 1e-6 and epoch = 8 would be the best model. \nevaluate this is a week with many takeaways. first, it is learnt that \ncapacity of running deep learning model is huge, there would be \nlimited gpu constraint. also, it is discovered that changing \nparameters would result in huge differences in terms of the \naccuracy of model. however, after solving for overfitting issue \nthe underfitting issue happens.  \nplan \ni decided to report over next business meeting where it is \nnecessary to find alternative dataset for training, or should i \nmove forward in resolving the model accuracy issue. \n \n \n34",
            "page": null,
            "goal": "week 11 – parameter tuning over bert model \ndescribe since some of the initial findings are reported during the \nmeeting, it is decided that parameter tuning shall be performed \nover below learning rate and dropout.  \n• dropout: between 0.5 to 0.6  \n• lr: 1e-5, 1e-6, 1e-7, 2e-5, 2e-6, 2e-7 \ninterpret the cpu is not enough to perform parameter tuning. it is \nresolved to working with gpu for parameter tuning and training \nof model. some of the results will be presented in the next \nsection of working examples. due to gpu limit, selected \nparameters were used and the summary of result is as follows:  \nclasses dropout \nrate \nlearning \nrate \nepoch \ntraining \naccuracy \n13 \n0.5 \n1e-6 \n6 \n0.955 \n20 \n0.5 \n1e-6 \n8 \n0.989 \n20 \n0.6 \n1e-6 \n8 \n0.966 \n20 \n0.5 \n1e-7 \n10 \n0.710 \n20 \n0.5 \n1e-5 \n3 \n0.910 \nit is analysed that 20 classes with dropout rate at 0.5, learning \nrate at 1e-6 and epoch = 8 would be the best model. \nevaluate this is a week with many takeaways. first, it is learnt that \ncapacity of running deep learning model is huge, there would be \nlimited gpu constraint. also, it is discovered that changing \nparameters would result in huge differences in terms of the \naccuracy of model. however, after solving for overfitting issue \nthe underfitting issue happens.  \nplan \ni decided to report over next business meeting where it is \nnecessary to find alternative dataset for training, or should i \nmove forward in resolving the model accuracy issue. \n \n \n34",
            "children": []
        },
        {
            "id": "1.23",
            "name": "week 12",
            "nodeType": "title",
            "text": "week 12",
            "page": null,
            "goal": "week 12",
            "children": []
        },
        {
            "id": "1.24",
            "name": "week 12 –",
            "nodeType": "paragraph",
            "text": "week 12 – fitting corpus dataset & finding \nalternatives \ndescribe it is assigned that due to lack of fit of current model for the \nasap dataset, it is decided to work on finding alternative and \nrecommend to itic.  \ninterpret it is researched that most of the current essay-scoring model \nare leveraged on asap dataset. a summary of datasets are \nlisted in graph 26.  \n \n \n \n \n \ngraph 26: list of popular datasets in research of essay-marking10 \nit is researched that some alternative models were used. wang \net al. suggested a joint learning approach for multi-scale essay \nrepresentation leveraging on the bert transformer function. \ngraph 26 is an illustration of the model architecture. \n \ngraph 26: illustration of multi-scale essay representation model design11 \n \n10  \n11  \n \n35 \nit is also assigned that i shall look into the incorporation of \ncorpus dataset for the training of model. it is found that multiple \nxml files are required to consolidate in order to get data, while i \nfaced some technicality issue and the files and unable to \nconsolidate the file. \nevaluate it is to stress that itic would like us to work on the alternative on \ncorpus dataset, while due to some interesting discovery over \nresearch, i personally decided to work on code analysis over a \nnew model instead. it is decided that it is more important to \nsolve a problem than to work according to assigned task.  \nplan \ni am going to report my recommendations and findings over the \nmodel analysis and seek for further advise in terms of my \nupcoming assignments.",
            "page": null,
            "goal": "week 12 – fitting corpus dataset & finding \nalternatives \ndescribe it is assigned that due to lack of fit of current model for the \nasap dataset, it is decided to work on finding alternative and \nrecommend to itic.  \ninterpret it is researched that most of the current essay-scoring model \nare leveraged on asap dataset. a summary of datasets are \nlisted in graph 26.  \n \n \n \n \n \ngraph 26: list of popular datasets in research of essay-marking10 \nit is researched that some alternative models were used. wang \net al. suggested a joint learning approach for multi-scale essay \nrepresentation leveraging on the bert transformer function. \ngraph 26 is an illustration of the model architecture. \n \ngraph 26: illustration of multi-scale essay representation model design11 \n \n10  \n11  \n \n35 \nit is also assigned that i shall look into the incorporation of \ncorpus dataset for the training of model. it is found that multiple \nxml files are required to consolidate in order to get data, while i \nfaced some technicality issue and the files and unable to \nconsolidate the file. \nevaluate it is to stress that itic would like us to work on the alternative on \ncorpus dataset, while due to some interesting discovery over \nresearch, i personally decided to work on code analysis over a \nnew model instead. it is decided that it is more important to \nsolve a problem than to work according to assigned task.  \nplan \ni am going to report my recommendations and findings over the \nmodel analysis and seek for further advise in terms of my \nupcoming assignments.",
            "children": []
        },
        {
            "id": "1.25",
            "name": "week 13",
            "nodeType": "title",
            "text": "week 13",
            "page": null,
            "goal": "week 13",
            "children": []
        },
        {
            "id": "1.26",
            "name": "week 13 –",
            "nodeType": "paragraph",
            "text": "week 13 – wrapping up the internship experience. \ndescribe since this is the last week of my internship experience, we are \nsupposed to work on consolidating all the work and wrap up our \nfindings for smooth hand-over to itic. \ninterpret learning about that smooth transition and data documentation \nare important since everyone have their finite tenure within a \ncompany.  \nevaluate professional working style are learnt, and it is important for my \nfuture development when i will be working within a company. \nplan \ni would like to seek for employment in australia in general. i \nwould start updating my resume with my experience in itic and \ntry to leverage on all the nlp techniques i learnt and transfer \nthem to my new working environment.",
            "page": null,
            "goal": "week 13 – wrapping up the internship experience. \ndescribe since this is the last week of my internship experience, we are \nsupposed to work on consolidating all the work and wrap up our \nfindings for smooth hand-over to itic. \ninterpret learning about that smooth transition and data documentation \nare important since everyone have their finite tenure within a \ncompany.  \nevaluate professional working style are learnt, and it is important for my \nfuture development when i will be working within a company. \nplan \ni would like to seek for employment in australia in general. i \nwould start updating my resume with my experience in itic and \ntry to leverage on all the nlp techniques i learnt and transfer \nthem to my new working environment.",
            "children": []
        }
    ]
}