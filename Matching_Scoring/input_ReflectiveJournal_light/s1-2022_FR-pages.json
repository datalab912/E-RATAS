{
    "id": "1",
    "name": "Reflective journal Entities",
    "nodeType": "section",
    "text": "week 4     \ngoals, activities and outcomes     \nwe examined the relationship between experience and salary rate this week. as a result of the \nfact that we had to analyse our data to determine the proper relationship between years of \nexperience and rate factor, we were under considerable pressure. to improve the analysis, we \nasked our university lecturer to use the most efficient method. despite our desire to utilize \nspss, we were concerned that our data was not sufficiently clean for testing. upon analysing \nour data, we found that there was a strong correlation between years of experience and salary \nrate. for example, an individual with more experience will earn a higher salary. due to \nunclearly of the foreseen model, we were unable to meet the target for the week.     \n    \ndescription of any new knowledge, skills, or experiences gained during the week:     \nwe were able to gain a lot of experience during the week because of the nltk library. the \nopportunity to work with such a large and well-organized library was a great experience for \nme. i feel like i learned a great deal about natural language processing this week. i'm looking \nforward to learning more about it in the future. i've also learned how to create custom functions \nto assist with these tasks.    \nfurthermore, i have learned how to create custom corpora and wordlists to help me accomplish \nthese tasks. in addition to that, i have gained a better understanding of how to use python for \ntext mining.    \n    \nin high-pressure situations, teamwork is essential to get the job done efficiently and effectively. \nwhen everyone is working together towards a common goal, it is easier to problem-solve and \ncome up with creative solutions. additionally, teamwork can help to reduce stress levels and \nbuild morale. when people are working together under pressure, it is important for them to be \nable to rely on each other. this means that team members need to be able to trust each other \nand know that they can count on each other to do their part. it is also important for team \nmembers to be able to communicate effectively with each other. this way, they can coordinate \ntheir efforts and make sure that everyone is on the same page.    \n    \nrewarding experience     \nthere is nothing more rewarding than being able to work together as a team under pressure and \ncoming out victorious. a sense of camaraderie and accomplishment that comes with \novercoming a difficult challenge together is unmatched by any other. when you are working \nas a team under pressure, it is essential for everyone to be on the same page and focus on the \nsame goal. there can be no room for error when lives are on the line. for this type of work \nenvironment to be successful, trust, communication, and respect must be present. if a team is \nable to work efficiently under pressure and come together as a unit, this is a truly rewarding \nexperience.    \n    \ndifficult experience    \ngetting started on a task is easy but it is not always easy to complete it. this is especially true \nif the task in question is challenging. in the case of a difficult task, it can be hard to find the \nmotivation to go on with it. it can be easy to get discouraged and give up on it. whenever i \nhave a difficult task that is hard to complete, it is important to remember that i am not alone in \nmy struggles. it is common for people to have difficulty completing difficult tasks. finding a \nway to keep going is the key to completing difficult tasks. among the ways to do this is to \nbreak the task down into smaller, more manageable pieces.     \n    \nnext week's tasks     \nwe should be working on the same task next week as we did this week. we ought to, once \nagain, use the frequency analysis method for analysing the skill required for the task and feed \nthat data into the training module.  having done this, we can understand what skills are needed \nfor the task and how to train for it in the best way possible. moreover, we have to learn about \nthe philosophy of servant leadership.     \n     \nreflective journal entries     \nweek 5     \ngoals, activities and outcomes    \nthe task we were working on this week is the same task we were working on last week. in \norder to analyse the skill required for the task and feed that data into the training module, we \nonce again used the frequency analysis method. by doing this, we were able to figure out what \nskills were needed for the data and how to train the data to achieve the best results. as part of \nthis week's study, we examined how experience influences salary rates. as a result of analysing \nour data, we were able to determine a possible relationship between years of experience and \nrate factor.    \n    \nas a second step to the frequency analysis, we cleaned up the data, filled in missing values, \nremoved stop words and non-alphabetic characters using nltk, and defined a function. the \nfrequency of words in requirements for both business analysts and data engineers, as well as \nthe requirements for data analysts, was also found.    \n    \nto better understand the resume skills, callum hired hr consultants with experience in the \nbusiness sector. thus, she asked me to be the scrum master for the project next week. i \ncompleted my scrum sprint 3 and forwarded it to jira.    \n     \ndescription of any new knowledge, skills, or experiences gained during the week    \ni learned how to use python for text mining. i learned how to create custom functions to help \nme with these tasks. i've also learned how to create custom corpora and word lists to help me \naccomplish these tasks. on top of that, i have a better understanding of how to use python for \ntext mining.    \n    \na new skill that i learn was servant leadership, which is a leadership philosophy in which the \nleader's primary motivation is to serve others. it can be accomplished in a number of ways, \nsuch as by providing support and guidance to team members, or by taking on tasks and \nresponsibilities that would otherwise fall to others. servant leaders are not motivated by power \nor prestige, but by a desire to help others fulfill their potential. they are servant hearted. the \nperson he or she leads has a genuine concern for the people he or she leads.     \n     \nrewarding experience    \nthe experience of working as a scrum master was very rewarding. we learned that it was an \nexcellent way to help teams work together more effectively and efficiently, and it was also a \ngreat way to get a better understanding of the inner workings of a team. as mentioned earlier, \nscrum masters can also be a great asset to a company since they can assist in improving \ncommunication and collaboration between a company's teams.    \n     \ndifficult experience    \ni was the scrum master for my team and it was a difficult experience. i had to keep the team on \ntrack and make sure that everyone was doing their part. it was a lot of work and i had to be \nvery organized.    \n    \nnext week's tasks     \nthe task for next week was to suggest new keywords, and phrases based on skill frequency \nanalysis for gtp3.    \n    \nreflective journal entries     \nweek 6     \ngoals, activities and outcomes    \ngoals are achieved by identifying the data, extracting the relevant roles, capturing the data, and \nconstructing a profile that can be used to build correlations between the data. once the contract \nroles have been defined, skillsets and requirements have been evaluated in the database to map \nthem to the contract opportunities. it would be helpful if you can provide me with a phrase \ninput, such as \"this is a test\" and a count of how many times the phrase appears in the text. my \ngoal is to see which phrase appears the most often out of a set of phrases. when i used the \nfrequency analysis function, it only counts the number of words, not the frequency of \noccurrence. if there is a way to search for a phrase and count how many times it appears in a \ndocument, i would greatly appreciate it. furthermore, callum suggested that we draw more \nplots to see how the re-queried and skill data outputs relate to one another.    \n    \ndescription of any new knowledge, skills, or experiences gained during the week   during \nthis week, i learned about gpt-3, a natural language processing platform that enables \ndevelopers to train and deploy ai models. the application provides a wide range of features, \nincluding text classification, entity recognition, and sentiment analysis. gpt-3 allows \ndevelopers to build applications that are capable of understanding and responding to natural \nlanguage inputs. gtp 3 is a toolkit that allows us to develop, test, and deploy chatbots and \nother applications that can be used in conversations. the tool includes a number of features, \nincluding natural language processing, dialogue management, and a chatbot development tool.    \n    \nrewarding experience    \nit was a great experience to use the gpt-3 open-source ai model. i was able to train the model \non a variety of data sets and achieve good results. the model was also able to generalize well \nto new data sets. i found the gpt3 open-ai to be a very rewarding experience. i was able to get \na lot of insights into how the system works and how it can be used to improve my own ai \nprojects. i would recommend this to anyone who is looking to get started with open-ai or to \nimprove their own ai projects.    \n    \ndifficult experience    \nthe gpt-3 open-ai model was difficult for me to use for a number of reasons. in the \nbeginning, the model is very large and requires a great deal of computational resources to run. \nin addition, there is insufficient documentation, and it is unclear how to use the model. last \nbut not least, the model is constantly changing, so it is difficult to stay on top of it.    \n    \nnext week's tasks     \nthe task for next week is to create a generative pre-trained transformer. thus, we intend to use \na pretrained model to generate a rewritten text. to achieve this, we can use the following \napproach:     \n   \n• \nto create customized texts from scratch, use the pre-trained model.     \n• \nto fine-tune a new model for a specific task, use the pre-trained model.    \n   \nit would be possible, for instance, to generate new recipes or to generate new product \ndescriptions by means of a model that has been pre-trained. it is also possible to fine-tuning a \nnew model to be used for a specific task based on a pre-trained model, for example sentiment \nanalysis or named entity recognition.   \n  \nreflective journal entries     \nweek 7    \ngoals, activities and outcomes  \nthere was no activity, goal, or outcome this week. we could also could not able to \ncommunicate with the company. this was a week of self-development for research and \nanalysis.   \n  \ndescription of any new knowledge, skills, or experiences gained during the week   i was able \nto build the ltsm and rnn models successfully. i also gained experience in using \nembeddings to convert words to vectors. this was a great learning experience for me, \nand i am excited to continue applying these techniques in the future.  \n  \nrewarding experience    \ni was very pleased with the results of ltsm and rnn work. seeing the cv project take \nshape was very rewarding, and i look forward to continuing my work on it.  \n  \ndifficult experience    \ngroup was not able to build the model and callum's hr consultants were not actively \ncreating scrums. the group was not sure what to do as should we develop model, or it will \nbe introduced so. it was a quiet week. i have started building ltsm and rnn models for \nlater sharing with team members and have looked for a solution to implementing keywords \nin sentences. i have also sent information to the team on how we can create a website \nusing flash models and integrate our model into it if required. as we approached week 8, \ni was nervous about not building the model and showing the university.  \n  \nnext week's tasks     \nthere was no task for next text week.  \n  \n   \nreflective journal entries     \nweek 8    \ngoals, activities and outcomes  \nwe arranged a meeting with callum to better understand the shuttle for this week. the \ndata structure and keyword extraction of the group revealed irregularities. in order to \nenhance cvs, our keyword extraction was not adequate. as for the words that callum will \nsend, he advised us to start from the beginning.  \n  \n  \ndescription of any new knowledge, skills, or experiences gained during the week   \ngroup members understood how critical the english language is to the system's \ndevelopment. it is imperative to analyse well and be mindful of the word structure to \neliminate adjectives from the verbs to extract the keywords.  \n  \nrewarding experience    \nit was rewarding to have a meeting with callum as he is an expert in the field. by \ncommunicating with him, the group was able to understand the system better and improve \ntheir skills.  \n  \ndifficult experience    \nthe group found it difficult to identify irregularities in the data structure and keyword \nextraction. however, they were able to overcome the challenge by communicating and \nworking together.  \n  \nnext week's tasks     \nthe same task should be assigned to us next week like week 4, however that time data \nwas provided by calum. a frequency analysis method should once again be used to \ndetermine the skill required for the task and feed that information into the training module. \nafter determining what skills are required for the task, we can determine how to train for it \nthe most effective.   \n  \n  \nreflective journal entries     \nweek 9  \ngoals, activities and outcome  \nto address the challenge of cv writing, we have done a lot of individual research and b \nbrainstorming. our group understood the structure of how to extract the keywords but was \nunable to find them in the data. we also struggled how the shape of the data. i suggested \nto the group also work with the text generation algorithms, so i sent them the structure of \nthe rnn model.   \n  \ndescription of any new knowledge, skills, or experiences gained during the week    \ngroup members were able to improve their skills by doing independent research. \nfurthermore, they were also able to communicate better and work as a team to overcome \nthe challenge of cv writing.  \n  \nrewarding experience    \nit was rewarding to find solutions to a challenging task. by working together, the group was \nable to achieve more and learn from each other.  \n  \ndifficult experience    \nbeing an intern, we thought it would be great to get advice and show the way how to do. \nwe worked mostly alone on this project. although callum was always there for us, i knew \nwe had to shape this project over time as data scientists. nobody showed us how to build \nthat system. being aware of that, and accepting it, since we already have the education \nand expertise in that area.   \n  \n  \nnext week's tasks     \nthere was no task assignment for next week  \n  \n  \nreflective journal entries     \nweek 10  \ngoals, activities and outcomes   \nthe goal for this week was to research and write about techniques for enhancing cv performance. \ni spent time reading about and researching popular techniques such as data augmentation, transfer \nlearning, and model assembling. i also experimented with applying these techniques to the cv \nproject.  \n  \nfor our cv enhancement project, i called our group together to show them how gpt-3 can work \nand how private data can be created. we may not need the list or cvs file once the private data \nhas been collected by gpt-3.  gpt-3 could handle all of that, in my opinion. i was worrying that \nmight not callum's thinking. however, sometimes you have to take a risk in order to succeed also \nwe had only 2 weeks left, there must be something to show.  \n  \nfirst, i organized a meeting with a commonwealth bank full stack developer to get some \nadvice about how to build the system i had in mind. in spite of his approach, he could not \nprovide advice due to ml modelling something outside of his expertise.  \n  \nsecondly, i decided to ask professor amin for some advice regarding the structure of the cv enhancement \nproject. professor responded with a leading researcher in the area of automating the recruitment process. \nthat study shaped our project for the better and was a great help to us.  \n  \nconsequently, we developed the system in collaboration with avinash, a chatbot-based sms \nservice that allows users to talk and write resumes, called ivi. ivi uses a decision tree model, where \nnodes can be built in a prompt. callum, however, was not happy with the idea of ivi, so we needed \nto build a new system.  \n  \ndescription of any new knowledge, skills, or experiences gained during the week    \nopen source ai refers to artificial intelligence technology that is made available to the public for use \nand modification. this term usually applies to ai software that is released under an open source \nlicense, which allows users to freely access and modify the source code.   \n  \ntwiligo is a cloud-based messaging platform that enables businesses to communicate with \ntheir customers through the use of chatbots and other messaging applications. it allows \nbusinesses to create, manage, and deploy chatbots across a variety of messaging applications, \nincluding facebook messenger, skype, whatsapp, and twitter.   \n  \nrender is a web-based design platform that enables designers and businesses to create, share, \nand manage their own custom websites and online stores. with render.com, users can create \nprofessional-grade websites in minutes, without any prior coding or design experience. \nrender.com also offers a wide range of built-in features and tools, including ecommerce \ncapabilities, seo optimization, social media integration, and more.  \n  \nrewarding experience    \ni was also very pleased with the quality of the write-up that i produced this week. overall, i was very \nhappy with the progress that i have made on this project.  \n  \ndifficult experience   \nthe most difficult experience this week was debugging the gpt-3 code. i had some trouble \ngetting the code to work properly, but i was eventually able to resolve the issue.   \n  \nnext week's tasks     \nstudy and practice how to use the new model. begin creating a data visualization of the model. refine \nthe data visualization.  \n  \n  \n  \nreflective journal entries     \nweek 11  \ngoals, activities and outcomes  \nthere was a meeting that callum arranged to learn how to build the system. to implement the \ndecision tree model, he identified the action verbs and explained how the past tense language \nshould be described. he also described how to remove biased words. additionally, he facilitates a \ngap workshop where a data science team experiences real-world employment scenario.    \n  \n  \ndescription of any new knowledge, skills, or experiences gained during the week   this \nweek, i gained a better understanding of how to enhance cv performance. i also gained \nexperience in applying these techniques to a real-world project. this was a great learning \nexperience for me, and i am excited to continue applying these techniques in the future.   \n  \nrewarding experience    \ni was very pleased with the results of this week's work. it was very rewarding to see the cv \nproject go live, and i am excited to continue working on it in the future.  \n  \ndifficult experience    \none of our group members identified himself as a project maker throughout the project. that was \na difficult experience for me and for the team. because all our team was working together.  \n  \nnext week's tasks     \npresentation of a cv enhancement model.  \n   \n  \nreflective journal entries     \nweek 12  \ngoals, activities and outcomes  \nthe data science team met again for brainstorming, and we divided the tasks into four to maximize \nthe project structure. i worked with avinash on tasks 2 and 3. it was a huge challenge in a short \nperiod of time.   \n  \nin this project, we examined the possibility of establishing a relationship between position and \nskill. we specifically looked at the following positions: data analyst, data engineer, and business \nanalyst. this list of data has been systematically gathered manually. using the website seek, we \nfound the roles needed for the project and parsed the entire job requirement and responsibilities \ndescription into a csv file. the data consists of 91 role requirements/responsibilities and is \norganized into 7 columns.in order to extract information from the unprocessed data that we used, \nwe needed to preprocess it. here are the steps we took:  \n  \n• \nlowercase all text  \n• \nremove all tabs, spaces  \n• \nremove all numbers  \n• \nremove nltk's defined stop words  \n• \nlemmatize text  \n  \nthe skill-extraction problem was to be transformed into a classification problem. after that, we \nextracted the key attributes for each classification. features that were crucial represented the \nkeywords that would indicate will apply to a class. callum requested that our team use the decision \ntree algorithm for this project, and we got 78 percent accuracy. we can improve our model by \n",
    "page": null,
    "goal": "Reflective journal Entities",
    "children": [
        {
            "id": "1.1",
            "name": "week 4",
            "nodeType": "title",
            "text": "week 4",
            "page": null,
            "goal": "week 4",
            "children": []
        },
        {
            "id": "1.2",
            "name": "week 4 goals,",
            "nodeType": "paragraph",
            "text": "week 4     \ngoals, activities and outcomes     \nwe examined the relationship between experience and salary rate this week. as a result of the \nfact that we had to analyse our data to determine the proper relationship between years of \nexperience and rate factor, we were under considerable pressure. to improve the analysis, we \nasked our university lecturer to use the most efficient method. despite our desire to utilize \nspss, we were concerned that our data was not sufficiently clean for testing. upon analysing \nour data, we found that there was a strong correlation between years of experience and salary \nrate. for example, an individual with more experience will earn a higher salary. due to \nunclearly of the foreseen model, we were unable to meet the target for the week.     \n    \ndescription of any new knowledge, skills, or experiences gained during the week:     \nwe were able to gain a lot of experience during the week because of the nltk library. the \nopportunity to work with such a large and well-organized library was a great experience for \nme. i feel like i learned a great deal about natural language processing this week. i'm looking \nforward to learning more about it in the future. i've also learned how to create custom functions \nto assist with these tasks.    \nfurthermore, i have learned how to create custom corpora and wordlists to help me accomplish \nthese tasks. in addition to that, i have gained a better understanding of how to use python for \ntext mining.    \n    \nin high-pressure situations, teamwork is essential to get the job done efficiently and effectively. \nwhen everyone is working together towards a common goal, it is easier to problem-solve and \ncome up with creative solutions. additionally, teamwork can help to reduce stress levels and \nbuild morale. when people are working together under pressure, it is important for them to be \nable to rely on each other. this means that team members need to be able to trust each other \nand know that they can count on each other to do their part. it is also important for team \nmembers to be able to communicate effectively with each other. this way, they can coordinate \ntheir efforts and make sure that everyone is on the same page.    \n    \nrewarding experience     \nthere is nothing more rewarding than being able to work together as a team under pressure and \ncoming out victorious. a sense of camaraderie and accomplishment that comes with \novercoming a difficult challenge together is unmatched by any other. when you are working \nas a team under pressure, it is essential for everyone to be on the same page and focus on the \nsame goal. there can be no room for error when lives are on the line. for this type of work \nenvironment to be successful, trust, communication, and respect must be present. if a team is \nable to work efficiently under pressure and come together as a unit, this is a truly rewarding \nexperience.    \n    \ndifficult experience    \ngetting started on a task is easy but it is not always easy to complete it. this is especially true \nif the task in question is challenging. in the case of a difficult task, it can be hard to find the \nmotivation to go on with it. it can be easy to get discouraged and give up on it. whenever i \nhave a difficult task that is hard to complete, it is important to remember that i am not alone in \nmy struggles. it is common for people to have difficulty completing difficult tasks. finding a \nway to keep going is the key to completing difficult tasks. among the ways to do this is to \nbreak the task down into smaller, more manageable pieces.     \n    \nnext week's tasks     \nwe should be working on the same task next week as we did this week. we ought to, once \nagain, use the frequency analysis method for analysing the skill required for the task and feed \nthat data into the training module.  having done this, we can understand what skills are needed \nfor the task and how to train for it in the best way possible. moreover, we have to learn about \nthe philosophy of servant leadership.     \n     \nreflective journal entries",
            "page": null,
            "goal": "week 4     \ngoals, activities and outcomes     \nwe examined the relationship between experience and salary rate this week. as a result of the \nfact that we had to analyse our data to determine the proper relationship between years of \nexperience and rate factor, we were under considerable pressure. to improve the analysis, we \nasked our university lecturer to use the most efficient method. despite our desire to utilize \nspss, we were concerned that our data was not sufficiently clean for testing. upon analysing \nour data, we found that there was a strong correlation between years of experience and salary \nrate. for example, an individual with more experience will earn a higher salary. due to \nunclearly of the foreseen model, we were unable to meet the target for the week.     \n    \ndescription of any new knowledge, skills, or experiences gained during the week:     \nwe were able to gain a lot of experience during the week because of the nltk library. the \nopportunity to work with such a large and well-organized library was a great experience for \nme. i feel like i learned a great deal about natural language processing this week. i'm looking \nforward to learning more about it in the future. i've also learned how to create custom functions \nto assist with these tasks.    \nfurthermore, i have learned how to create custom corpora and wordlists to help me accomplish \nthese tasks. in addition to that, i have gained a better understanding of how to use python for \ntext mining.    \n    \nin high-pressure situations, teamwork is essential to get the job done efficiently and effectively. \nwhen everyone is working together towards a common goal, it is easier to problem-solve and \ncome up with creative solutions. additionally, teamwork can help to reduce stress levels and \nbuild morale. when people are working together under pressure, it is important for them to be \nable to rely on each other. this means that team members need to be able to trust each other \nand know that they can count on each other to do their part. it is also important for team \nmembers to be able to communicate effectively with each other. this way, they can coordinate \ntheir efforts and make sure that everyone is on the same page.    \n    \nrewarding experience     \nthere is nothing more rewarding than being able to work together as a team under pressure and \ncoming out victorious. a sense of camaraderie and accomplishment that comes with \novercoming a difficult challenge together is unmatched by any other. when you are working \nas a team under pressure, it is essential for everyone to be on the same page and focus on the \nsame goal. there can be no room for error when lives are on the line. for this type of work \nenvironment to be successful, trust, communication, and respect must be present. if a team is \nable to work efficiently under pressure and come together as a unit, this is a truly rewarding \nexperience.    \n    \ndifficult experience    \ngetting started on a task is easy but it is not always easy to complete it. this is especially true \nif the task in question is challenging. in the case of a difficult task, it can be hard to find the \nmotivation to go on with it. it can be easy to get discouraged and give up on it. whenever i \nhave a difficult task that is hard to complete, it is important to remember that i am not alone in \nmy struggles. it is common for people to have difficulty completing difficult tasks. finding a \nway to keep going is the key to completing difficult tasks. among the ways to do this is to \nbreak the task down into smaller, more manageable pieces.     \n    \nnext week's tasks     \nwe should be working on the same task next week as we did this week. we ought to, once \nagain, use the frequency analysis method for analysing the skill required for the task and feed \nthat data into the training module.  having done this, we can understand what skills are needed \nfor the task and how to train for it in the best way possible. moreover, we have to learn about \nthe philosophy of servant leadership.     \n     \nreflective journal entries",
            "children": []
        },
        {
            "id": "1.3",
            "name": "week 5",
            "nodeType": "title",
            "text": "week 5",
            "page": null,
            "goal": "week 5",
            "children": []
        },
        {
            "id": "1.4",
            "name": "week 5 goals,",
            "nodeType": "paragraph",
            "text": "week 5     \ngoals, activities and outcomes    \nthe task we were working on this week is the same task we were working on last week. in \norder to analyse the skill required for the task and feed that data into the training module, we \nonce again used the frequency analysis method. by doing this, we were able to figure out what \nskills were needed for the data and how to train the data to achieve the best results. as part of \nthis week's study, we examined how experience influences salary rates. as a result of analysing \nour data, we were able to determine a possible relationship between years of experience and \nrate factor.    \n    \nas a second step to the frequency analysis, we cleaned up the data, filled in missing values, \nremoved stop words and non-alphabetic characters using nltk, and defined a function. the \nfrequency of words in requirements for both business analysts and data engineers, as well as \nthe requirements for data analysts, was also found.    \n    \nto better understand the resume skills, callum hired hr consultants with experience in the \nbusiness sector. thus, she asked me to be the scrum master for the project next week. i \ncompleted my scrum sprint 3 and forwarded it to jira.    \n     \ndescription of any new knowledge, skills, or experiences gained during the week    \ni learned how to use python for text mining. i learned how to create custom functions to help \nme with these tasks. i've also learned how to create custom corpora and word lists to help me \naccomplish these tasks. on top of that, i have a better understanding of how to use python for \ntext mining.    \n    \na new skill that i learn was servant leadership, which is a leadership philosophy in which the \nleader's primary motivation is to serve others. it can be accomplished in a number of ways, \nsuch as by providing support and guidance to team members, or by taking on tasks and \nresponsibilities that would otherwise fall to others. servant leaders are not motivated by power \nor prestige, but by a desire to help others fulfill their potential. they are servant hearted. the \nperson he or she leads has a genuine concern for the people he or she leads.     \n     \nrewarding experience    \nthe experience of working as a scrum master was very rewarding. we learned that it was an \nexcellent way to help teams work together more effectively and efficiently, and it was also a \ngreat way to get a better understanding of the inner workings of a team. as mentioned earlier, \nscrum masters can also be a great asset to a company since they can assist in improving \ncommunication and collaboration between a company's teams.    \n     \ndifficult experience    \ni was the scrum master for my team and it was a difficult experience. i had to keep the team on \ntrack and make sure that everyone was doing their part. it was a lot of work and i had to be \nvery organized.    \n    \nnext week's tasks     \nthe task for next week was to suggest new keywords, and phrases based on skill frequency \nanalysis for gtp3.    \n    \nreflective journal entries",
            "page": null,
            "goal": "week 5     \ngoals, activities and outcomes    \nthe task we were working on this week is the same task we were working on last week. in \norder to analyse the skill required for the task and feed that data into the training module, we \nonce again used the frequency analysis method. by doing this, we were able to figure out what \nskills were needed for the data and how to train the data to achieve the best results. as part of \nthis week's study, we examined how experience influences salary rates. as a result of analysing \nour data, we were able to determine a possible relationship between years of experience and \nrate factor.    \n    \nas a second step to the frequency analysis, we cleaned up the data, filled in missing values, \nremoved stop words and non-alphabetic characters using nltk, and defined a function. the \nfrequency of words in requirements for both business analysts and data engineers, as well as \nthe requirements for data analysts, was also found.    \n    \nto better understand the resume skills, callum hired hr consultants with experience in the \nbusiness sector. thus, she asked me to be the scrum master for the project next week. i \ncompleted my scrum sprint 3 and forwarded it to jira.    \n     \ndescription of any new knowledge, skills, or experiences gained during the week    \ni learned how to use python for text mining. i learned how to create custom functions to help \nme with these tasks. i've also learned how to create custom corpora and word lists to help me \naccomplish these tasks. on top of that, i have a better understanding of how to use python for \ntext mining.    \n    \na new skill that i learn was servant leadership, which is a leadership philosophy in which the \nleader's primary motivation is to serve others. it can be accomplished in a number of ways, \nsuch as by providing support and guidance to team members, or by taking on tasks and \nresponsibilities that would otherwise fall to others. servant leaders are not motivated by power \nor prestige, but by a desire to help others fulfill their potential. they are servant hearted. the \nperson he or she leads has a genuine concern for the people he or she leads.     \n     \nrewarding experience    \nthe experience of working as a scrum master was very rewarding. we learned that it was an \nexcellent way to help teams work together more effectively and efficiently, and it was also a \ngreat way to get a better understanding of the inner workings of a team. as mentioned earlier, \nscrum masters can also be a great asset to a company since they can assist in improving \ncommunication and collaboration between a company's teams.    \n     \ndifficult experience    \ni was the scrum master for my team and it was a difficult experience. i had to keep the team on \ntrack and make sure that everyone was doing their part. it was a lot of work and i had to be \nvery organized.    \n    \nnext week's tasks     \nthe task for next week was to suggest new keywords, and phrases based on skill frequency \nanalysis for gtp3.    \n    \nreflective journal entries",
            "children": []
        },
        {
            "id": "1.5",
            "name": "week 6",
            "nodeType": "title",
            "text": "week 6",
            "page": null,
            "goal": "week 6",
            "children": []
        },
        {
            "id": "1.6",
            "name": "week 6 goals,",
            "nodeType": "paragraph",
            "text": "week 6     \ngoals, activities and outcomes    \ngoals are achieved by identifying the data, extracting the relevant roles, capturing the data, and \nconstructing a profile that can be used to build correlations between the data. once the contract \nroles have been defined, skillsets and requirements have been evaluated in the database to map \nthem to the contract opportunities. it would be helpful if you can provide me with a phrase \ninput, such as \"this is a test\" and a count of how many times the phrase appears in the text. my \ngoal is to see which phrase appears the most often out of a set of phrases. when i used the \nfrequency analysis function, it only counts the number of words, not the frequency of \noccurrence. if there is a way to search for a phrase and count how many times it appears in a \ndocument, i would greatly appreciate it. furthermore, callum suggested that we draw more \nplots to see how the re-queried and skill data outputs relate to one another.    \n    \ndescription of any new knowledge, skills, or experiences gained during the week   during \nthis week, i learned about gpt-3, a natural language processing platform that enables \ndevelopers to train and deploy ai models. the application provides a wide range of features, \nincluding text classification, entity recognition, and sentiment analysis. gpt-3 allows \ndevelopers to build applications that are capable of understanding and responding to natural \nlanguage inputs. gtp 3 is a toolkit that allows us to develop, test, and deploy chatbots and \nother applications that can be used in conversations. the tool includes a number of features, \nincluding natural language processing, dialogue management, and a chatbot development tool.    \n    \nrewarding experience    \nit was a great experience to use the gpt-3 open-source ai model. i was able to train the model \non a variety of data sets and achieve good results. the model was also able to generalize well \nto new data sets. i found the gpt3 open-ai to be a very rewarding experience. i was able to get \na lot of insights into how the system works and how it can be used to improve my own ai \nprojects. i would recommend this to anyone who is looking to get started with open-ai or to \nimprove their own ai projects.    \n    \ndifficult experience    \nthe gpt-3 open-ai model was difficult for me to use for a number of reasons. in the \nbeginning, the model is very large and requires a great deal of computational resources to run. \nin addition, there is insufficient documentation, and it is unclear how to use the model. last \nbut not least, the model is constantly changing, so it is difficult to stay on top of it.    \n    \nnext week's tasks     \nthe task for next week is to create a generative pre-trained transformer. thus, we intend to use \na pretrained model to generate a rewritten text. to achieve this, we can use the following \napproach:     \n   \n• \nto create customized texts from scratch, use the pre-trained model.     \n• \nto fine-tune a new model for a specific task, use the pre-trained model.    \n   \nit would be possible, for instance, to generate new recipes or to generate new product \ndescriptions by means of a model that has been pre-trained. it is also possible to fine-tuning a \nnew model to be used for a specific task based on a pre-trained model, for example sentiment \nanalysis or named entity recognition.   \n  \nreflective journal entries",
            "page": null,
            "goal": "week 6     \ngoals, activities and outcomes    \ngoals are achieved by identifying the data, extracting the relevant roles, capturing the data, and \nconstructing a profile that can be used to build correlations between the data. once the contract \nroles have been defined, skillsets and requirements have been evaluated in the database to map \nthem to the contract opportunities. it would be helpful if you can provide me with a phrase \ninput, such as \"this is a test\" and a count of how many times the phrase appears in the text. my \ngoal is to see which phrase appears the most often out of a set of phrases. when i used the \nfrequency analysis function, it only counts the number of words, not the frequency of \noccurrence. if there is a way to search for a phrase and count how many times it appears in a \ndocument, i would greatly appreciate it. furthermore, callum suggested that we draw more \nplots to see how the re-queried and skill data outputs relate to one another.    \n    \ndescription of any new knowledge, skills, or experiences gained during the week   during \nthis week, i learned about gpt-3, a natural language processing platform that enables \ndevelopers to train and deploy ai models. the application provides a wide range of features, \nincluding text classification, entity recognition, and sentiment analysis. gpt-3 allows \ndevelopers to build applications that are capable of understanding and responding to natural \nlanguage inputs. gtp 3 is a toolkit that allows us to develop, test, and deploy chatbots and \nother applications that can be used in conversations. the tool includes a number of features, \nincluding natural language processing, dialogue management, and a chatbot development tool.    \n    \nrewarding experience    \nit was a great experience to use the gpt-3 open-source ai model. i was able to train the model \non a variety of data sets and achieve good results. the model was also able to generalize well \nto new data sets. i found the gpt3 open-ai to be a very rewarding experience. i was able to get \na lot of insights into how the system works and how it can be used to improve my own ai \nprojects. i would recommend this to anyone who is looking to get started with open-ai or to \nimprove their own ai projects.    \n    \ndifficult experience    \nthe gpt-3 open-ai model was difficult for me to use for a number of reasons. in the \nbeginning, the model is very large and requires a great deal of computational resources to run. \nin addition, there is insufficient documentation, and it is unclear how to use the model. last \nbut not least, the model is constantly changing, so it is difficult to stay on top of it.    \n    \nnext week's tasks     \nthe task for next week is to create a generative pre-trained transformer. thus, we intend to use \na pretrained model to generate a rewritten text. to achieve this, we can use the following \napproach:     \n   \n• \nto create customized texts from scratch, use the pre-trained model.     \n• \nto fine-tune a new model for a specific task, use the pre-trained model.    \n   \nit would be possible, for instance, to generate new recipes or to generate new product \ndescriptions by means of a model that has been pre-trained. it is also possible to fine-tuning a \nnew model to be used for a specific task based on a pre-trained model, for example sentiment \nanalysis or named entity recognition.   \n  \nreflective journal entries",
            "children": []
        },
        {
            "id": "1.7",
            "name": "week 7",
            "nodeType": "title",
            "text": "week 7",
            "page": null,
            "goal": "week 7",
            "children": []
        },
        {
            "id": "1.8",
            "name": "week 7 goals,",
            "nodeType": "paragraph",
            "text": "week 7    \ngoals, activities and outcomes  \nthere was no activity, goal, or outcome this week. we could also could not able to \ncommunicate with the company. this was a week of self-development for research and \nanalysis.   \n  \ndescription of any new knowledge, skills, or experiences gained during the week   i was able \nto build the ltsm and rnn models successfully. i also gained experience in using \nembeddings to convert words to vectors. this was a great learning experience for me, \nand i am excited to continue applying these techniques in the future.  \n  \nrewarding experience    \ni was very pleased with the results of ltsm and rnn work. seeing the cv project take \nshape was very rewarding, and i look forward to continuing my work on it.  \n  \ndifficult experience    \ngroup was not able to build the model and callum's hr consultants were not actively \ncreating scrums. the group was not sure what to do as should we develop model, or it will \nbe introduced so. it was a quiet week. i have started building ltsm and rnn models for \nlater sharing with team members and have looked for a solution to implementing keywords \nin sentences. i have also sent information to the team on how we can create a website \nusing flash models and integrate our model into it if required. as we approached",
            "page": null,
            "goal": "week 7    \ngoals, activities and outcomes  \nthere was no activity, goal, or outcome this week. we could also could not able to \ncommunicate with the company. this was a week of self-development for research and \nanalysis.   \n  \ndescription of any new knowledge, skills, or experiences gained during the week   i was able \nto build the ltsm and rnn models successfully. i also gained experience in using \nembeddings to convert words to vectors. this was a great learning experience for me, \nand i am excited to continue applying these techniques in the future.  \n  \nrewarding experience    \ni was very pleased with the results of ltsm and rnn work. seeing the cv project take \nshape was very rewarding, and i look forward to continuing my work on it.  \n  \ndifficult experience    \ngroup was not able to build the model and callum's hr consultants were not actively \ncreating scrums. the group was not sure what to do as should we develop model, or it will \nbe introduced so. it was a quiet week. i have started building ltsm and rnn models for \nlater sharing with team members and have looked for a solution to implementing keywords \nin sentences. i have also sent information to the team on how we can create a website \nusing flash models and integrate our model into it if required. as we approached",
            "children": []
        },
        {
            "id": "1.9",
            "name": "week 8",
            "nodeType": "title",
            "text": "week 8",
            "page": null,
            "goal": "week 8",
            "children": []
        },
        {
            "id": "1.10",
            "name": "week 8, i",
            "nodeType": "paragraph",
            "text": "week 8, \ni was nervous about not building the model and showing the university.  \n  \nnext week's tasks     \nthere was no task for next text week.  \n  \n   \nreflective journal entries     \nweek 8    \ngoals, activities and outcomes  \nwe arranged a meeting with callum to better understand the shuttle for this week. the \ndata structure and keyword extraction of the group revealed irregularities. in order to \nenhance cvs, our keyword extraction was not adequate. as for the words that callum will \nsend, he advised us to start from the beginning.  \n  \n  \ndescription of any new knowledge, skills, or experiences gained during the week   \ngroup members understood how critical the english language is to the system's \ndevelopment. it is imperative to analyse well and be mindful of the word structure to \neliminate adjectives from the verbs to extract the keywords.  \n  \nrewarding experience    \nit was rewarding to have a meeting with callum as he is an expert in the field. by \ncommunicating with him, the group was able to understand the system better and improve \ntheir skills.  \n  \ndifficult experience    \nthe group found it difficult to identify irregularities in the data structure and keyword \nextraction. however, they were able to overcome the challenge by communicating and \nworking together.  \n  \nnext week's tasks     \nthe same task should be assigned to us next week like week 4, however that time data \nwas provided by calum. a frequency analysis method should once again be used to \ndetermine the skill required for the task and feed that information into the training module. \nafter determining what skills are required for the task, we can determine how to train for it \nthe most effective.   \n  \n  \nreflective journal entries",
            "page": null,
            "goal": "week 8, \ni was nervous about not building the model and showing the university.  \n  \nnext week's tasks     \nthere was no task for next text week.  \n  \n   \nreflective journal entries     \nweek 8    \ngoals, activities and outcomes  \nwe arranged a meeting with callum to better understand the shuttle for this week. the \ndata structure and keyword extraction of the group revealed irregularities. in order to \nenhance cvs, our keyword extraction was not adequate. as for the words that callum will \nsend, he advised us to start from the beginning.  \n  \n  \ndescription of any new knowledge, skills, or experiences gained during the week   \ngroup members understood how critical the english language is to the system's \ndevelopment. it is imperative to analyse well and be mindful of the word structure to \neliminate adjectives from the verbs to extract the keywords.  \n  \nrewarding experience    \nit was rewarding to have a meeting with callum as he is an expert in the field. by \ncommunicating with him, the group was able to understand the system better and improve \ntheir skills.  \n  \ndifficult experience    \nthe group found it difficult to identify irregularities in the data structure and keyword \nextraction. however, they were able to overcome the challenge by communicating and \nworking together.  \n  \nnext week's tasks     \nthe same task should be assigned to us next week like week 4, however that time data \nwas provided by calum. a frequency analysis method should once again be used to \ndetermine the skill required for the task and feed that information into the training module. \nafter determining what skills are required for the task, we can determine how to train for it \nthe most effective.   \n  \n  \nreflective journal entries",
            "children": []
        },
        {
            "id": "1.11",
            "name": "week 9",
            "nodeType": "title",
            "text": "week 9",
            "page": null,
            "goal": "week 9",
            "children": []
        },
        {
            "id": "1.12",
            "name": "week 9 goals,",
            "nodeType": "paragraph",
            "text": "week 9  \ngoals, activities and outcome  \nto address the challenge of cv writing, we have done a lot of individual research and b \nbrainstorming. our group understood the structure of how to extract the keywords but was \nunable to find them in the data. we also struggled how the shape of the data. i suggested \nto the group also work with the text generation algorithms, so i sent them the structure of \nthe rnn model.   \n  \ndescription of any new knowledge, skills, or experiences gained during the week    \ngroup members were able to improve their skills by doing independent research. \nfurthermore, they were also able to communicate better and work as a team to overcome \nthe challenge of cv writing.  \n  \nrewarding experience    \nit was rewarding to find solutions to a challenging task. by working together, the group was \nable to achieve more and learn from each other.  \n  \ndifficult experience    \nbeing an intern, we thought it would be great to get advice and show the way how to do. \nwe worked mostly alone on this project. although callum was always there for us, i knew \nwe had to shape this project over time as data scientists. nobody showed us how to build \nthat system. being aware of that, and accepting it, since we already have the education \nand expertise in that area.   \n  \n  \nnext week's tasks     \nthere was no task assignment for next week  \n  \n  \nreflective journal entries",
            "page": null,
            "goal": "week 9  \ngoals, activities and outcome  \nto address the challenge of cv writing, we have done a lot of individual research and b \nbrainstorming. our group understood the structure of how to extract the keywords but was \nunable to find them in the data. we also struggled how the shape of the data. i suggested \nto the group also work with the text generation algorithms, so i sent them the structure of \nthe rnn model.   \n  \ndescription of any new knowledge, skills, or experiences gained during the week    \ngroup members were able to improve their skills by doing independent research. \nfurthermore, they were also able to communicate better and work as a team to overcome \nthe challenge of cv writing.  \n  \nrewarding experience    \nit was rewarding to find solutions to a challenging task. by working together, the group was \nable to achieve more and learn from each other.  \n  \ndifficult experience    \nbeing an intern, we thought it would be great to get advice and show the way how to do. \nwe worked mostly alone on this project. although callum was always there for us, i knew \nwe had to shape this project over time as data scientists. nobody showed us how to build \nthat system. being aware of that, and accepting it, since we already have the education \nand expertise in that area.   \n  \n  \nnext week's tasks     \nthere was no task assignment for next week  \n  \n  \nreflective journal entries",
            "children": []
        },
        {
            "id": "1.13",
            "name": "week 10",
            "nodeType": "title",
            "text": "week 10",
            "page": null,
            "goal": "week 10",
            "children": []
        },
        {
            "id": "1.14",
            "name": "week 10 goals,",
            "nodeType": "paragraph",
            "text": "week 10  \ngoals, activities and outcomes   \nthe goal for this week was to research and write about techniques for enhancing cv performance. \ni spent time reading about and researching popular techniques such as data augmentation, transfer \nlearning, and model assembling. i also experimented with applying these techniques to the cv \nproject.  \n  \nfor our cv enhancement project, i called our group together to show them how gpt-3 can work \nand how private data can be created. we may not need the list or cvs file once the private data \nhas been collected by gpt-3.  gpt-3 could handle all of that, in my opinion. i was worrying that \nmight not callum's thinking. however, sometimes you have to take a risk in order to succeed also \nwe had only 2 weeks left, there must be something to show.  \n  \nfirst, i organized a meeting with a commonwealth bank full stack developer to get some \nadvice about how to build the system i had in mind. in spite of his approach, he could not \nprovide advice due to ml modelling something outside of his expertise.  \n  \nsecondly, i decided to ask professor amin for some advice regarding the structure of the cv enhancement \nproject. professor responded with a leading researcher in the area of automating the recruitment process. \nthat study shaped our project for the better and was a great help to us.  \n  \nconsequently, we developed the system in collaboration with avinash, a chatbot-based sms \nservice that allows users to talk and write resumes, called ivi. ivi uses a decision tree model, where \nnodes can be built in a prompt. callum, however, was not happy with the idea of ivi, so we needed \nto build a new system.  \n  \ndescription of any new knowledge, skills, or experiences gained during the week    \nopen source ai refers to artificial intelligence technology that is made available to the public for use \nand modification. this term usually applies to ai software that is released under an open source \nlicense, which allows users to freely access and modify the source code.   \n  \ntwiligo is a cloud-based messaging platform that enables businesses to communicate with \ntheir customers through the use of chatbots and other messaging applications. it allows \nbusinesses to create, manage, and deploy chatbots across a variety of messaging applications, \nincluding facebook messenger, skype, whatsapp, and twitter.   \n  \nrender is a web-based design platform that enables designers and businesses to create, share, \nand manage their own custom websites and online stores. with render.com, users can create \nprofessional-grade websites in minutes, without any prior coding or design experience. \nrender.com also offers a wide range of built-in features and tools, including ecommerce \ncapabilities, seo optimization, social media integration, and more.  \n  \nrewarding experience    \ni was also very pleased with the quality of the write-up that i produced this week. overall, i was very \nhappy with the progress that i have made on this project.  \n  \ndifficult experience   \nthe most difficult experience this week was debugging the gpt-3 code. i had some trouble \ngetting the code to work properly, but i was eventually able to resolve the issue.   \n  \nnext week's tasks     \nstudy and practice how to use the new model. begin creating a data visualization of the model. refine \nthe data visualization.  \n  \n  \n  \nreflective journal entries",
            "page": null,
            "goal": "week 10  \ngoals, activities and outcomes   \nthe goal for this week was to research and write about techniques for enhancing cv performance. \ni spent time reading about and researching popular techniques such as data augmentation, transfer \nlearning, and model assembling. i also experimented with applying these techniques to the cv \nproject.  \n  \nfor our cv enhancement project, i called our group together to show them how gpt-3 can work \nand how private data can be created. we may not need the list or cvs file once the private data \nhas been collected by gpt-3.  gpt-3 could handle all of that, in my opinion. i was worrying that \nmight not callum's thinking. however, sometimes you have to take a risk in order to succeed also \nwe had only 2 weeks left, there must be something to show.  \n  \nfirst, i organized a meeting with a commonwealth bank full stack developer to get some \nadvice about how to build the system i had in mind. in spite of his approach, he could not \nprovide advice due to ml modelling something outside of his expertise.  \n  \nsecondly, i decided to ask professor amin for some advice regarding the structure of the cv enhancement \nproject. professor responded with a leading researcher in the area of automating the recruitment process. \nthat study shaped our project for the better and was a great help to us.  \n  \nconsequently, we developed the system in collaboration with avinash, a chatbot-based sms \nservice that allows users to talk and write resumes, called ivi. ivi uses a decision tree model, where \nnodes can be built in a prompt. callum, however, was not happy with the idea of ivi, so we needed \nto build a new system.  \n  \ndescription of any new knowledge, skills, or experiences gained during the week    \nopen source ai refers to artificial intelligence technology that is made available to the public for use \nand modification. this term usually applies to ai software that is released under an open source \nlicense, which allows users to freely access and modify the source code.   \n  \ntwiligo is a cloud-based messaging platform that enables businesses to communicate with \ntheir customers through the use of chatbots and other messaging applications. it allows \nbusinesses to create, manage, and deploy chatbots across a variety of messaging applications, \nincluding facebook messenger, skype, whatsapp, and twitter.   \n  \nrender is a web-based design platform that enables designers and businesses to create, share, \nand manage their own custom websites and online stores. with render.com, users can create \nprofessional-grade websites in minutes, without any prior coding or design experience. \nrender.com also offers a wide range of built-in features and tools, including ecommerce \ncapabilities, seo optimization, social media integration, and more.  \n  \nrewarding experience    \ni was also very pleased with the quality of the write-up that i produced this week. overall, i was very \nhappy with the progress that i have made on this project.  \n  \ndifficult experience   \nthe most difficult experience this week was debugging the gpt-3 code. i had some trouble \ngetting the code to work properly, but i was eventually able to resolve the issue.   \n  \nnext week's tasks     \nstudy and practice how to use the new model. begin creating a data visualization of the model. refine \nthe data visualization.  \n  \n  \n  \nreflective journal entries",
            "children": []
        },
        {
            "id": "1.15",
            "name": "week 11",
            "nodeType": "title",
            "text": "week 11",
            "page": null,
            "goal": "week 11",
            "children": []
        },
        {
            "id": "1.16",
            "name": "week 11 goals,",
            "nodeType": "paragraph",
            "text": "week 11  \ngoals, activities and outcomes  \nthere was a meeting that callum arranged to learn how to build the system. to implement the \ndecision tree model, he identified the action verbs and explained how the past tense language \nshould be described. he also described how to remove biased words. additionally, he facilitates a \ngap workshop where a data science team experiences real-world employment scenario.    \n  \n  \ndescription of any new knowledge, skills, or experiences gained during the week   this \nweek, i gained a better understanding of how to enhance cv performance. i also gained \nexperience in applying these techniques to a real-world project. this was a great learning \nexperience for me, and i am excited to continue applying these techniques in the future.   \n  \nrewarding experience    \ni was very pleased with the results of this week's work. it was very rewarding to see the cv \nproject go live, and i am excited to continue working on it in the future.  \n  \ndifficult experience    \none of our group members identified himself as a project maker throughout the project. that was \na difficult experience for me and for the team. because all our team was working together.  \n  \nnext week's tasks     \npresentation of a cv enhancement model.  \n   \n  \nreflective journal entries",
            "page": null,
            "goal": "week 11  \ngoals, activities and outcomes  \nthere was a meeting that callum arranged to learn how to build the system. to implement the \ndecision tree model, he identified the action verbs and explained how the past tense language \nshould be described. he also described how to remove biased words. additionally, he facilitates a \ngap workshop where a data science team experiences real-world employment scenario.    \n  \n  \ndescription of any new knowledge, skills, or experiences gained during the week   this \nweek, i gained a better understanding of how to enhance cv performance. i also gained \nexperience in applying these techniques to a real-world project. this was a great learning \nexperience for me, and i am excited to continue applying these techniques in the future.   \n  \nrewarding experience    \ni was very pleased with the results of this week's work. it was very rewarding to see the cv \nproject go live, and i am excited to continue working on it in the future.  \n  \ndifficult experience    \none of our group members identified himself as a project maker throughout the project. that was \na difficult experience for me and for the team. because all our team was working together.  \n  \nnext week's tasks     \npresentation of a cv enhancement model.  \n   \n  \nreflective journal entries",
            "children": []
        },
        {
            "id": "1.17",
            "name": "week 12",
            "nodeType": "title",
            "text": "week 12",
            "page": null,
            "goal": "week 12",
            "children": []
        },
        {
            "id": "1.18",
            "name": "week 12 goals,",
            "nodeType": "paragraph",
            "text": "week 12  \ngoals, activities and outcomes  \nthe data science team met again for brainstorming, and we divided the tasks into four to maximize \nthe project structure. i worked with avinash on tasks 2 and 3. it was a huge challenge in a short \nperiod of time.   \n  \nin this project, we examined the possibility of establishing a relationship between position and \nskill. we specifically looked at the following positions: data analyst, data engineer, and business \nanalyst. this list of data has been systematically gathered manually. using the website seek, we \nfound the roles needed for the project and parsed the entire job requirement and responsibilities \ndescription into a csv file. the data consists of 91 role requirements/responsibilities and is \norganized into 7 columns.in order to extract information from the unprocessed data that we used, \nwe needed to preprocess it. here are the steps we took:  \n  \n• \nlowercase all text  \n• \nremove all tabs, spaces  \n• \nremove all numbers  \n• \nremove nltk's defined stop words  \n• \nlemmatize text  \n  \nthe skill-extraction problem was to be transformed into a classification problem. after that, we \nextracted the key attributes for each classification. features that were crucial represented the \nkeywords that would indicate will apply to a class. callum requested that our team use the decision \ntree algorithm for this project, and we got 78 percent accuracy. we can improve our model by",
            "page": null,
            "goal": "week 12  \ngoals, activities and outcomes  \nthe data science team met again for brainstorming, and we divided the tasks into four to maximize \nthe project structure. i worked with avinash on tasks 2 and 3. it was a huge challenge in a short \nperiod of time.   \n  \nin this project, we examined the possibility of establishing a relationship between position and \nskill. we specifically looked at the following positions: data analyst, data engineer, and business \nanalyst. this list of data has been systematically gathered manually. using the website seek, we \nfound the roles needed for the project and parsed the entire job requirement and responsibilities \ndescription into a csv file. the data consists of 91 role requirements/responsibilities and is \norganized into 7 columns.in order to extract information from the unprocessed data that we used, \nwe needed to preprocess it. here are the steps we took:  \n  \n• \nlowercase all text  \n• \nremove all tabs, spaces  \n• \nremove all numbers  \n• \nremove nltk's defined stop words  \n• \nlemmatize text  \n  \nthe skill-extraction problem was to be transformed into a classification problem. after that, we \nextracted the key attributes for each classification. features that were crucial represented the \nkeywords that would indicate will apply to a class. callum requested that our team use the decision \ntree algorithm for this project, and we got 78 percent accuracy. we can improve our model by",
            "children": []
        }
    ]
}