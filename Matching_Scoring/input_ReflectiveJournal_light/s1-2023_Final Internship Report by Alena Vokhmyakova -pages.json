{
    "id": "1",
    "name": "Reflective journal Entities",
    "nodeType": "section",
    "text": "week 1  \n \nthe first week of the internship was a kick of session and an introduction into an \norganization with the ceo/supervisor stephen elbourn and project manager masoud. the \nsession was held on a thursday and the focus of the session was on the introduction into \nthe organizational group structure and a brief introduction into the project. it was discussed \nthat our team consisting of 7 team members including myself will have 3 project sessions \nper week where: \n- session 1 will focus on task allocation and project discussion \n- session 2 will focus on q&a \n- session 3 will be a presentation on the findings and research completed during the week.  \nat the end of this week, i have confirmed my work arrangements and attendance with my \nsupervisor stephen elbourn taking into consideration the participation in the data analyst \ntoolkit course.  \n \nthe project which we’ll be working on is the ai enabled exam marking. the purpose of the \nproject is to develop an efficient model which will help teachers and instructors in exam \n \n17 \nmarking. an internship proposal has been prepared and submitted on friday outlining the \ndetails of the project, learning objectives and an internship plan.  \n \nmoreover, during this week i was given access to the itic learning portal for the data \nscience short course beginning from week 3 and it will be on every tuesday and thursday \nfrom 9:00 am till 12:00pm until the 30th of march. this course will focus on four modules: \npython, sql, tableau and power bi.  \n \nin addition, closer to the end of the week i was provided with various documents, those \ninclude: \n- \n a gantt chart for the ai enabled exam marking project outlining the project \nschedule for the upcoming weeks. the gantt chart provided by stephen elbourn \nassisted me in the preparation of the gantt chart for the internship proposal. \n- \ncompany’s policies which i had to read to ensure that i am aware and understand all \nthe policies. \n- \nslides to an old project on ai enabled exam marking to help us understand the idea \nof the project.  \nthus, during this week there was no task allocation as the purpose of this week was to \nintroduce us to the organization and the project.  \n \nweek 2 \n \nthe focus of the second week of the internship was based on the scope and product \narchitecture of the automatic exam marking project. the project manager masoud \ndiscussed the importance of project planning, the 10 phases of the project, research into \nexisting tools, technologies, and available datasets. \n \nduring this week we were requested to complete a capability matrix outlining our \nknowledge and experience in the areas like software, data analyst, data science and project \nmanagement. the purpose of this capability matrix was to help stephen (supervisor) and \nmasoud (project manager) in allocation of the future project tasks based on our knowledge \nand experience.  \n \n18 \nthere was no task allocation during this week. the task allocation will begin from next week \nwith friday team meetings.  \n \nmoreover, it was advised that the knowledge of mongodb and nodejs would be very \nbeneficial for this project. consequently, next week i’ll focus on revising mongodb.  \n \nweek 3 \n \nduring week 3, i have started the uts data analyst toolkit course as part of my internship \ntraining at itic. the short course comprises of 4 modules, those are: python, sql, tableau \nand powerbi. the course is taught by matineh pooshiden. the module for this week was \npython. the first session which was held on a tuesday morning covered introduction to \npython, system setup, basic functions and numpy. the second session which was held on a \nthursday morning covered the topics: pandas and data visualization. hence, the material \ntaught in the two sessions was very insightful and it provided a good revision of python for \ndata science.  \n \nthe project session for this week focused on the project structure, a prototype of ui, use of \nchatgpt for building a dataset, and a breakdown of 4 tasks available for this week. this \nweek our supervisor gave us an opportunity to decide from the list of tasks the task we \nwould like to focus on for the week. hence, based on the chosen task we were required to \nprepare a presentation for friday team meeting to present our findings. the task i’ve chosen \nfor the week was to prepare a demo into chatgpt for generating data in json format and \nevaluate the use of ai like chatgpt for the purpose of data generation. consequently, the \nfocus of my demonstration was based on asking chatgpt to produce a certain number of \nstem questions with answers on a topic of data science in a json format. in addition, my \npresentation also demonstrated the ability of chatgpt to produce stem questions without \njson format, produce non-multiple-choice questions and answers in json format and \nwithout json format. thus, i have concluded that chatgpt is a powerful tool which can be \nused for data generation in json format. however, i have identified that this tool is \ninconsistent and has several drawbacks like question repetition and other.  \n \n19 \nfurthermore, we’ve also discussed another interesting project idea which can help to detect \nai cheating in the assessments and exams. the supervisor/ceo indicated that the further \ndiscussion of this idea will be held on next week.  \n \nweek 4 \n \nin week four, i have completed two sessions of the data analyst toolkit course. the module \nfor this week was sql. during the first session matineh the course instructor gave us an \nintroduction into sql. we were encouraged to use google cloud platform for learning \npurposes. additionally, matineh introduced us to the basic crud operations. the first \nsession was very helpful. it was a great revision of sql. the second session of sql was much \nmore complex. we were introduced to joins and advanced queries and functions. we were \ngiven a set of exercises to practice our knowledge and understanding of sql. the exercises \nwere a great learning opportunity. despite the complexity and the material load during the \nsecond lesson, i found that it was very insightful and educational.  \n \nduring week 4 the project task for the week was given by the supervisor. we were asked to \nprepare a summary of the monday project session where masoud discussed the use of gan \nfor generating data and the use of ml methods for scoring essays. the main topics of \ndiscussion included: availability of the datasets, feature extraction, evaluation metrics used \nin automatic essay scoring (aes), ml techniques and current challenges in aes. the purpose \nof this task was to show our understanding of the presentation and how we can link those \ntechniques to the automatic exam marking project and the other potential project on the \ndetection of ai generated material. thus, by completing this task, i have learnt that nlp can \nbe easily implemented for feature extraction, and it can help us with pre-processing of text \ndata. the ml models like bert can be implemented for text summarization, and question \ngeneration.  \n \nweek 5 \n \nduring week 5 i have completed two sessions of the uts data analyst toolkit course on \ntableau. the focus of the first session was based on: \n- \nunderstanding the basics of tableau,  \n \n20 \n- \ncreating simple charts, maps, dashboard, \n- \nworking with filters and colours, and \n- \nanalysing the charts.  \nthe first session was very practical, and it had taught me a lot of new things in tableau. \nfurthermore, in the second session of tableau, matineh introduced us to heatmaps, text \ntable, pie charts and other types of charts, customization techniques and other. i’ve found \nthat the second session was much more complex than the first session. during both sessions \nwe were given a lot of different tasks to work on in tableau. basically, we had to execute \ndifferent charts, work with customization, and other. i am looking forward to working with \ntableau in the future.  \n \nthe project during this week focused on the discussion of the user interface (ui) design for \nthe automatic exam marking tool for a modified project and the available research papers \non aes which can assist with the project. this week we had two tasks available to choose \nfrom. hence, this week i’ve focused on reviewing a research paper on use of bert for \nautomatic scoring and the code. based on the research paper, i have learned that fine-\ntuning and meta-training of a bert model can assist in developing a better performing \nmodel for the automatic scoring. in addition, i’ve also reviewed the code, where i was \nfocusing on identifying the libraries which can assist us in the future development of the \nmodel.  \nthus, all the knowledge and findings which i have collected from the research paper i have \npresented during the team meeting. in addition, during my presentation i have discussed \nhow we can link bert model and the transformers library to our project. this week team \nmeeting was very helpful and insightful for the project.  \n \nweek 6 \n \nthe focus of week 6 was based on three tasks: completion of the powerbi course, weekly \nproject task completion and mid-term presentation. this week has been one of the most \ndifficult in relation to the time management and completion of the tasks.  \n \n \n21 \nthe last two sessions of the data analyst toolkit course focused on powerbi. in the first \nsession we were introduced to importation, cleaning and transformation of data and looking \nat the reports. in the second session of the course, we looked at making interactive reports, \ndax, creating different visualizations like: area charts, tree maps, and other types of charts. \nduring both sessions we had to execute several different tasks. this was my first time \nworking with powerbi and i have found the entire experience very interesting and \neducational. however, i personally prefer tableau over powerbi.  \n \nthis week masoud our project manager delivered a very detailed and educational \npresentation on the machine learning engine for the exam management product. the focus \nof the presentation was based on the discussion of different language models, bert and fine \ntuning of the model and the transformer architecture. consequently, this week i was \nworking on understanding the details of the presentation for the future implementation of \nthe bert model and importance of model fine-tuning. hence, this week during the friday \npresentation we had to present a summary of masoud’s presentation outlining the use of \nbert. while preparing a presentation, i’ve developed a good understanding of the \ndifferences between the various lm, especially the gpt-3 model by openai in comparison \nto bert. i have also made additional research to help me develop a deeper understanding \ninto bert and architecture of the transformer. thus, this week i have made a good progress \ninto understanding how the discussed model can be applied to the project.  \n \nweek 7 \n \nthe week 7 will commence on the 17th of april 2023. on monday the ceo/supervisor had \ninformed us that due to his tight schedule and the public holidays he needs to reschedule \nthe project sessions. consequently, the supervisor requested to take this week as the first \nweek of the holiday break meaning that week 7 will commence from the 17th of april.  \n \nthe week 7 of the internship commenced on the 20th of april. during the thursday project \nsession, the project supervisor discussed the tasks for the completion between thursday \nthis week and next week thursday. hence, the tasks outlined during the project included: \nreading and reviewing different materials shared by stephen on bbc bert model and \n \n22 \nessaygan. this week we didn’t have to prepare the presentation for a friday team meeting \nas we only received the information regarding the tasks on thursday. thus, this week, i was \nfocusing on studying the materials shared by stephen for next week thursday session.  \n \nweek 8 \n \nduring week 8 the team had a face-to-face project meeting as the project manager masoud \nhad arrived in sydney. the project meeting focused on the discussion of a current state of \nthe project and the design and implementation of a machine learning model. masoud \ndelivered a detailed presentation on a bbc bert model. the meeting was very interesting \nand educational as it not only helped me to understand the use of bert in text classification \nbut also in understanding the type of a model, we will be focusing on in the future weeks \nwhile implementing a ml model. moreover, masoud also discussed the future tasks which \nwe will need to focus on.  \nthis week, i continued working on the task from the previous week. hence, i’ve focused on \nreviewing a research paper on use of gan and the analysis of a bbc code. the purpose of \nreviewing a research paper was to help in understanding how gan can be implemented in \ngenerating additional data for building a stronger ml model for our project. hence, i’ve \nprepared a short paper review in a form of a presentation summarising the important \ninformation in the paper. \nfurthermore, the other task which i’ve focused on was running the bbc bert model and \nanalysing the code.  \n \nweek 9 \n \nthe focus of week 9 was based on the detailed analysis of the code of the bbc bert model \nand training/testing the model with different parameters for the purpose of improving the \nmodel performance. hence, throughout the week, i was working on testing different \nparameters in the model for the purpose of trying to identify a better performing \nparameters than the ones in the original bert model. throughout the testing of models \nwith different parameters the main challenge which i’ve encountered was not enough gpu \npower. this challenge had limited the testing of certain parameters. in addition, despite the \nlimited gpu, i was still able to test a number of different models. all the different model \n \n23 \ntestings with the performance scores i’ve summarised in a report which was presented \nduring the team meeting.  \nmoreover, the second part of my presentation was based on the detailed review of the code \nwhich, i also presented during the friday presentation. a detailed analysis of the code was a \ngood challenge. the task assisted in broadening my understanding of a bert model.  \n \nweek 10 \n \nthe project during week 10 focused on the exploration of asap dataset and model \ncustomization. during one of the project sessions this week the project manager masoud \ndelivered an interesting presentation on customization of bbc bert model. the \npresentation focused on the discussion of how changing different model parameters may \nhelp to improve the model performance. the purpose of the presentation was to assist us \n(interns) in understanding the model customization process for the purpose of effectively \ncustomizing the bert model to fit our project and the dataset. hence, the allocated tasks for \nthis week were to review and analyse the asap dataset which was chosen by the project \nsupervisor for building a question scoring model and begin to work on the model \ncustomization for the asap dataset.  \ntherefore, this week i’ve performed data visualization for the purpose of understanding the \nasap data. based on the analysis of the data and the plots, i’ve cleaned the asap training \ndataset and begun customizing the bbc bert model for the asap dataset. during the \ncustomization of the code, i have encountered a few difficulties, consequently, i was only \nable to train the model closer to the end of the week as i had to spend some time to fix the \nerrors. next week, i will continue to work on model customization for the purpose of \ndeveloping a better performing model. \n \nweek 11 \n \nduring week 11 the project focused on the customization of the bert model for the asap \ndataset. this week project manager masoud had asked us (the interns) to test a number of \ndifferent parameter’s which may improve the performance of our model for the automated \nexam marking project. consequently, this week i have focused on model customization and \ntraining of the model with different parameters. during the training phase of the model, i \n \n24 \nhave encountered an issue with the computing units in google colab. the main issue is the \nlimitation of the computing power in google colab. consequently, to increase the \ncomputing power and improve the training of the model i’ve upgraded my account to colab \npro. hence, by upgrading to colab pro and changing the runtime type to gpu a100 with a \nhigh-ram the speed of training each epoch increased significantly. therefore, this allowed \nme to test more models with the different parameters.  \nthus, on friday i’ve prepared and presented my results of training bert model with \ndifferent parameters on the cleaned asap dataset to the project supervisor, manager and \nthe team. further training and customization are required for developing a stronger and \nbetter performing model. hence, i will continue to work on improving the performance of a \nmodel until the next specified task. \n \nweek 12 \n \nthis week was a challenging week as we (interns) had to work on a weekly task set by the \nproject supervisor and complete our final internship presentation for the university. hence, \nthe week was a bit stressful due to the workload. the project supervisor gave us the tasks \nuntil the end of the internship. hence, this week i was working on completing my \npresentation, preparing my final report for the supervisor, trying to create an api and \nworking with a new dataset. the new dataset is a clc fce dataset which comprises of 1,244 \nenglish exam scripts where the scripts are saved in separate xml files (ilexir, n.d.). hence, i \nhave encountered a few challenges with the dataset. due to the complex structure of the \ndataset i’ve struggled to read and extract the relevant information from the dataset. hence, \ni’ve been researching and trying different methods for reading the dataset. i have shared my \nchallenges with the project supervisor during the friday team meeting. during the team \nmeeting i’ve learnt that the other interns are also experiencing the same difficulties with the \ndataset. hence, the project supervisor asked us to continue to work with the dataset until \nthe next project session which will be next week.  \nmoreover, one of the other project tasks which i’ve been working on is creating an api. i \nhave never previously created an api, consequently, i’ve found this task to be very \nchallenging. i haven’t been able to create an api yet as i am still in the process of reading \nand researching into the creation process of api.  \n \n25 \nthus, next week i will focus on finalising the tasks given by the project supervisor. i will also \ntry my best to create my first api.  \n \nweek 13 \n \nthis week is the final week of the internship, consequently the two main tasks which i’ve \nbeen focusing on throughout the week included finalising the final report for the university \nand finalising the report with the colab notebook (with bert model and asap dataset) for \nstephen elbourn (project supervisor). unfortunately, due to my lack of experience in api \ncreation, i couldn’t create an api for the ml model. i’ve read different materials and \nwatched several educational videos; however, i couldn’t create an api. therefore, i’ve \nprepared a detailed report outlining the details of the data exploration, cleaning, \npreprocessing, model customization steps and model performance. i hope that the report \nand the notebook would be helpful for the next team working on this project. \nmoreover, this week chris dawson from itic helped to prepare and generate the new data \ninto a csv format. the project supervisor shared the file with us for the review. hence, this \nweek i’ve also managed to work a little bit with a new dataset (clc fce data). i was able to \nexplore the dataset and do a little bit of data cleaning. i’ve shared my progress with the \nteam and the project supervisor.   \n \n",
    "page": null,
    "goal": "Reflective journal Entities",
    "children": [
        {
            "id": "1.1",
            "name": "week 1",
            "nodeType": "title",
            "text": "week 1",
            "page": null,
            "goal": "week 1",
            "children": []
        },
        {
            "id": "1.2",
            "name": "week 1 the",
            "nodeType": "paragraph",
            "text": "week 1  \n \nthe first week of the internship was a kick of session and an introduction into an \norganization with the ceo/supervisor stephen elbourn and project manager masoud. the \nsession was held on a thursday and the focus of the session was on the introduction into \nthe organizational group structure and a brief introduction into the project. it was discussed \nthat our team consisting of 7 team members including myself will have 3 project sessions \nper week where: \n- session 1 will focus on task allocation and project discussion \n- session 2 will focus on q&a \n- session 3 will be a presentation on the findings and research completed during the week.  \nat the end of this week, i have confirmed my work arrangements and attendance with my \nsupervisor stephen elbourn taking into consideration the participation in the data analyst \ntoolkit course.  \n \nthe project which we’ll be working on is the ai enabled exam marking. the purpose of the \nproject is to develop an efficient model which will help teachers and instructors in exam \n \n17 \nmarking. an internship proposal has been prepared and submitted on friday outlining the \ndetails of the project, learning objectives and an internship plan.  \n \nmoreover, during this week i was given access to the itic learning portal for the data \nscience short course beginning from week 3 and it will be on every tuesday and thursday \nfrom 9:00 am till 12:00pm until the 30th of march. this course will focus on four modules: \npython, sql, tableau and power bi.  \n \nin addition, closer to the end of the week i was provided with various documents, those \ninclude: \n- \n a gantt chart for the ai enabled exam marking project outlining the project \nschedule for the upcoming weeks. the gantt chart provided by stephen elbourn \nassisted me in the preparation of the gantt chart for the internship proposal. \n- \ncompany’s policies which i had to read to ensure that i am aware and understand all \nthe policies. \n- \nslides to an old project on ai enabled exam marking to help us understand the idea \nof the project.  \nthus, during this week there was no task allocation as the purpose of this week was to \nintroduce us to the organization and the project.",
            "page": null,
            "goal": "week 1  \n \nthe first week of the internship was a kick of session and an introduction into an \norganization with the ceo/supervisor stephen elbourn and project manager masoud. the \nsession was held on a thursday and the focus of the session was on the introduction into \nthe organizational group structure and a brief introduction into the project. it was discussed \nthat our team consisting of 7 team members including myself will have 3 project sessions \nper week where: \n- session 1 will focus on task allocation and project discussion \n- session 2 will focus on q&a \n- session 3 will be a presentation on the findings and research completed during the week.  \nat the end of this week, i have confirmed my work arrangements and attendance with my \nsupervisor stephen elbourn taking into consideration the participation in the data analyst \ntoolkit course.  \n \nthe project which we’ll be working on is the ai enabled exam marking. the purpose of the \nproject is to develop an efficient model which will help teachers and instructors in exam \n \n17 \nmarking. an internship proposal has been prepared and submitted on friday outlining the \ndetails of the project, learning objectives and an internship plan.  \n \nmoreover, during this week i was given access to the itic learning portal for the data \nscience short course beginning from week 3 and it will be on every tuesday and thursday \nfrom 9:00 am till 12:00pm until the 30th of march. this course will focus on four modules: \npython, sql, tableau and power bi.  \n \nin addition, closer to the end of the week i was provided with various documents, those \ninclude: \n- \n a gantt chart for the ai enabled exam marking project outlining the project \nschedule for the upcoming weeks. the gantt chart provided by stephen elbourn \nassisted me in the preparation of the gantt chart for the internship proposal. \n- \ncompany’s policies which i had to read to ensure that i am aware and understand all \nthe policies. \n- \nslides to an old project on ai enabled exam marking to help us understand the idea \nof the project.  \nthus, during this week there was no task allocation as the purpose of this week was to \nintroduce us to the organization and the project.",
            "children": []
        },
        {
            "id": "1.3",
            "name": "week 2",
            "nodeType": "title",
            "text": "week 2",
            "page": null,
            "goal": "week 2",
            "children": []
        },
        {
            "id": "1.4",
            "name": "week 2 the",
            "nodeType": "paragraph",
            "text": "week 2 \n \nthe focus of the second week of the internship was based on the scope and product \narchitecture of the automatic exam marking project. the project manager masoud \ndiscussed the importance of project planning, the 10 phases of the project, research into \nexisting tools, technologies, and available datasets. \n \nduring this week we were requested to complete a capability matrix outlining our \nknowledge and experience in the areas like software, data analyst, data science and project \nmanagement. the purpose of this capability matrix was to help stephen (supervisor) and \nmasoud (project manager) in allocation of the future project tasks based on our knowledge \nand experience.  \n \n18 \nthere was no task allocation during this week. the task allocation will begin from next week \nwith friday team meetings.  \n \nmoreover, it was advised that the knowledge of mongodb and nodejs would be very \nbeneficial for this project. consequently, next week i’ll focus on revising mongodb.",
            "page": null,
            "goal": "week 2 \n \nthe focus of the second week of the internship was based on the scope and product \narchitecture of the automatic exam marking project. the project manager masoud \ndiscussed the importance of project planning, the 10 phases of the project, research into \nexisting tools, technologies, and available datasets. \n \nduring this week we were requested to complete a capability matrix outlining our \nknowledge and experience in the areas like software, data analyst, data science and project \nmanagement. the purpose of this capability matrix was to help stephen (supervisor) and \nmasoud (project manager) in allocation of the future project tasks based on our knowledge \nand experience.  \n \n18 \nthere was no task allocation during this week. the task allocation will begin from next week \nwith friday team meetings.  \n \nmoreover, it was advised that the knowledge of mongodb and nodejs would be very \nbeneficial for this project. consequently, next week i’ll focus on revising mongodb.",
            "children": []
        },
        {
            "id": "1.5",
            "name": "week 3",
            "nodeType": "title",
            "text": "week 3",
            "page": null,
            "goal": "week 3",
            "children": []
        },
        {
            "id": "1.6",
            "name": "week 3 during",
            "nodeType": "paragraph",
            "text": "week 3 \n \nduring week 3, i have started the uts data analyst toolkit course as part of my internship \ntraining at itic. the short course comprises of 4 modules, those are: python, sql, tableau \nand powerbi. the course is taught by matineh pooshiden. the module for this week was \npython. the first session which was held on a tuesday morning covered introduction to \npython, system setup, basic functions and numpy. the second session which was held on a \nthursday morning covered the topics: pandas and data visualization. hence, the material \ntaught in the two sessions was very insightful and it provided a good revision of python for \ndata science.  \n \nthe project session for this week focused on the project structure, a prototype of ui, use of \nchatgpt for building a dataset, and a breakdown of 4 tasks available for this week. this \nweek our supervisor gave us an opportunity to decide from the list of tasks the task we \nwould like to focus on for the week. hence, based on the chosen task we were required to \nprepare a presentation for friday team meeting to present our findings. the task i’ve chosen \nfor the week was to prepare a demo into chatgpt for generating data in json format and \nevaluate the use of ai like chatgpt for the purpose of data generation. consequently, the \nfocus of my demonstration was based on asking chatgpt to produce a certain number of \nstem questions with answers on a topic of data science in a json format. in addition, my \npresentation also demonstrated the ability of chatgpt to produce stem questions without \njson format, produce non-multiple-choice questions and answers in json format and \nwithout json format. thus, i have concluded that chatgpt is a powerful tool which can be \nused for data generation in json format. however, i have identified that this tool is \ninconsistent and has several drawbacks like question repetition and other.  \n \n19 \nfurthermore, we’ve also discussed another interesting project idea which can help to detect \nai cheating in the assessments and exams. the supervisor/ceo indicated that the further \ndiscussion of this idea will be held on next week.",
            "page": null,
            "goal": "week 3 \n \nduring week 3, i have started the uts data analyst toolkit course as part of my internship \ntraining at itic. the short course comprises of 4 modules, those are: python, sql, tableau \nand powerbi. the course is taught by matineh pooshiden. the module for this week was \npython. the first session which was held on a tuesday morning covered introduction to \npython, system setup, basic functions and numpy. the second session which was held on a \nthursday morning covered the topics: pandas and data visualization. hence, the material \ntaught in the two sessions was very insightful and it provided a good revision of python for \ndata science.  \n \nthe project session for this week focused on the project structure, a prototype of ui, use of \nchatgpt for building a dataset, and a breakdown of 4 tasks available for this week. this \nweek our supervisor gave us an opportunity to decide from the list of tasks the task we \nwould like to focus on for the week. hence, based on the chosen task we were required to \nprepare a presentation for friday team meeting to present our findings. the task i’ve chosen \nfor the week was to prepare a demo into chatgpt for generating data in json format and \nevaluate the use of ai like chatgpt for the purpose of data generation. consequently, the \nfocus of my demonstration was based on asking chatgpt to produce a certain number of \nstem questions with answers on a topic of data science in a json format. in addition, my \npresentation also demonstrated the ability of chatgpt to produce stem questions without \njson format, produce non-multiple-choice questions and answers in json format and \nwithout json format. thus, i have concluded that chatgpt is a powerful tool which can be \nused for data generation in json format. however, i have identified that this tool is \ninconsistent and has several drawbacks like question repetition and other.  \n \n19 \nfurthermore, we’ve also discussed another interesting project idea which can help to detect \nai cheating in the assessments and exams. the supervisor/ceo indicated that the further \ndiscussion of this idea will be held on next week.",
            "children": []
        },
        {
            "id": "1.7",
            "name": "week 4",
            "nodeType": "title",
            "text": "week 4",
            "page": null,
            "goal": "week 4",
            "children": []
        },
        {
            "id": "1.8",
            "name": "week 4 in",
            "nodeType": "paragraph",
            "text": "week 4 \n \nin week four, i have completed two sessions of the data analyst toolkit course. the module \nfor this week was sql. during the first session matineh the course instructor gave us an \nintroduction into sql. we were encouraged to use google cloud platform for learning \npurposes. additionally, matineh introduced us to the basic crud operations. the first \nsession was very helpful. it was a great revision of sql. the second session of sql was much \nmore complex. we were introduced to joins and advanced queries and functions. we were \ngiven a set of exercises to practice our knowledge and understanding of sql. the exercises \nwere a great learning opportunity. despite the complexity and the material load during the \nsecond lesson, i found that it was very insightful and educational.  \n \nduring week 4 the project task for the week was given by the supervisor. we were asked to \nprepare a summary of the monday project session where masoud discussed the use of gan \nfor generating data and the use of ml methods for scoring essays. the main topics of \ndiscussion included: availability of the datasets, feature extraction, evaluation metrics used \nin automatic essay scoring (aes), ml techniques and current challenges in aes. the purpose \nof this task was to show our understanding of the presentation and how we can link those \ntechniques to the automatic exam marking project and the other potential project on the \ndetection of ai generated material. thus, by completing this task, i have learnt that nlp can \nbe easily implemented for feature extraction, and it can help us with pre-processing of text \ndata. the ml models like bert can be implemented for text summarization, and question \ngeneration.",
            "page": null,
            "goal": "week 4 \n \nin week four, i have completed two sessions of the data analyst toolkit course. the module \nfor this week was sql. during the first session matineh the course instructor gave us an \nintroduction into sql. we were encouraged to use google cloud platform for learning \npurposes. additionally, matineh introduced us to the basic crud operations. the first \nsession was very helpful. it was a great revision of sql. the second session of sql was much \nmore complex. we were introduced to joins and advanced queries and functions. we were \ngiven a set of exercises to practice our knowledge and understanding of sql. the exercises \nwere a great learning opportunity. despite the complexity and the material load during the \nsecond lesson, i found that it was very insightful and educational.  \n \nduring week 4 the project task for the week was given by the supervisor. we were asked to \nprepare a summary of the monday project session where masoud discussed the use of gan \nfor generating data and the use of ml methods for scoring essays. the main topics of \ndiscussion included: availability of the datasets, feature extraction, evaluation metrics used \nin automatic essay scoring (aes), ml techniques and current challenges in aes. the purpose \nof this task was to show our understanding of the presentation and how we can link those \ntechniques to the automatic exam marking project and the other potential project on the \ndetection of ai generated material. thus, by completing this task, i have learnt that nlp can \nbe easily implemented for feature extraction, and it can help us with pre-processing of text \ndata. the ml models like bert can be implemented for text summarization, and question \ngeneration.",
            "children": []
        },
        {
            "id": "1.9",
            "name": "week 5",
            "nodeType": "title",
            "text": "week 5",
            "page": null,
            "goal": "week 5",
            "children": []
        },
        {
            "id": "1.10",
            "name": "week 5 during",
            "nodeType": "paragraph",
            "text": "week 5 \n \nduring week 5 i have completed two sessions of the uts data analyst toolkit course on \ntableau. the focus of the first session was based on: \n- \nunderstanding the basics of tableau,  \n \n20 \n- \ncreating simple charts, maps, dashboard, \n- \nworking with filters and colours, and \n- \nanalysing the charts.  \nthe first session was very practical, and it had taught me a lot of new things in tableau. \nfurthermore, in the second session of tableau, matineh introduced us to heatmaps, text \ntable, pie charts and other types of charts, customization techniques and other. i’ve found \nthat the second session was much more complex than the first session. during both sessions \nwe were given a lot of different tasks to work on in tableau. basically, we had to execute \ndifferent charts, work with customization, and other. i am looking forward to working with \ntableau in the future.  \n \nthe project during this week focused on the discussion of the user interface (ui) design for \nthe automatic exam marking tool for a modified project and the available research papers \non aes which can assist with the project. this week we had two tasks available to choose \nfrom. hence, this week i’ve focused on reviewing a research paper on use of bert for \nautomatic scoring and the code. based on the research paper, i have learned that fine-\ntuning and meta-training of a bert model can assist in developing a better performing \nmodel for the automatic scoring. in addition, i’ve also reviewed the code, where i was \nfocusing on identifying the libraries which can assist us in the future development of the \nmodel.  \nthus, all the knowledge and findings which i have collected from the research paper i have \npresented during the team meeting. in addition, during my presentation i have discussed \nhow we can link bert model and the transformers library to our project. this week team \nmeeting was very helpful and insightful for the project.",
            "page": null,
            "goal": "week 5 \n \nduring week 5 i have completed two sessions of the uts data analyst toolkit course on \ntableau. the focus of the first session was based on: \n- \nunderstanding the basics of tableau,  \n \n20 \n- \ncreating simple charts, maps, dashboard, \n- \nworking with filters and colours, and \n- \nanalysing the charts.  \nthe first session was very practical, and it had taught me a lot of new things in tableau. \nfurthermore, in the second session of tableau, matineh introduced us to heatmaps, text \ntable, pie charts and other types of charts, customization techniques and other. i’ve found \nthat the second session was much more complex than the first session. during both sessions \nwe were given a lot of different tasks to work on in tableau. basically, we had to execute \ndifferent charts, work with customization, and other. i am looking forward to working with \ntableau in the future.  \n \nthe project during this week focused on the discussion of the user interface (ui) design for \nthe automatic exam marking tool for a modified project and the available research papers \non aes which can assist with the project. this week we had two tasks available to choose \nfrom. hence, this week i’ve focused on reviewing a research paper on use of bert for \nautomatic scoring and the code. based on the research paper, i have learned that fine-\ntuning and meta-training of a bert model can assist in developing a better performing \nmodel for the automatic scoring. in addition, i’ve also reviewed the code, where i was \nfocusing on identifying the libraries which can assist us in the future development of the \nmodel.  \nthus, all the knowledge and findings which i have collected from the research paper i have \npresented during the team meeting. in addition, during my presentation i have discussed \nhow we can link bert model and the transformers library to our project. this week team \nmeeting was very helpful and insightful for the project.",
            "children": []
        },
        {
            "id": "1.11",
            "name": "week 6",
            "nodeType": "title",
            "text": "week 6",
            "page": null,
            "goal": "week 6",
            "children": []
        },
        {
            "id": "1.12",
            "name": "week 6 the",
            "nodeType": "paragraph",
            "text": "week 6 \n \nthe focus of week 6 was based on three tasks: completion of the powerbi course, weekly \nproject task completion and mid-term presentation. this week has been one of the most \ndifficult in relation to the time management and completion of the tasks.  \n \n \n21 \nthe last two sessions of the data analyst toolkit course focused on powerbi. in the first \nsession we were introduced to importation, cleaning and transformation of data and looking \nat the reports. in the second session of the course, we looked at making interactive reports, \ndax, creating different visualizations like: area charts, tree maps, and other types of charts. \nduring both sessions we had to execute several different tasks. this was my first time \nworking with powerbi and i have found the entire experience very interesting and \neducational. however, i personally prefer tableau over powerbi.  \n \nthis week masoud our project manager delivered a very detailed and educational \npresentation on the machine learning engine for the exam management product. the focus \nof the presentation was based on the discussion of different language models, bert and fine \ntuning of the model and the transformer architecture. consequently, this week i was \nworking on understanding the details of the presentation for the future implementation of \nthe bert model and importance of model fine-tuning. hence, this week during the friday \npresentation we had to present a summary of masoud’s presentation outlining the use of \nbert. while preparing a presentation, i’ve developed a good understanding of the \ndifferences between the various lm, especially the gpt-3 model by openai in comparison \nto bert. i have also made additional research to help me develop a deeper understanding \ninto bert and architecture of the transformer. thus, this week i have made a good progress \ninto understanding how the discussed model can be applied to the project.",
            "page": null,
            "goal": "week 6 \n \nthe focus of week 6 was based on three tasks: completion of the powerbi course, weekly \nproject task completion and mid-term presentation. this week has been one of the most \ndifficult in relation to the time management and completion of the tasks.  \n \n \n21 \nthe last two sessions of the data analyst toolkit course focused on powerbi. in the first \nsession we were introduced to importation, cleaning and transformation of data and looking \nat the reports. in the second session of the course, we looked at making interactive reports, \ndax, creating different visualizations like: area charts, tree maps, and other types of charts. \nduring both sessions we had to execute several different tasks. this was my first time \nworking with powerbi and i have found the entire experience very interesting and \neducational. however, i personally prefer tableau over powerbi.  \n \nthis week masoud our project manager delivered a very detailed and educational \npresentation on the machine learning engine for the exam management product. the focus \nof the presentation was based on the discussion of different language models, bert and fine \ntuning of the model and the transformer architecture. consequently, this week i was \nworking on understanding the details of the presentation for the future implementation of \nthe bert model and importance of model fine-tuning. hence, this week during the friday \npresentation we had to present a summary of masoud’s presentation outlining the use of \nbert. while preparing a presentation, i’ve developed a good understanding of the \ndifferences between the various lm, especially the gpt-3 model by openai in comparison \nto bert. i have also made additional research to help me develop a deeper understanding \ninto bert and architecture of the transformer. thus, this week i have made a good progress \ninto understanding how the discussed model can be applied to the project.",
            "children": []
        },
        {
            "id": "1.13",
            "name": "week 7",
            "nodeType": "title",
            "text": "week 7",
            "page": null,
            "goal": "week 7",
            "children": []
        },
        {
            "id": "1.14",
            "name": "week 7 the",
            "nodeType": "paragraph",
            "text": "week 7 \n \nthe week 7 will commence on the 17th of april 2023. on monday the ceo/supervisor had \ninformed us that due to his tight schedule and the public holidays he needs to reschedule \nthe project sessions. consequently, the supervisor requested to take this week as the first \nweek of the holiday break meaning that week 7 will commence from the 17th of april.  \n \nthe week 7 of the internship commenced on the 20th of april. during the thursday project \nsession, the project supervisor discussed the tasks for the completion between thursday \nthis week and next week thursday. hence, the tasks outlined during the project included: \nreading and reviewing different materials shared by stephen on bbc bert model and \n \n22 \nessaygan. this week we didn’t have to prepare the presentation for a friday team meeting \nas we only received the information regarding the tasks on thursday. thus, this week, i was \nfocusing on studying the materials shared by stephen for next week thursday session.",
            "page": null,
            "goal": "week 7 \n \nthe week 7 will commence on the 17th of april 2023. on monday the ceo/supervisor had \ninformed us that due to his tight schedule and the public holidays he needs to reschedule \nthe project sessions. consequently, the supervisor requested to take this week as the first \nweek of the holiday break meaning that week 7 will commence from the 17th of april.  \n \nthe week 7 of the internship commenced on the 20th of april. during the thursday project \nsession, the project supervisor discussed the tasks for the completion between thursday \nthis week and next week thursday. hence, the tasks outlined during the project included: \nreading and reviewing different materials shared by stephen on bbc bert model and \n \n22 \nessaygan. this week we didn’t have to prepare the presentation for a friday team meeting \nas we only received the information regarding the tasks on thursday. thus, this week, i was \nfocusing on studying the materials shared by stephen for next week thursday session.",
            "children": []
        },
        {
            "id": "1.15",
            "name": "week 8",
            "nodeType": "title",
            "text": "week 8",
            "page": null,
            "goal": "week 8",
            "children": []
        },
        {
            "id": "1.16",
            "name": "week 8 during",
            "nodeType": "paragraph",
            "text": "week 8 \n \nduring week 8 the team had a face-to-face project meeting as the project manager masoud \nhad arrived in sydney. the project meeting focused on the discussion of a current state of \nthe project and the design and implementation of a machine learning model. masoud \ndelivered a detailed presentation on a bbc bert model. the meeting was very interesting \nand educational as it not only helped me to understand the use of bert in text classification \nbut also in understanding the type of a model, we will be focusing on in the future weeks \nwhile implementing a ml model. moreover, masoud also discussed the future tasks which \nwe will need to focus on.  \nthis week, i continued working on the task from the previous week. hence, i’ve focused on \nreviewing a research paper on use of gan and the analysis of a bbc code. the purpose of \nreviewing a research paper was to help in understanding how gan can be implemented in \ngenerating additional data for building a stronger ml model for our project. hence, i’ve \nprepared a short paper review in a form of a presentation summarising the important \ninformation in the paper. \nfurthermore, the other task which i’ve focused on was running the bbc bert model and \nanalysing the code.",
            "page": null,
            "goal": "week 8 \n \nduring week 8 the team had a face-to-face project meeting as the project manager masoud \nhad arrived in sydney. the project meeting focused on the discussion of a current state of \nthe project and the design and implementation of a machine learning model. masoud \ndelivered a detailed presentation on a bbc bert model. the meeting was very interesting \nand educational as it not only helped me to understand the use of bert in text classification \nbut also in understanding the type of a model, we will be focusing on in the future weeks \nwhile implementing a ml model. moreover, masoud also discussed the future tasks which \nwe will need to focus on.  \nthis week, i continued working on the task from the previous week. hence, i’ve focused on \nreviewing a research paper on use of gan and the analysis of a bbc code. the purpose of \nreviewing a research paper was to help in understanding how gan can be implemented in \ngenerating additional data for building a stronger ml model for our project. hence, i’ve \nprepared a short paper review in a form of a presentation summarising the important \ninformation in the paper. \nfurthermore, the other task which i’ve focused on was running the bbc bert model and \nanalysing the code.",
            "children": []
        },
        {
            "id": "1.17",
            "name": "week 9",
            "nodeType": "title",
            "text": "week 9",
            "page": null,
            "goal": "week 9",
            "children": []
        },
        {
            "id": "1.18",
            "name": "week 9 the",
            "nodeType": "paragraph",
            "text": "week 9 \n \nthe focus of week 9 was based on the detailed analysis of the code of the bbc bert model \nand training/testing the model with different parameters for the purpose of improving the \nmodel performance. hence, throughout the week, i was working on testing different \nparameters in the model for the purpose of trying to identify a better performing \nparameters than the ones in the original bert model. throughout the testing of models \nwith different parameters the main challenge which i’ve encountered was not enough gpu \npower. this challenge had limited the testing of certain parameters. in addition, despite the \nlimited gpu, i was still able to test a number of different models. all the different model \n \n23 \ntestings with the performance scores i’ve summarised in a report which was presented \nduring the team meeting.  \nmoreover, the second part of my presentation was based on the detailed review of the code \nwhich, i also presented during the friday presentation. a detailed analysis of the code was a \ngood challenge. the task assisted in broadening my understanding of a bert model.",
            "page": null,
            "goal": "week 9 \n \nthe focus of week 9 was based on the detailed analysis of the code of the bbc bert model \nand training/testing the model with different parameters for the purpose of improving the \nmodel performance. hence, throughout the week, i was working on testing different \nparameters in the model for the purpose of trying to identify a better performing \nparameters than the ones in the original bert model. throughout the testing of models \nwith different parameters the main challenge which i’ve encountered was not enough gpu \npower. this challenge had limited the testing of certain parameters. in addition, despite the \nlimited gpu, i was still able to test a number of different models. all the different model \n \n23 \ntestings with the performance scores i’ve summarised in a report which was presented \nduring the team meeting.  \nmoreover, the second part of my presentation was based on the detailed review of the code \nwhich, i also presented during the friday presentation. a detailed analysis of the code was a \ngood challenge. the task assisted in broadening my understanding of a bert model.",
            "children": []
        },
        {
            "id": "1.19",
            "name": "week 10",
            "nodeType": "title",
            "text": "week 10",
            "page": null,
            "goal": "week 10",
            "children": []
        },
        {
            "id": "1.20",
            "name": "week 10 the",
            "nodeType": "paragraph",
            "text": "week 10 \n \nthe project during week 10 focused on the exploration of asap dataset and model \ncustomization. during one of the project sessions this week the project manager masoud \ndelivered an interesting presentation on customization of bbc bert model. the \npresentation focused on the discussion of how changing different model parameters may \nhelp to improve the model performance. the purpose of the presentation was to assist us \n(interns) in understanding the model customization process for the purpose of effectively \ncustomizing the bert model to fit our project and the dataset. hence, the allocated tasks for \nthis week were to review and analyse the asap dataset which was chosen by the project \nsupervisor for building a question scoring model and begin to work on the model \ncustomization for the asap dataset.  \ntherefore, this week i’ve performed data visualization for the purpose of understanding the \nasap data. based on the analysis of the data and the plots, i’ve cleaned the asap training \ndataset and begun customizing the bbc bert model for the asap dataset. during the \ncustomization of the code, i have encountered a few difficulties, consequently, i was only \nable to train the model closer to the end of the week as i had to spend some time to fix the \nerrors. next week, i will continue to work on model customization for the purpose of \ndeveloping a better performing model.",
            "page": null,
            "goal": "week 10 \n \nthe project during week 10 focused on the exploration of asap dataset and model \ncustomization. during one of the project sessions this week the project manager masoud \ndelivered an interesting presentation on customization of bbc bert model. the \npresentation focused on the discussion of how changing different model parameters may \nhelp to improve the model performance. the purpose of the presentation was to assist us \n(interns) in understanding the model customization process for the purpose of effectively \ncustomizing the bert model to fit our project and the dataset. hence, the allocated tasks for \nthis week were to review and analyse the asap dataset which was chosen by the project \nsupervisor for building a question scoring model and begin to work on the model \ncustomization for the asap dataset.  \ntherefore, this week i’ve performed data visualization for the purpose of understanding the \nasap data. based on the analysis of the data and the plots, i’ve cleaned the asap training \ndataset and begun customizing the bbc bert model for the asap dataset. during the \ncustomization of the code, i have encountered a few difficulties, consequently, i was only \nable to train the model closer to the end of the week as i had to spend some time to fix the \nerrors. next week, i will continue to work on model customization for the purpose of \ndeveloping a better performing model.",
            "children": []
        },
        {
            "id": "1.21",
            "name": "week 11",
            "nodeType": "title",
            "text": "week 11",
            "page": null,
            "goal": "week 11",
            "children": []
        },
        {
            "id": "1.22",
            "name": "week 11 during",
            "nodeType": "paragraph",
            "text": "week 11 \n \nduring week 11 the project focused on the customization of the bert model for the asap \ndataset. this week project manager masoud had asked us (the interns) to test a number of \ndifferent parameter’s which may improve the performance of our model for the automated \nexam marking project. consequently, this week i have focused on model customization and \ntraining of the model with different parameters. during the training phase of the model, i \n \n24 \nhave encountered an issue with the computing units in google colab. the main issue is the \nlimitation of the computing power in google colab. consequently, to increase the \ncomputing power and improve the training of the model i’ve upgraded my account to colab \npro. hence, by upgrading to colab pro and changing the runtime type to gpu a100 with a \nhigh-ram the speed of training each epoch increased significantly. therefore, this allowed \nme to test more models with the different parameters.  \nthus, on friday i’ve prepared and presented my results of training bert model with \ndifferent parameters on the cleaned asap dataset to the project supervisor, manager and \nthe team. further training and customization are required for developing a stronger and \nbetter performing model. hence, i will continue to work on improving the performance of a \nmodel until the next specified task.",
            "page": null,
            "goal": "week 11 \n \nduring week 11 the project focused on the customization of the bert model for the asap \ndataset. this week project manager masoud had asked us (the interns) to test a number of \ndifferent parameter’s which may improve the performance of our model for the automated \nexam marking project. consequently, this week i have focused on model customization and \ntraining of the model with different parameters. during the training phase of the model, i \n \n24 \nhave encountered an issue with the computing units in google colab. the main issue is the \nlimitation of the computing power in google colab. consequently, to increase the \ncomputing power and improve the training of the model i’ve upgraded my account to colab \npro. hence, by upgrading to colab pro and changing the runtime type to gpu a100 with a \nhigh-ram the speed of training each epoch increased significantly. therefore, this allowed \nme to test more models with the different parameters.  \nthus, on friday i’ve prepared and presented my results of training bert model with \ndifferent parameters on the cleaned asap dataset to the project supervisor, manager and \nthe team. further training and customization are required for developing a stronger and \nbetter performing model. hence, i will continue to work on improving the performance of a \nmodel until the next specified task.",
            "children": []
        },
        {
            "id": "1.23",
            "name": "week 12",
            "nodeType": "title",
            "text": "week 12",
            "page": null,
            "goal": "week 12",
            "children": []
        },
        {
            "id": "1.24",
            "name": "week 12 this",
            "nodeType": "paragraph",
            "text": "week 12 \n \nthis week was a challenging week as we (interns) had to work on a weekly task set by the \nproject supervisor and complete our final internship presentation for the university. hence, \nthe week was a bit stressful due to the workload. the project supervisor gave us the tasks \nuntil the end of the internship. hence, this week i was working on completing my \npresentation, preparing my final report for the supervisor, trying to create an api and \nworking with a new dataset. the new dataset is a clc fce dataset which comprises of 1,244 \nenglish exam scripts where the scripts are saved in separate xml files (ilexir, n.d.). hence, i \nhave encountered a few challenges with the dataset. due to the complex structure of the \ndataset i’ve struggled to read and extract the relevant information from the dataset. hence, \ni’ve been researching and trying different methods for reading the dataset. i have shared my \nchallenges with the project supervisor during the friday team meeting. during the team \nmeeting i’ve learnt that the other interns are also experiencing the same difficulties with the \ndataset. hence, the project supervisor asked us to continue to work with the dataset until \nthe next project session which will be next week.  \nmoreover, one of the other project tasks which i’ve been working on is creating an api. i \nhave never previously created an api, consequently, i’ve found this task to be very \nchallenging. i haven’t been able to create an api yet as i am still in the process of reading \nand researching into the creation process of api.  \n \n25 \nthus, next week i will focus on finalising the tasks given by the project supervisor. i will also \ntry my best to create my first api.",
            "page": null,
            "goal": "week 12 \n \nthis week was a challenging week as we (interns) had to work on a weekly task set by the \nproject supervisor and complete our final internship presentation for the university. hence, \nthe week was a bit stressful due to the workload. the project supervisor gave us the tasks \nuntil the end of the internship. hence, this week i was working on completing my \npresentation, preparing my final report for the supervisor, trying to create an api and \nworking with a new dataset. the new dataset is a clc fce dataset which comprises of 1,244 \nenglish exam scripts where the scripts are saved in separate xml files (ilexir, n.d.). hence, i \nhave encountered a few challenges with the dataset. due to the complex structure of the \ndataset i’ve struggled to read and extract the relevant information from the dataset. hence, \ni’ve been researching and trying different methods for reading the dataset. i have shared my \nchallenges with the project supervisor during the friday team meeting. during the team \nmeeting i’ve learnt that the other interns are also experiencing the same difficulties with the \ndataset. hence, the project supervisor asked us to continue to work with the dataset until \nthe next project session which will be next week.  \nmoreover, one of the other project tasks which i’ve been working on is creating an api. i \nhave never previously created an api, consequently, i’ve found this task to be very \nchallenging. i haven’t been able to create an api yet as i am still in the process of reading \nand researching into the creation process of api.  \n \n25 \nthus, next week i will focus on finalising the tasks given by the project supervisor. i will also \ntry my best to create my first api.",
            "children": []
        },
        {
            "id": "1.25",
            "name": "week 13",
            "nodeType": "title",
            "text": "week 13",
            "page": null,
            "goal": "week 13",
            "children": []
        },
        {
            "id": "1.26",
            "name": "week 13 this",
            "nodeType": "paragraph",
            "text": "week 13 \n \nthis week is the final week of the internship, consequently the two main tasks which i’ve \nbeen focusing on throughout the week included finalising the final report for the university \nand finalising the report with the colab notebook (with bert model and asap dataset) for \nstephen elbourn (project supervisor). unfortunately, due to my lack of experience in api \ncreation, i couldn’t create an api for the ml model. i’ve read different materials and \nwatched several educational videos; however, i couldn’t create an api. therefore, i’ve \nprepared a detailed report outlining the details of the data exploration, cleaning, \npreprocessing, model customization steps and model performance. i hope that the report \nand the notebook would be helpful for the next team working on this project. \nmoreover, this week chris dawson from itic helped to prepare and generate the new data \ninto a csv format. the project supervisor shared the file with us for the review. hence, this \nweek i’ve also managed to work a little bit with a new dataset (clc fce data). i was able to \nexplore the dataset and do a little bit of data cleaning. i’ve shared my progress with the \nteam and the project supervisor.",
            "page": null,
            "goal": "week 13 \n \nthis week is the final week of the internship, consequently the two main tasks which i’ve \nbeen focusing on throughout the week included finalising the final report for the university \nand finalising the report with the colab notebook (with bert model and asap dataset) for \nstephen elbourn (project supervisor). unfortunately, due to my lack of experience in api \ncreation, i couldn’t create an api for the ml model. i’ve read different materials and \nwatched several educational videos; however, i couldn’t create an api. therefore, i’ve \nprepared a detailed report outlining the details of the data exploration, cleaning, \npreprocessing, model customization steps and model performance. i hope that the report \nand the notebook would be helpful for the next team working on this project. \nmoreover, this week chris dawson from itic helped to prepare and generate the new data \ninto a csv format. the project supervisor shared the file with us for the review. hence, this \nweek i’ve also managed to work a little bit with a new dataset (clc fce data). i was able to \nexplore the dataset and do a little bit of data cleaning. i’ve shared my progress with the \nteam and the project supervisor.",
            "children": []
        }
    ]
}