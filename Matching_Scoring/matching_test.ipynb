{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph_list = [\n",
    "    \"During the seventh week of the internship program, I became familiar with the indicators of Compromise (IOC) in a digital forensic process and what role does it plays in the investigation process. There were multiple aspects that were covered throughout this week such as- the potential signs of compromise in a network, the process of network monitoring to identify the indicator of compromise, the process of gathering the evidence and also the process of extracting some valuable leads from that evidence that can help in solving the digital forensic case. Along with that, there are numerous war rooms scenarios designed for students, each focusing on a particular subject such as network analysis, forensics analysis, Linux foundations, system analysis, scripting, and PowerShell basics. I concentrated on Battle Room 9 this week. The main goal of this week’s internship were:  To understand the basics of the Indicators of Compromise in a cyber-incident, On Friday, I gave a talk about one of the tasks I accomplished in battle room 9, finding the laptop's registered owner. To inspect registry hives, I used Registry Explorer, an open-source program. I used the local workstation of Steve Laptop to load the SYSTEM register hive and to learn about the procedure to identify the IOCs, the criteria of its identification and also the process of its verification. The learning of activities and the fulfillment of these goals gave the following outcomes after the end of this week: At the end of this week, I was aware of the basic concept of the IOCs in a forensic process which includes unusual outbound network traffic, sales in the database read volume, mismatched port application traffic etc. which are also considered as the potential signs of IOCs, the process of identifying these IOC are also learnt and I was able to identify these IOCs after the completion of this week The life cycle includes- gathering data from the initial leads, create or edit the IOCs which includes verification of the IOCs and then the final step is to publish the IOCs (Domingues et al., 2023) and I finished quizzes on the danger landscape and creating a successful reaction strategy on our ITIC LMS platform.\",\n",
    "    \"Amid week 6, I met Anya Chung, who was making a difference with the CarClarity scene report. As a portion of my work, I considered the scene visualizations and the reports she had as of now made, proposing enhancements that can be made and what ought to be actualized for future reports. I proposed the dashboard we required for our accomplices and the fundamental information for the report, making a test report on Exceed expectations to appear her. In another task, I found some null information in a few columns within the information distribution center, and I detailed my investigation to Sam, who clarified the rationale behind the column being invalid and the reason. Moreover, I got criticism on my midterm introduction from Sam, who given fundamental changes that required to be made. Additionally, I made a Salesforce report for the promoting group, assessing the execution of the Klaviyo promoting stage within the final three months, and making a media arrange for the up-and-coming quarters. In conclusion, I made a renegotiate report that secured the taking after focuses: how numerous renegotiate leads and settlements have we gotten over the past 12 months, required by month; how numerous renegotiate leads came through our renegotiate landing page on our site, too by month; and with the renegotiate leads, where are they coming from? Direct/Google, accomplices, etc. Part of the channels. During this week, I learned the significance of paying consideration to detail and being careful in analyzing information. By finding the invalid information within the information distribution center and announcing it to Sam, I realized the value of having a tutor who can clarify the thinking behind certain choices or information focuses. When making reports, such as the renegotiate report, I had to create beyond any doubt that I caught on the essential information focuses and how to show them successfully. In working with Anya, I moreover learned the significance of communicating thoughts and collaborating viably to make impactful reports. By and large, I found week 6 to be a productive and quick week. The errands doled out to me required a tall level of consideration to detail and understanding of the information sources. My intuition with Sam and Anya showed me the significance of working collaboratively to attain the task's objectives and looking for criticism to progress my work. The renegotiate report and Salesforce report made a difference in my knowledge and abilities in displaying information successfully, which can be advantageous in my future work.\",\n",
    "    \"In this week, a new task was given to me. The task given to me was to collect the data of all the people who have done their internship from Reesby IoT Recruitment Agency and have listed it on their experience from Linkedin. The task assigned to me was to obtain all the data of all the people who have done their internship from Reesby IoT Recruitment Agency and have listed it on their experience from Linkedin. This wasn’t an easy task as it seems which I realised while I was working through it. The project was to collect all the data available on the person which translates to getting all information such as is the person male or a female? Is the person in Australia? If the person is in Australia, which city is the person living in? What is the highest educational qualification? When did the person start their internship with Reesby IoT Recruitment Agency? When did the person finish their internship with Reesby IoT Recruitment Agency? How long did the person had to wait until they landed their job? Are they still continuing their job where they landed their job or have, they changed their job? If they have changed their job, did change the field of their job or is the field same? How many times did they change their job? What is the biggest brand they have worked for up until now? What is the ethnic background of the person? These are just some of the main pertinent questions to the analysis. I was not able to use the web scraper here as LinkedIn blocks all sorts of scrapers. So, this task has to be done manually and I did it during this whole week as there were many people who have completed their internship. This whole week was just to collect the data from LinkedIn\",\n",
    "    \"One of my primary goals was to create a report for the finance department and learn SQL, a skill I had yet to acquire. This project aimed to provide valuable insights to the finance team while also allowing me to expand my skill set and gain practical experience in database management. To achieve this goal, I participated in several activities, including a meeting with my supervisor to discuss the project requirements, timeline, and expectations. My supervisor provided me with guidance and support throughout the task, ensuring that I was well-equipped to deliver the report successfully and learn the necessary SQL skills. In addition to meeting with my supervisor, I attended a workshop on advanced SQL techniques, titled 'Advanced SQL II.' This workshop helped me build upon my existing data analysis skills and equipped me with the necessary knowledge to work with databases, perform complex queries, and manipulate data using SQL. After acquiring the necessary SQL skills and knowledge, I began working on the report for the finance department. I analysed the data, extracted relevant information using SQL queries, and created visualisations to highlight trends and patterns in the financial data. I then designed an interactive dashboard with multiple views, advanced filters, and parameters, providing users with a more immersive and engaging experience. Upon completing the report, I uploaded it to the Domain server, making it accessible to the relevant stakeholders within the finance department. The successful completion of this project allowed me to gain advanced SQL skills and develop a good understanding of database management. During the process, I also learned how to update databases, which further enhanced my knowledge and skills in database management. This hands-on experience in working with real-world databases not only improved my technical abilities but also gave me the confidence to tackle similar projects in the future.\"\n",
    "]\n",
    "\n",
    "#First sample list to check\n",
    "library_sample_check_list = [\n",
    "    \"One of my primary goals was to create a report for the finance department and learn SQL, a skill I had yet to acquire. This project aimed to provide valuable insights to the finance team while also allowing me to expand my skill set and gain practical experience in database management. To achieve this goal, I participated in several activities, including a meeting with my supervisor to discuss the project requirements, timeline, and expectations. My supervisor provided me with guidance and support throughout the task, ensuring that I was well-equipped to deliver the report successfully and learn the necessary SQL skills. In addition to meeting with my supervisor, I attended a workshop on advanced SQL techniques, titled 'Advanced SQL II.' This workshop helped me build upon my existing data analysis skills and equipped me with the necessary knowledge to work with databases, perform complex queries, and manipulate data using SQL. After acquiring the necessary SQL skills and knowledge, I began working on the report for the finance department. I analysed the data, extracted relevant information using SQL queries, and created visualisations to highlight trends and patterns in the financial data. I then designed an interactive dashboard with multiple views, advanced filters, and parameters, providing users with a more immersive and engaging experience. Upon completing the report, I uploaded it to the Domain server, making it accessible to the relevant stakeholders within the finance department. The successful completion of this project allowed me to gain advanced SQL skills and develop a good understanding of database management. During the process, I also learned how to update databases, which further enhanced my knowledge and skills in database management. This hands-on experience in working with real-world databases not only improved my technical abilities but also gave me the confidence to tackle similar projects in the future.\",\n",
    "    \"I would like to express my deepest gratitude to Suyash, Gilmar, Phuong, Hieu, and Ahmad from Domain Group Australia for their invaluable help and guidance during the past 7 weeks. Their expertise, support, and encouragement have been instrumental in my growth and learning throughout this period. In addition, I am extremely thankful for the assistance provided by the Unit Convenor of Internship at Macquarie University, Amin, whose efforts have significantly contributed to the success of this experience. I am truly fortunate to have had the opportunity to learn from and work with such dedicated professionals, and I am confident that the knowledge and skills I have gained will serve me well in my future endeavours.\",\n",
    "    \"Prioritise time management and work-life balance: Encourage employees to effectively balance their workload, personal commitments, and other responsibilities. This may include offering flexible working hours, providing time management training, or promoting a culture of open communication around workload expectations. Expand training and development opportunities: Continue investing in employee development through workshops, training sessions, and mentorship programs. Offering additional training opportunities in emerging technologies and industry trends will help employees stay ahead in their careers and contribute more effectively to the company's success. Evaluate and improve internal processes: Regularly assess the effectiveness of internal processes and workflows, and make improvements where necessary. This may include implementing more efficient project management methodologies, improving communication channels, or updating technology infrastructure.\",\n",
    "    \"Domain Group Australia, a prominent property and technology group, has been a key player in the Australian real estate market since its founding in 1994. Initially a print publication called Domain under Fairfax Media, the company focused on offering property listings and insights to the public. Over time, Domain evolved and adapted to industry changes, harnessing technological advancements to enhance its services. In 1999, Domain launched its first online platform, domain.com.au, providing a digital space for property listings and related information. This marked the beginning of Domain's transformation into a technology-driven company, ensuring its relevance in Australia's dynamic real estate market. Over the next decade, Domain expanded its online presence and improved its platform through innovative features and services. Acquisitions and strategic partnerships fueled this growth, enabling Domain to diversify its offerings and solidify its industry position. Notable acquisitions include Property Data Solutions (PDS) in 2006 and Home Price Guide in 2008, which provided data, mapping, and property valuation services.\",\n",
    "    \"Domain Group is dedicated to protecting the privacy and personal information of its users. Their privacy policy outlines the types of information they collect, how it is used, and the measures taken to safeguard it. Domain is committed to complying with the Australian Privacy Principles (APPs) and other relevant privacy regulations.\",\n",
    "    \"This department is responsible for driving revenue growth, promoting Domain's products and services, and acquiring new customers. The sales team works closely with real estate agents, property developers, and other stakeholders to identify their needs and offer tailored solutions.\"\n",
    "]\n",
    "\n",
    "#Second sample with different sections of the document that does not relate to the title\n",
    "library_sample_check_list_2 = [\n",
    "    \"In this week, a new task was given to me. The task given to me was to collect the data of all the people who have done their internship from Reesby IoT Recruitment Agency and have listed it on their experience from Linkedin. The task assigned to me was to obtain all the data of all the people who have done their internship from Reesby IoT Recruitment Agency and have listed it on their experience from Linkedin. This wasn’t an easy task as it seems which I realised while I was working through it. The project was to collect all the data available on the person which translates to getting all information such as is the person male or a female? Is the person in Australia? If the person is in Australia, which city is the person living in? What is the highest educational qualification? When did the person start their internship with Reesby IoT Recruitment Agency? When did the person finish their internship with Reesby IoT Recruitment Agency? How long did the person had to wait until they landed their job? Are they still continuing their job where they landed their job or have, they changed their job? If they have changed their job, did change the field of their job or is the field same? How many times did they change their job? What is the biggest brand they have worked for up until now? What is the ethnic background of the person? These are just some of the main pertinent questions to the analysis. I was not able to use the web scraper here as LinkedIn blocks all sorts of scrapers. So, this task has to be done manually and I did it during this whole week as there were many people who have completed their internship. This whole week was just to collect the data from LinkedIn\",\n",
    "    \"Reesby was established in 2016 in Melbourne. The company is an innovative and premium recruitment and employment services agency. It operates globally and has collaborated with big brands such as Microsoft, Amazon, Coles, NAB, DefenceForce Australia, and more. With a female executive team and strong culture for diversity Reesby have been nominated for many awards for their services and technology product developments and training programs.\",\n",
    "    \"The company needs to hire more permenant employees in order to scale the company. The company should build robust cyber security network so that threats from scammers can be neautralised easily. The company needs to focus on the data integrity when the access ID given to interns who have joined. A robust background check should be done to anyone who applies to be an intern. These are the recommendations to the company.\",\n",
    "    \"Events and Event Planning which focuses on running a community focused events in collaboration with other companies to create tailored events in person and online. For instance, the most recent event that the company has organized is the cybersecurity event where in companies looking for job seekers with skills in cyber security was held.\",\n",
    "    \"From the starting of my internship with Reesby IoT Recruitment Agency, I have been involved with two tasks. The very first task I was assigned was a data acquisition task which was to collect the data from the all the job searching websites for the following roles, Chief Technology Officer, Business Development Manager, Director of Operations, Chief of Staff, Chief Strategy Office, Chief Administrative Officer, General Manager, Vice President of Operations, Chief Transformation Officer, Chief Customer Officer, Chief Experience Officer for the executive roles. Operations Manager, Service Operations Manager, Customer Service Manager, Delivery Manager, IT Service Manager, Client Services Manager, Service Support Manager, Customer Experience Manager, Service Desk Manager for service delivery manager roles and many more . Then I got to work collecting the data from all those job listing websites. Once the data was collected, it was made into a report and submitted it to the concerned person.\"\n",
    "]\n",
    "\n",
    "#Third sample with different sections of the document that does not relate to the title\n",
    "library_sample_check_list_3 = [\n",
    "    \"Amid week 6, I met Anya Chung, who was making a difference with the CarClarity scene report. As a portion of my work, I considered the scene visualizations and the reports she had as of now made, proposing enhancements that can be made and what ought to be actualized for future reports. I proposed the dashboard we required for our accomplices and the fundamental information for the report, making a test report on Exceed expectations to appear her. In another task, I found some null information in a few columns within the information distribution center, and I detailed my investigation to Sam, who clarified the rationale behind the column being invalid and the reason. Moreover, I got criticism on my midterm introduction from Sam, who given fundamental changes that required to be made. Additionally, I made a Salesforce report for the promoting group, assessing the execution of the Klaviyo promoting stage within the final three months, and making a media arrange for the up-and-coming quarters. In conclusion, I made a renegotiate report that secured the taking after focuses: how numerous renegotiate leads and settlements have we gotten over the past 12 months, required by month; how numerous renegotiate leads came through our renegotiate landing page on our site, too by month; and with the renegotiate leads, where are they coming from? Direct/Google, accomplices, etc. Part of the channels. During this week, I learned the significance of paying consideration to detail and being careful in analyzing information. By finding the invalid information within the information distribution center and announcing it to Sam, I realized the value of having a tutor who can clarify the thinking behind certain choices or information focuses. When making reports, such as the renegotiate report, I had to create beyond any doubt that I caught on the essential information focuses and how to show them successfully. In working with Anya, I moreover learned the significance of communicating thoughts and collaborating viably to make impactful reports. By and large, I found week 6 to be a productive and quick week. The errands doled out to me required a tall level of consideration to detail and understanding of the information sources. My intuition with Sam and Anya showed me the significance of working collaboratively to attain the task's objectives and looking for criticism to progress my work. The renegotiate report and Salesforce report made a difference in my knowledge and abilities in displaying information successfully, which can be advantageous in my future work.\",\n",
    "    \"I would like to precise my true appreciation to the taking after individuals who made noteworthy commitments to this report: Adam Israel, Installments Master at CarClarity; Yijia (Bella) Client Interface Architect Zhang UI/UX Designer at CarClarity; Phil O'Connor, Head of Promoting at CarClarity; Joseph Vu, Item Chief at CarClarity, and Sam Khadivizand, Data Scientist at CarClarity. Their important commitments in terms of ability, counsel, and comments contributed enormously to the victory of this report. Their polished skill and commitment to the extent are excellent, and I could not have inquired for a distant better; much better; higher; stronger; improved group. Their mastery and information in their areas greatly contributed to the quality of the report, and their readiness to share their views and concepts was a source of inspiration. Their useful input and bolster all through the method was priceless and much acknowledged.\",\n",
    "    \"CarClarity ought to investigate openings to extend its assets in arrange to contribute to unused advances, promoting campaigns, and other activities that may help it grow its reach and move forward with its administrations. This may incorporate looking for out unused speculators or associations, as well as investigating elective sources of financing such as gifts or advances. In arranging to compete with bigger and more built-up competitors, CarClarity ought to center on moving forward with its client involvement. This might incorporate contributing to user-friendly innovation and interfacing, giving comprehensive and opportune client bolster, and advertising competitive intrigued rates and credit terms.\",\n",
    "    \"CarClarity is a car Loan Platform that was propelled in 2020 by its founders, Zaheer Jappie (CEO), Luke Scott (CTO), and David Fahim (COO). The platform was planned to rearrange the method of choosing a car loan, by providing clients with access to 30+ moneylenders with a few of the foremost competitive rates within Australian advertising. The establishing group of CarClarity pointed to bringing world-class designing and customer-obsessed operations to their clients, with the objective of diminishing the potential stresses that come with applying for unused car credit. The company's center on client benefit and providing easy get-to-do run of car advance alternatives has made a difference it rapidly set up a solid nearness within the Australian Market.\",\n",
    "    \"The marketing team at CarClarity is responsible for driving awareness and demand for the company's services. Led by Bridget Devlin, the team consists of creative professionals who work together to develop compelling campaigns and strategies that resonate with potential customers. From graphic designers to digital marketing managers, each member of the team plays a critical role in shaping CarClarity's messaging and driving growth.\"\n",
    "]\n",
    "#Final sample with different sections of the document that does not relate to the title\n",
    "library_sample_check_list_4 = [\n",
    "    \"During the seventh week of the internship program, I became familiar with the indicators of Compromise (IOC) in a digital forensic process and what role does it plays in the investigation process. There were multiple aspects that were covered throughout this week such as- the potential signs of compromise in a network, the process of network monitoring to identify the indicator of compromise, the process of gathering the evidence and also the process of extracting some valuable leads from that evidence that can help in solving the digital forensic case. Along with that, there are numerous war rooms scenarios designed for students, each focusing on a particular subject such as network analysis, forensics analysis, Linux foundations, system analysis, scripting, and PowerShell basics. I concentrated on Battle Room 9 this week. The main goal of this week’s internship were:  To understand the basics of the Indicators of Compromise in a cyber-incident, On Friday, I gave a talk about one of the tasks I accomplished in battle room 9, finding the laptop's registered owner. To inspect registry hives, I used Registry Explorer, an open-source program. I used the local workstation of Steve Laptop to load the SYSTEM register hive and to learn about the procedure to identify the IOCs, the criteria of its identification and also the process of its verification. The learning of activities and the fulfillment of these goals gave the following outcomes after the end of this week: At the end of this week, I was aware of the basic concept of the IOCs in a forensic process which includes unusual outbound network traffic, sales in the database read volume, mismatched port application traffic etc. which are also considered as the potential signs of IOCs, the process of identifying these IOC are also learnt and I was able to identify these IOCs after the completion of this week The life cycle includes- gathering data from the initial leads, create or edit the IOCs which includes verification of the IOCs and then the final step is to publish the IOCs (Domingues et al., 2023) and I finished quizzes on the danger landscape and creating a successful reaction strategy on our ITIC LMS platform.\",\n",
    "    \"During the time of my internship, I received a ton of support and assistance from my colleagues and also form the ITIC team. Firstly, I want to thank ITIC group for giving this wonderful opportunity and making me a part of the internship and secondly, I want to extend my gratitude to Macquarie university for allowing me to pursue this internship program which helped me to gain a strong practical knowledge and as well as theoretical knowledge. In addition, I would like to express my profound gratitude to my mentor, Stephen Elbourn, for his valuable support throughout the internship. His experience and expertise have had a huge impact on how I perceive the sector. Also, I would like to convey my gratitude to Dr. Amin Beheshti, the convenor of my unit, for his assistance and answers to my enquiries. Finally, I would like to thank my friends, colleagues and family who encouraged me to focus on my studies all the time. They supported me emotionally and financially throughout my degree.\",\n",
    "    \"More investment sin their security infrastructure to keep their research work and also the details of their customers and partners secure from any unauthorized interferences. Also, they require more technically skilled workforce in order to meet the changing and increasing demands in the future because with the current work force it will be tough for the company to manage all of their operations related to their software system development, networking, technological solutions, AI research and educational training programs.\",\n",
    "    \"ITIC is an IT based company which provides the technologies which includes the technologies like Cloud, Security, Software Development, Artificial Intelligence and Data Science. ITIC is a premier training organization which provides IT training, IT support and the project implementation services throughout Australia and New Zealand. The organization is also one of the largest entities in Australia to conduct and host the exams from Pearson, PSI, Kryterion and Prometric. The organization also offers the internships to the college students and provides the students with the knowledge of the various IT technologies. ITIC operates from the three subsidiaries known as ITIC Education, ITIC Research, ITIC Systems\",\n",
    "    \"The corporation keeps ownership rights to the data. The Intuitive Technology Innovations Pty Ltd IT system should not be used to access, store, or distribute anything or information that employees do not want the firm to see or hear. Access to or delivery of electronic material (including emails and internet websites) that may violate any of Intuitive Technology Innovations Pty Ltd.’s policies may be banned if the firm feels it is necessary and permitted by law\",\n",
    "    \"ITIC Research, an industry stream of the AI enabled Process (AIP) Research Centre, has awarded Macquarie University a four-year research grant for the 'Intelligence-led Learning and Teaching' project. The fundamental purpose of this research is to advance scientific understanding of intelligent and AI-enabled learning and teaching. It could be used to discover new artificial intelligence and data science applications in education. Businesses are employing artificial intelligence and data science to fundamentally change operations, such as assisting staff in communicating analysis and making decisions\"\n",
    "]\n",
    "\n",
    "#title = \"What are student's recommendation about the improvements that can be done with their respective companies.\"\n",
    "title = 'Provide a detailed description of the project conducted during the internship and its overall expectations.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 78.9 \n",
      "Last Float: 78.9\n",
      "\n",
      "Input: 0.519蟗\n",
      "Last Float: 0.519\n",
      "\n",
      "Input: The text mentions evaluating various positions data, cleaning text data, carefully extracting relevant keywords, using decision trees for classification, and achieving a certain accuracy rate. The approach was quite well-systematized. Here are the detailed observations, weighed by the rubric segments:\n",
      "\n",
      "1. Task Description: The text indeed describes tasks and outlines the goals, ensuring the steps taken toward those goals. It also mentions the extraction of relevant information and conveys the process for cleaning and lemmatizing the datasets. Additionally, the results gained from classification and key feature extraction were clearly discussed.\n",
      "  - Compliance rate –– 0.85  0.35 = 0.2975\n",
      "\n",
      "2. Event Connection: The text mentions the happenings of meetings for brainstorming and task assignment. It vividly relays experiences and discussions with team members regarding the project and the tools/algorithms used, without going into detail about those events.\n",
      "  - Compliance rate – – 0.70  0.30 = 0.21\n",
      "\n",
      "3. Connection with Others: The text communicates the activities in collaboration with team members - especially working tandem with Avinash. Elements such as struggles, task distribution, and talk of overcoming challenges are briefed. Yet, clear feelings or future learning from these team exercises werent fully immersed.\n",
      "  - Compliance rate –– 0.55  0.30 = 0.165\n",
      "\n",
      "Summarising the rubric-based calculations: 0.2975 + 0.21 + 0.165 = 0.6725, rounded would be 0.673\n",
      "\n",
      "Therefore, the rubric compliance evaluation:  \n",
      "\n",
      "0.673  \n",
      "\n",
      "The newly assigned text should be evaluated taking into consideration the structured rubric and relative observations relevant to each rubric segment. Please proceed with the next sequence if required.\n",
      "\n",
      "\n",
      "Last Float: 0.673\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def get_last_float(text):\n",
    "    \"\"\"\n",
    "    Extracts and returns the last float number mentioned in the input text.\n",
    "    If no valid float is found, returns None.\n",
    "    \"\"\"\n",
    "    # Regular expression to match float numbers (handles decimals and negatives)\n",
    "    float_pattern = r\"-?\\d+\\.\\d+|-?\\d+\"\n",
    "\n",
    "    # Find all matches in the text\n",
    "    matches = re.findall(float_pattern, text)\n",
    "\n",
    "    if matches:\n",
    "        # Convert the last match to float and return\n",
    "        return float(matches[-1])\n",
    "    \n",
    "    return None  # Return None if no float is found\n",
    "\n",
    "# Example usage:\n",
    "texts = [\n",
    "    \"78.9 \",\n",
    "    #\"No numbers here!\",\n",
    "    \"0.519蟗\",\n",
    "    \"The text mentions evaluating various positions data, cleaning text data, carefully extracting relevant keywords, using decision trees for classification, and achieving a certain accuracy rate. The approach was quite well-systematized. Here are the detailed observations, weighed by the rubric segments:\\n\\n1. Task Description: The text indeed describes tasks and outlines the goals, ensuring the steps taken toward those goals. It also mentions the extraction of relevant information and conveys the process for cleaning and lemmatizing the datasets. Additionally, the results gained from classification and key feature extraction were clearly discussed.\\n  - Compliance rate –– 0.85  0.35 = 0.2975\\n\\n2. Event Connection: The text mentions the happenings of meetings for brainstorming and task assignment. It vividly relays experiences and discussions with team members regarding the project and the tools/algorithms used, without going into detail about those events.\\n  - Compliance rate – – 0.70  0.30 = 0.21\\n\\n3. Connection with Others: The text communicates the activities in collaboration with team members - especially working tandem with Avinash. Elements such as struggles, task distribution, and talk of overcoming challenges are briefed. Yet, clear feelings or future learning from these team exercises werent fully immersed.\\n  - Compliance rate –– 0.55  0.30 = 0.165\\n\\nSummarising the rubric-based calculations: 0.2975 + 0.21 + 0.165 = 0.6725, rounded would be 0.673\\n\\nTherefore, the rubric compliance evaluation:  \\n\\n0.673  \\n\\nThe newly assigned text should be evaluated taking into consideration the structured rubric and relative observations relevant to each rubric segment. Please proceed with the next sequence if required.\\n\\n\",\n",
    "    #\"5 apples, 2 oranges, and 3.14 pies.\"\n",
    "]\n",
    "\n",
    "for text in texts:\n",
    "    print(f\"Input: {text}\\nLast Float: {get_last_float(text)}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import re\n",
    "\n",
    "def get_last_float(text):\n",
    "    \"\"\"\n",
    "    Extracts and returns the last float number mentioned in the input text.\n",
    "    If no valid float is found, returns None.\n",
    "    \"\"\"\n",
    "    # Regular expression to match float numbers (handles decimals and negatives)\n",
    "    float_pattern = r\"-?\\d+\\.\\d+|-?\\d+\"\n",
    "\n",
    "    # Find all matches in the text\n",
    "    matches = re.findall(float_pattern, text)\n",
    "\n",
    "    if matches:\n",
    "        # Convert the last match to float and return\n",
    "        return float(matches[-1])\n",
    "    \n",
    "    return None  # Return None if no float is found\n",
    "\n",
    "# Example usage:\n",
    "texts = [\n",
    "    \"The values are 12, 45.6, and 78.9 in the report.\",\n",
    "    \"No numbers here!\",\n",
    "    \"Negative values like -12.5 and 4.7 are considered.\",\n",
    "    \"'The text mentions evaluating various positions data, cleaning text data, carefully extracting relevant keywords, using decision trees for classification, and achieving a certain accuracy rate. The approach was quite well-systematized. Here are the detailed observations, weighed by the rubric segments:\\n\\n1. Task Description: The text indeed describes tasks and outlines the goals, ensuring the steps taken toward those goals. It also mentions the extraction of relevant information and conveys the process for cleaning and lemmatizing the datasets. Additionally, the results gained from classification and key feature extraction were clearly discussed.\\n  - Compliance rate –– 0.85  0.35 = 0.2975\\n\\n2. Event Connection: The text mentions the happenings of meetings for brainstorming and task assignment. It vividly relays experiences and discussions with team members regarding the project and the tools/algorithms used, without going into detail about those events.\\n  - Compliance rate – – 0.70  0.30 = 0.21\\n\\n3. Connection with Others: The text communicates the activities in collaboration with team members - especially working tandem with Avinash. Elements such as struggles, task distribution, and talk of overcoming challenges are briefed. Yet, clear feelings or future learning from these team exercises werent fully immersed.\\n  - Compliance rate –– 0.55  0.30 = 0.165\\n\\nSummarising the rubric-based calculations: 0.2975 + 0.21 + 0.165 = 0.6725, rounded would be 0.673\\n\\nTherefore, the rubric compliance evaluation:  \\n\\n0.673  \\n\\nThe newly assigned text should be evaluated taking into consideration the structured rubric and relative observations relevant to each rubric segment. Please proceed with the next sequence if required.\\n\\n\",\n",
    "    \"5 apples, 2 oranges, and 3.14 pies.\"\n",
    "]\n",
    "\n",
    "for text in texts:\n",
    "    print(f\"Input: {text}\\nLast Float: {get_last_float(text)}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sentence_transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer, util\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Function to check the similarity of the title with the paragraphs\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlibrary_sample_check_function_new_sentence_model\u001b[39m(library_sample_check_list, title):\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sentence_transformers'"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Function to check the similarity of the title with the paragraphs\n",
    "def library_sample_check_function_new_sentence_model(library_sample_check_list, title):\n",
    "    model = SentenceTransformer('all-mpnet-base-v2')\n",
    "    title_encoded = model.encode(title)\n",
    "    paragraph_dict = {}\n",
    "    for paragraph in library_sample_check_list:\n",
    "        paragraph_encoded = model.encode(paragraph)\n",
    "        similarity_score = round(util.pytorch_cos_sim(title_encoded, paragraph_encoded).item() * 100)\n",
    "        paragraph_dict[paragraph] = similarity_score\n",
    "    return paragraph_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performing context similarity check with all paragraph lists.\n",
    "library_list = [library_sample_check_list, library_sample_check_list_2, library_sample_check_list_3,library_sample_check_list_4]\n",
    "library_sentence_transformer_list = []\n",
    "for list_var in library_list:\n",
    "  library_sentence_transformer_list.append(library_sample_check_function_new_sentence_model(list_var, title))\n",
    "for var in library_sentence_transformer_list:\n",
    "  print(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from anytree import NodeMixin, PreOrderIter, PostOrderIter, findall_by_attr, NodeMixin, find as find_node\n",
    "from converting_RKT_ACT import ACTNode, RKTNode, load_tree, write_rkt_to_json, display_table \n",
    "import random\n",
    "from GPT_assistant.score_01 import SR_01_Assistant\n",
    "from GPT_assistant.score_100_whole import SR_100_WHOLE_Assistant\n",
    "from GPT_assistant.score_100 import SR_100_Assistant\n",
    "import re\n",
    "rkt_tree = load_tree(\".\\\\output\\\\v2_short_RKT_with_scores_withweek1t03.json\", RKTNode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999999999999998\n"
     ]
    }
   ],
   "source": [
    "print(rkt_tree.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[{'id': '.1.1.1.1', 'score_source_id': 1, 'score_source': 0.7, 'influence_of_scoring': 0.07777777777777777, 'rewarded_score': 1.0, 'related_part': '7.4', 'reason': ': The text describes an assignment given in Week 1 to study problems related to face recognition systems.'}, {'id': '.1.1.1.2', 'score_source_id': 1, 'score_source': 0.7, 'influence_of_scoring': 0.07777777777777777, 'rewarded_score': 1.0, 'related_part': '7.4', 'reason': ': The text describes the kick start of the project and multiple happenings and discussions in Week 1, fulfilling the criterion.'}, {'id': '.1.1.1.3', 'score_source_id': 1, 'score_source': 0.7, 'influence_of_scoring': 0.07777777777777777, 'rewarded_score': 1.0, 'related_part': '7.2', 'reason': ': Describes connections with mentor and other attendees, plus team work involved—meeting the criterion of communication experience.'}], [{'id': '.1.1.2.1', 'score_source_id': 1, 'score_source': 0.7, 'influence_of_scoring': 0.07777777777777777, 'rewarded_score': 1.0, 'related_part': '7.8', 'reason': ': Details an assignment in Week 2 involving creating a database using TensorFlow and keras data augmentation techniques.'}, {'id': '.1.1.2.2', 'score_source_id': 1, 'score_source': 0.7, 'influence_of_scoring': 0.07777777777777777, 'rewarded_score': 1.0, 'related_part': '7.8', 'reason': ': Describes multiple events in Week 2, including project discussions, task assignments, and learning sessions, meeting the criterion.'}, {'id': '.1.1.2.3', 'score_source_id': 1, 'score_source': 0.7, 'influence_of_scoring': 0.07777777777777777, 'rewarded_score': 1.0, 'related_part': '7.8', 'reason': \": Details discussions and interactions with a mentor about the project's objectives and tasks, constituting connection and communication.\"}], [{'id': '.1.1.3.1', 'score_source_id': 1, 'score_source': 0.7, 'influence_of_scoring': 0.07777777777777777, 'rewarded_score': 1.0, 'related_part': '7.9', 'reason': ': The text details assignments and activities concerning database creation and data augmentation specifically in Week 3.'}, {'id': '.1.1.3.2', 'score_source_id': 1, 'score_source': 0.7, 'influence_of_scoring': 0.07777777777777777, 'rewarded_score': 1.0, 'related_part': '7.9', 'reason': ': Details multiple happenings, events, and tasks clearly described for Week 3, including database creation and discussions on data processing techniques.'}, {'id': '.1.1.3.3', 'score_source_id': 1, 'score_source': 0.7, 'influence_of_scoring': 0.07777777777777777, 'rewarded_score': 1.0, 'related_part': '7.9', 'reason': ': Clearly details connections and communication experiences with the mentor and peers involving group collaboration on database creation during Week 3.'}]], {'id': '.1.2', 'score_source_id': 2, 'score_source': 0.3, 'influence_of_scoring': 0.3, 'rewarded_score': 1.0, 'related_part': '7.2', 'reason': ': Mentions the detailed description of tasks assigned and learning objectives delivered, which relate to assignments in Week 1.'}]\n"
     ]
    }
   ],
   "source": [
    "print(rkt_tree.main_reason)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_list(nested_list):\n",
    "    flat_list = []\n",
    "    for item in nested_list:\n",
    "        if isinstance(item, list):\n",
    "            flat_list.extend(flatten_list(item))\n",
    "        else:\n",
    "            flat_list.append(item)\n",
    "    return flat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_main_reason = flatten_list(rkt_tree.main_reason)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for reason in flat_main_reason:\n",
    "    print(reason.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_node_by_id(root, target_id):\n",
    "    for node in PreOrderIter(root):\n",
    "        if node.id == target_id:\n",
    "            return node\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:  based on simplest criterion number with ID .1.1.1.1 which is: Week 1 Subsection (essential) should cover at least one assignment, task, or activity from score source: 0.7\n",
      "\n",
      "has been gain 1.0 from 7.4 part of the answer\n",
      "\n",
      "because of the reason: : The text describes an assignment given in Week 1 to study problems related to face recognition systems. \n",
      "\n",
      "\n",
      "\n",
      "2:  based on simplest criterion number with ID .1.1.1.2 which is: Week 1 Subsection (essential) should cover at least one happening, event, or observation from score source: 0.7\n",
      "\n",
      "has been gain 1.0 from 7.4 part of the answer\n",
      "\n",
      "because of the reason: : The text describes the kick start of the project and multiple happenings and discussions in Week 1, fulfilling the criterion. \n",
      "\n",
      "\n",
      "\n",
      "3:  based on simplest criterion number with ID .1.1.1.3 which is: Week 1 Subsection (essential) should cover at least one connection and communication experience with others and organizations from score source: 0.7\n",
      "\n",
      "has been gain 1.0 from 7.2 part of the answer\n",
      "\n",
      "because of the reason: : Describes connections with mentor and other attendees, plus team work involved—meeting the criterion of communication experience. \n",
      "\n",
      "\n",
      "\n",
      "4:  based on simplest criterion number with ID .1.1.2.1 which is: Week 2 Subsection (essential) should cover at least one assignment, task, or activity from score source: 0.7\n",
      "\n",
      "has been gain 1.0 from 7.8 part of the answer\n",
      "\n",
      "because of the reason: : Details an assignment in Week 2 involving creating a database using TensorFlow and keras data augmentation techniques. \n",
      "\n",
      "\n",
      "\n",
      "5:  based on simplest criterion number with ID .1.1.2.2 which is: Week 2 Subsection (essential) should cover at least one happening, event, or observation from score source: 0.7\n",
      "\n",
      "has been gain 1.0 from 7.8 part of the answer\n",
      "\n",
      "because of the reason: : Describes multiple events in Week 2, including project discussions, task assignments, and learning sessions, meeting the criterion. \n",
      "\n",
      "\n",
      "\n",
      "6:  based on simplest criterion number with ID .1.1.2.3 which is: Week 2 Subsection (essential) should cover at least one connection and communication experience with others and organizations from score source: 0.7\n",
      "\n",
      "has been gain 1.0 from 7.8 part of the answer\n",
      "\n",
      "because of the reason: : Details discussions and interactions with a mentor about the project's objectives and tasks, constituting connection and communication. \n",
      "\n",
      "\n",
      "\n",
      "7:  based on simplest criterion number with ID .1.1.3.1 which is: Week 3 Subsection (essential) should cover at least one assignment, task, or activity from score source: 0.7\n",
      "\n",
      "has been gain 1.0 from 7.9 part of the answer\n",
      "\n",
      "because of the reason: : The text details assignments and activities concerning database creation and data augmentation specifically in Week 3. \n",
      "\n",
      "\n",
      "\n",
      "8:  based on simplest criterion number with ID .1.1.3.2 which is: Week 3 Subsection (essential) should cover at least one happening, event, or observation from score source: 0.7\n",
      "\n",
      "has been gain 1.0 from 7.9 part of the answer\n",
      "\n",
      "because of the reason: : Details multiple happenings, events, and tasks clearly described for Week 3, including database creation and discussions on data processing techniques. \n",
      "\n",
      "\n",
      "\n",
      "9:  based on simplest criterion number with ID .1.1.3.3 which is: Week 3 Subsection (essential) should cover at least one connection and communication experience with others and organizations from score source: 0.7\n",
      "\n",
      "has been gain 1.0 from 7.9 part of the answer\n",
      "\n",
      "because of the reason: : Clearly details connections and communication experiences with the mentor and peers involving group collaboration on database creation during Week 3. \n",
      "\n",
      "\n",
      "\n",
      "10:  based on simplest criterion number with ID .1.2 which is: For subsection week 1, include information related to assignments from score source: 0.3\n",
      "\n",
      "has been gain 1.0 from 7.2 part of the answer\n",
      "\n",
      "because of the reason: : Mentions the detailed description of tasks assigned and learning objectives delivered, which relate to assignments in Week 1. \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for reason in flat_main_reason:\n",
    "    i = i+1\n",
    "    x = find_node_by_id(rkt_tree, reason.get('id'))\n",
    "    print(str(i) + \":  based on simplest criterion number with ID \" + reason.get('id') + \" which is: \" + x.criteria + \" from score source: \" + str(reason.get('score_source')) + \"\\n\")\n",
    "    print(\"has been gain \" + str(reason.get('rewarded_score')) + \" from \" + reason.get('related_part') + \" part of the answer\\n\")\n",
    "    print(\"because of the reason: \" + reason.get('reason') + \" \\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the text file in write mode (this will overwrite existing files with the same name)\n",
    "with open('.\\\\output\\\\output.txt', 'w') as file:\n",
    "    i = 0\n",
    "    for reason in flat_main_reason:\n",
    "        i += 1\n",
    "        x = find_node_by_id(rkt_tree, reason.get('id'))\n",
    "        file.write(f\"{i}: based on simplest criterion number with ID {reason.get('id')} which is: {x.criteria} from score source: {reason.get('score_source')}\\n\")\n",
    "        file.write(f\"has been gain {reason.get('rewarded_score')} from {reason.get('related_part')} part of the answer\\n\")\n",
    "        file.write(f\"because of the reason: {reason.get('reason')} \\n\\n\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
