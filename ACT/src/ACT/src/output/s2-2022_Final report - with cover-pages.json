{
    "id": "1",
    "name": "Reflective journal Entities",
    "nodeType": "section",
    "text": "week 1 \ndescription \nthe first goal to be achieved during this week was to complete the onboarding procedure, which was \nimportant in order to receive the company account and access to the internal system. the second goal \nwas to create an internship project plan regarding truuth’s liveness data augmentation. this project \nplan would be included in my internship proposal and provide high-level milestones for my future work \nprogress and reference. \nthe first day of my internship started with a virtual meet & greet session with the team including the \nceo mike, the liveness team lead, also my direct supervisor, matineh and two other interns, jennifer \n15 \n \nand arunabh. i was briefly introduced the company’s products, goals, functions, team members and \neach person’s role and tasks. then, for the next session, matineh held a mini workshop on how to use \nthe confluence page to document our work and how to access and use the amazon web services \nmachine learning platforms (sagemaker) to obtain the data and create notebooks to train and deploy \nmodels. in addition, during this week, i spent some time to complete some forms and go through the \npolicy and security procedures of the company. \nthe outcomes of my first week consisted of finishing the onboarding steps, getting to know my \ncolleagues at truuth, learning about the internal system, and submitting my project plan. \ninterpretation \nthe first week always came with a large amount of new information. it was my first time ever being \nexposed to atlassian’s confluence and aws’s platforms. i learned that i must always close the \nnotebook properly as aws charged the usage per hour. there were instances of companies being \ncharged an absurd amount just because someone forgot to end the working session. additionally, i \nlearned about the gantt chart and how to use it for scheduling the project tasks and milestones. \nevaluation \nlearning new things was always exciting for me. first of all, my first-hand experience with aws was \ndefinitely interesting and useful for my career as it was commonly used in companies. second, \nestablishing a plan for my internship project was helpful as it gave me a better insight on each step \nrequired to carry out the project. third, it was also enjoyable to meet with mike and matineh, who were \nthe experienced professionals in the industry. i believed that i would learn a lot from them in terms of \nbusiness perspectives, technical knowledge, and professional mannerisms. \nwhile it was rewarding, getting acquainted with my new colleagues was difficult for me at the same \ntime as i was more of an introvert person and was not good at starting the conversation. i also felt \nintimidating as an inexperienced intern when i learned that we would have to report daily to not only \nmatineh, but also mike and that he would frequently join our daily catchup. in addition, although it was \nnot really a difficult experience, waiting for the company account and the system access to be granted \nwas a long process. the related response and communication often arrived late and outside of the \nbusiness hours. i realized that this situation tended to happen when these tasks involved outsourcing the \nexternal service. \nplanning \nthe first and foremost task for the following week involved conducting a deep literature review on the \ncurrent state-of-the-art academic papers on the general adversarial networks (gans) on human face \nimages. thereon, i would classify the relevant gans into different functions and build a comprehensive \nlist accordingly. \n \nweek 2 \ndescription \nthe goal to be accomplished for the second week mainly involved reviewing the current state-of the-\nart general adversarial network (gan) models that were developed for generating synthetic human face \nimages. during the process, i needed to build a list of potential gans that were relevant to the project \nand categorize their functions. ultimately, i was required to document the summary of each gan along \nwith their pros and cons and any technical challenges. \nthe activities first involved researching on the most advanced and high-performing gans that were \nrelevant to my project problem. i looked through various recent articles from different online sources, \n16 \n \nmainly on google scholar and paper with codes. once i found a seemingly useful gan, i noted its \nname and the main application as well as the paper and code links. then, i proceeded to group these \nmodels into different categories, such as age, gender, race, and gender.  \nhere, i divided the task with arunabh, in which each of us would carry out the individual review on \ndifferent gans to be more efficient. next, i carefully read, summarized, and compared each gan in \nthe same category with special notes on the training and execution time and requirements. i created a \nconfluence page for both of us to record our summaries and findings regarding the relevant gan \nmodels. finally, we briefly presented our work to mike and matineh during the meetings. \nthe outcomes of this week included a thorough review and comparison between different gan models \non creating synthetic human face images, which comprised the summary of the paper and the model \narchitecture, the advantages and disadvantages, the technical gaps, the datasets required, special notes \non the training process and the links to other relevant materials. \ninterpretation \nduring the second week, i had to take in a massive amount of knowledge regarding to the conceptual \nframework of different general adversarial networks. i also gained some skills in online researching for \nthe suitable gan models on google scholar and paper with code. this was my first-time discovering \npaper with code. it was a very useful repository that aggregated various academic papers along with \ntheir datasets and code implementation and compared their models on different performance metrics \nand scale. in addition, i acquired some experience from presenting my review to the liveness team. \nevaluation \nthe discovery of different concepts of the general adversarial networks was rewarding. i was amazed \nby the new advances in image processing and by the hyperreal quality of some synthetic image. i have \nnever questioned the mechanisms of facial changing technology before (e.g., some mobile app filters). \nhad it not been for this project, i might not be exposed to this area of machine learning so soon. besides, \nthe presentation of the review on the state-of-the-art was also a great experience as it was an opportunity \nto practice and boost my confidence in speaking and presenting in front of others. \nhowever, as i was new to this area of image processing in machine learning, understanding the new \ntechnical and mathematical concepts was a great challenge for me. i spent lots of time just to digest a \nsingle article. the task became slightly better when i found some similar patterns or structures between \nsome models and was able to connect the points.  \nanother difficult task was to get ready to speak about my literature review. i needed to arrange my \nthoughts to deliver the findings concisely and coherently. moreover, i had to prepare myself to answer \nquestions coming in later, some of which i did not even know the answer. \nplanning \nthe main task for the upcoming week would be to narrow down the list to a few best gan models for \neach category. then, the implementation and testing would start with the model for age estimation on \nface image and any trial progress would also be documented. other than that, i needed to continue to \nlook for any better model or solution to the project problem. \n \nweek 3 \ndescription \nthe main goal for the third week was to replicate the code implementation of the chosen gan technique \nin facial aging category and to document any findings or issues encountered during the process.  \n17 \n \nthe activities for this week were more technical. i started to experiment with the gra-gan model \nwhich would simultaneously transform the gender, race, and age of an input image. i attempted to find \nand use the available code and training weight on the author’s github. however, i met with numerous \nchallenges and ended up failing this task. there was a github code link for the model; however, the full \ncode implementation and instructions, the training weights and the required datasets were not provided. \nthe option of training the model from scratch was also not viable because it took the authors around \none week to train the model with the full gpu processing capacity.  \nsimilarly, arunabh also experienced several difficulties in doing the same task on a different gan (i.e., \nage-cgan). the other models we found also had the same issues. at this stage, we reached a dead end \nand upon the daily meeting, we were advised by matineh to only look at the models with the full code \nand pre-trained weights available to deploy the model directly and avoid building everything from \nscratch. i went back to explore other possible solutions since then. \nthe primary outcome of this week was the failure to implement the gra-gan model and the \nrealization of a multitude of possible technical gaps associated with replicating the academic papers. \nupon digesting the paper in more depth, i also discovered several other issues associated with the state-\nof-the-art gans for the style-based racial transformation. for example, the quality of the generated \nimages from the current best models was still insufficient as the output clearly exhibited much irregular \nand unrealistic acuity to the human eyes. additionally, the final output was a transformed centered crop \nof the input image and not yet a complete face. hence, although the model was a state-of-the-art, it was \nyet applicable to the real-life business cases. \ninterpretation \nthis week, i gained a lot of new experience from the technical task. firstly, the majority of gans was \nimplemented using in pytorch, of which i was completely unfamiliar. so, i spent some time to search \nand pick up some basics from a brief online guide. secondly, i obtained some skills in finding the \nsources of different face datasets and how to read different types of zipped data (e.g., .tar files). thirdly, \ni learned what to look out for in my next gan research attempt from the mistakes and errors \nencountered during my failure. finally, although i decided to discard this solution, i had had better \nunderstanding of gra-gan and its issues from this trial. \nevaluation \nsince it was not a very fruitful week, there was not much rewarding experience to be spoken of. the \nonly fact i could be slightly proud of would be the success in discovering and reading a new type of \ndata file. i suppose i could think of this mini accomplishment as gaining a reusable skill in reading the \ndata before model implementation. \nit was certainly a difficult week when all i could report to the team was about my failed experiments. i \nhad to let go of an unsuccessful solution and i felt quite disappointed in myself for not being capable \nenough to solve the problem. at the same time, i acknowledged that this was just one tiny bit of the \nmany challenges that people in research roles would meet. this made me to further appreciate the skills \nand persistence of the researchers, innovators, and pioneers.  \nadditionally, i also experienced technical challenges in handling pytorch codes. i did not have sufficient \ntime to learn the basics thoroughly and could only learn as much as i went. finally, the subpar image \nquality of most of the gans’ output popped up as a significant novel challenge to be solved. \nplanning \nthe focus for the following week would be to find a new direction to the project. in other word, i should \nresearch and come up with a new model solution to the business problem. \n \n18 \n \nweek 4 \ndescription \nthe primary goal for the fourth week was to identify a new approach to solve the dataset problem. the \nnew gan model should have at least all the necessary codes, training weights and partial datasets \navailable. \nmy activities for this week started with looking for the alternative gan solutions that were: (1) the \nmost recent state-of-the-art, (2) capable of full replication, (3) producing sufficiently high-quality \noutput, and (4) satisfying other criteria related to my project problem. this time, i did not just look at \nthe academic papers only, but also visited other sources, such as webpages, blogs, and videos regarding \ngans for human face images.  \ni found stylegan, first developed by nvidia in 2019, was one of the current best state-of-the-art and \nwas being implemented for generating realistic human ai face photos for real-life uses. this model \napproach ticked most of the boxes and had the best output quality compared to all previous models i \nfound so far. however, it still raised a material concern due to its unconditional characteristic that gave \nthe users little control over the aspects of the generated photos.  \ni had a lot of discussions with arunabh throughout the process and brought up these findings with the \nteam during the meetings. i was suggested by matineh to give it a go but also paying attention to the \nmodel-specific issue at the same time. \nthe outcomes of the week included the thorough review, documentation and discussions regarding the \nstyle-based generator and its variants. i added a new category for unconditional gans to the current \nconfluence page and documented all the relevant summaries and notes. \ninterpretation \nduring the fourth week, i gained the knowledge about the style-based generator and some of its variants \n(e.g., stylegan2). i learned about its conceptual framework, findings, and results through a variety of \nchannels, such as the original paper, the github and the introductory videos. i also noticed that the \nstylegan was one of the prevailing approaches that attracted significant attention and focus for further \nfuture development. \nevaluation \nthe discovery of the style-based generators was eye-opening to me. i was amazed by nvidia’s \ninnovation and progress in creating the stylegan architecture and by its impressive synthetic human \nimages with a high resolution and a realistic look that was indistinguishable to the human eye. \nfurthermore, it was a relief to find a prospective novel solution to the project. this temporarily got me \nout of the roadblock i encountered last week. \nas usual, it was challenging for me to quickly grasp and digest the new technical concepts. but i found \nthe task easier this time thanks to my learning experience with other models in the previous weeks.  \nhowever, the main anxiety came from the new concern about the characteristics of the style-based \ngenerators. as this matter was not a concern to the model’s original purposes, but was specific to our \nuse case, i was unsure how to tackle it. nevertheless, i would research more next week to broaden my \nknowledge and perspective and to come up with some useful ideas. \nfinally, it was slightly worrisome when i realized that the progress and performance of the current state-\nof-the-art conditional gans were still far behind the unconditional ones, especially in terms of the \nimage quality. this would leave me with limited feasible solutions for my project problem. \n19 \n \nplanning \nthe main task for the next week would be to carry out extensive study and to prepare for the \nimplementation of the style-based generators. i needed to figure out whether the stylegan approach \ncould actually address our project problem. \n \nweek 5 \ndescription \nthe goals to be accomplished for the fifth week were primarily to conduct research to validate the \nstylegan approach to truuth’s data augmentation case and to propose an actionable solution \naccordingly.  \nmy activities for this week started with reviewing the details in the literature of the style-based \ngenerators again, noting down their weaknesses and some known issues and finding any of its active \nimplementations. from my discussions with arunabh, we both found that almost any gans, even the \nhigh-performing ones, would perform poorly on a small dataset, and that the distribution of the final \noutput of stylegans would depend on the original distribution of the input dataset. this meant that \nstylegan could produce a biased set of images given an imbalanced initial dataset, which added \nconcerns to the current challenges of our project. \nthen, we proceeded to look for the relevant works on handling these issues. we compared our findings \nand agreed upon a set of different solutions with both unconditional and conditional gan approaches. \nwe then presented our findings and proposed solutions to mike and matineh during our meetings.  \nthe outcomes of the week included offering a set of potential solutions to our project problem. arunabh \ncreated a new confluence page for us to document the proposed solutions along with the rationale and \nthe reference of the related academic papers and techniques. however, we were not completely \nsuccessful with our deliverables, which would be described in more detail in the difficult experience \npart. \ninterpretation \nfor this week, i gained some more comprehensive knowledge about the style-based generators, \nspecifically stylegan2 and its known issues. in addition to the papers that debugged the biased \nproblem of the stylegan2, i found some relevant supporting frameworks, such as pixel2style2pixel, \nwhich assists in mapping different types of input images to the latent space required in the style-based \narchitectures. \nevaluation \na rewarding experience for this week was that we had materialized our research so far into a clearer set \nof different approaches for the project problem. i felt better that our approaches were narrowed down \nand became more explicit. \nthe difficult experiences stemmed from several major challenges we met this week. first of all, i had \nyet found an answer for ensuring a certain criterion of the output generated under the approach using \nthe unconditional gans. secondly, i was yet able to solve the issues of the current conditional gans \napproach. moreover, i was quite disappointed to find that there was little to no disclosure of the real-\nlife cases of using the gan-based augmented datasets in facial liveness recognition, let alone the \nstylegan-based. the only paper we found was the application in the medical domain on x-ray and \nct scan images, which was quite far from our business case.  \n20 \n \nhence, it might have looked uncertain when we discussed our solutions during the team meeting. mike \nsaid he felt confused and questioned the current prospects and application of gan-based approaches to \nenlarge the dataset. he would like us to come up with a recommendation on how to move forward with \nthe project in the upcoming week. if necessary, we might need to set aside the current project idea and \nturn to a different project problem. \ni was intimidated by his remarks, but i understood that he wanted the better for all of us. it was likely \nthat, from his experience working with the r&d team, he might have caught a sense of uncertainty of \nwhere the project was heading at this stage.  \nplanning \nfrom mike’s feedback, my task for the following week would be to re-evaluate and validate the current \napproach to see if it can bring forward a tangible outcome and to propose how to either move forward \nwith or move on from the current approach. \n \nweek 6 \ndescription \nthe main goal for the sixth week involved offering recommendations on how to proceed further with \nthe ongoing project. i needed to check whether the general idea of using gans to expand the dataset \nwas feasible for our business case and determine what the next steps would be.  \nmy activities for the week started with finding and reviewing the literature in the practice of data \naugmentation for facial recognition and relevant tasks. i was still unable to find any research on the \napplication of gan to enlarge the live datasets in the facial liveness tasks. however, i discovered \nseveral papers that adopted gan techniques to generate spoofing data for the facial liveness tasks. on \nthe other hand, i found more experiments on using gan-based data augmentation for other facial \nrecognition tasks, more prominently in identity verification (e.g., face, iris, and fingerprints).  \nfrom my findings, i answered mike’s question on the feasibility of using gan to augment the dataset \nfor the facial liveness task and proved that there would be merits to truuth’s business case if the solution \ncould be implemented successfully. then, we discussed with mike on the next steps and settled upon \ntrying one approach for the next phase. at the end, mike asked for the hypotheses and the more detailed \nproposal of the chosen gan approach to enlarge the dataset. \nthe outcomes of this week were: (1) the validation of the feasibility of our current project and approach, \nand (2) the agreement on the next steps and the solution to be focused on for implementation and testing. \ni created a new confluence page that documented my reviews and comments on the current progress \nof using gan-based augmented datasets for relevant facial recognition tasks and another page for the \nnext steps to be carried out that were suggested by mike. \ninterpretation \nfor this week, i learned more about the case-specific application of gan models in facial recognition \ntasks. i also discovered a few approaches that addressed the challenges of stylegan2 in dealing with \nthe minority class. i also gained valuable experience in how to bring up the problem and solution more \neffectively through our team interaction with mike. more importantly, i also got to understand more \nabout mike’s viewpoint. \n21 \n \nevaluation \ni was happy to learn some use cases of gans model in facial recognition tasks. even though there was \nno result that exactly matched our business problem, the cases i found were close enough to relate and \ncheck the effect of the gan application.  \nadditionally, i felt excited about some interesting experiments where gans were used to generate the \nenhanced spoof image for the facial liveness task either from just spoof images with different \npresentation attack instruments or the mixture of the live and spoof images. this indicated that there \nwere valid approaches in applying the gan architectures to augment the spoof datasets.  \nfinally, i also felt relieved after getting mike’s understanding of our progress and challenges and having \nreached an agreement and clarity on what we were supposed to do next. \nthe most difficult experience for me during this week was the first meeting with mike. although i had \nquite anticipated it, i still experienced some anxiety and pressure, especially when knowing that there \nwas no available academic paper that had the matching application for us to refer the whole approach \nto and for mike to have a quality assurance. \nbefore the meeting, i and arunabh had briefly discussed what to present to mike. however, there was \ninsufficient time to bring up everything in the short meeting, and mike had to leave early for another \nclient meeting. we were not able to convey all our findings and that meeting became tense as we did \nnot deliver what mike had expected from us.  \ni also felt guilty for letting arunabh initiating that meeting alone and feeling depressed afterwards. i \ndid not find the chance to have a word to clarify and support his discussion during that meeting. so, i \ndecided to initiate the talk for the next meeting and paved the way for arunabh’s pitch by briefly \nexplaining to mike why we could not find one perfect paper/solution that matched exactly our business \nproblem. then, arunabh could proceed to talk about several proposed solutions that we had come up \nwith before. \ni was glad that the second meeting became smoother. however, i understood what mike was worried \nabout. it was rather easy to get lost in the research phase and it was his role to prevent us from jumping \ninto that rabbit hole. \nplanning \nthe tasks for the upcoming week involved creating a more detailed approach with the selected gan \nmodel and proposing some hypotheses to better visualize and crystalize the outcomes of implementing \nthe solution from the available data and knowledge. \n \nweek 7 \ndescription \nthe main goals for the seventh week involved building a more comprehensive approach with the \nselected gan model and providing some hypotheses to better visualize the outcomes of implementing \nthe solution from the available data and knowledge. \nthis week was rather special. everyone in our team, including arunabh, jennifer and i, would \nparticipate in a cyber security hackathon on thursday and friday. so, on monday, we asked mike and \nmatineh for the permission to be absent and reduce the workload for this week.  \nsince i was busy with mid-term assignments and hackathon, not much work had been done and there \nwas nothing new to report with the team. what i did during the first half of the week was mainly the \n22 \n \nextension of the previous week. i tried to refine the last proposal and draft up some hypotheses regarding \nhow much the original dataset could be enlarged from implementing a transformer gan. additionally, \ni found some new models that might enhance and address the issues of stylegan2. \nthen, on the first day of the hackathon, we met mike for the first time in person. he attended the \nhackathon for half of the day. matineh was also present at the event as a member of big data society \n- the organizing team. together with the truuth cohorts, we had conversations about the company, their \nupcoming plan and about their position and ambition in the data security and biometric market. on the \nsecond day, we took part in the data lake security challenge, presented our solution, and luckily got \nthe second place in the data lake security challenge. \nthe outcomes of this week were: (1) the refined proposed approach for data generation, and (2) the \nhypotheses on the new dataset size. \ninterpretation \nat first, we were quite nervous about asking mike to delay our work for our hackathon attendance. but \nit turned out that he was very supportive of such events and really encouraged us to join. i realized that \nmike always tried his best to keep updated with the industry and expand his networks with clients, \ninvestors, and partners. despite his busy schedule, he still sat the hackathon for a morning to connect \nwith the guest speakers. \nfrom the casual conversation with mike, i was deeply impressed by the way he carried his pitch about \ntruuth, which really showed his persuasion and entrepreneurial skills. he managed to inspire our \nhackathon team, most of whom were also truuth’s interns. hence, we tried to incorporate truuth’s \nbusiness solution as part of the security layers and developed further on it. this really validated his \nability to influence people. \nevaluation \nfor this week, i experienced a lot of things for the first time. i had never participated in a hackathon \nevent or gone in-depth into the cyber security topics before. this is also my first-time tackling a less-\n24-hour challenge and having to speak in front of such a large audience of almost 100 people. this \nhackathon event was a great learning curve for me. it was challenging but also eye-opening. i again \nfeel thankful towards prof. amin, mike and matineh, as well as my teammate, for enabling me to join \nthis event. \nplanning \nfrom this week’s experience, i realized the great benefits of joining hackathons and seminars. i decided \nthat i would always do my best to attend and make use of the similar opportunities in the future. \nmoreover, learning from mike, i would also work on improving my communication and networking \nskills and take every chance to connect with others in the industry. \nthe tasks for the upcoming week mainly involved generating synthetic images with a gan model of \nour choice. \n \nweek 8 \ndescription \nthe main goal for week 8 was to start experimenting with our first choice of gan model. \nwe did not have a good start for this week as i got a flu and arunabh tested positive for covid. so, we \ngave a prior notice to the team and were absent from the monday meeting. i returned to work on \nwednesday, when i felt slightly better, and my head was clearer. \n23 \n \ni looked for the official stylegan2 implementation on github and began my replication attempts. the \nprocess did not go smoothly. the first problem we needed to tackle was obtaining the dataset. we were \ngiven the path to the dataset in one of the sagemaker notebooks. however, we found that we could not \nmove or import the dataset directly from one notebook instance to another. hence, we had to zip the \ndata file in the original notebook, downloaded it to our local machine, then uploaded and unzipped it in \nour working instance. only then could we get to start working with the gan model. \nagain, i met a lot of technical challenges when i began implementing the gan model following the \nofficial github instructions. they were mainly incompatible configuration issues between the \nrequirements for stylegan2 code implementation and aws sagemaker platform. for example, the \nimplementation required tensorflow 1.14, while amazon only offered tensorflow 2.0. at this stage, i \nput my work on hold for next week. \nthe outcomes of this week included getting the dataset in the right location and having the partial \nstylegan2 working codes on aws sagemaker notebook. \ninterpretation \ni felt bad about being sick and absent, but my supervisors were very understanding about our \ncircumstances. this made me relieved, but at the same time, slightly worried about slowing our work \nprogress. this led us to try to catch up as soon as we got better. \nat first, when i got hold of the github repository, i was very excited, thinking that the implementation \nprocess would go smooth and i could take what i learned in class (i.e., tensorflow) to practice. but \nthe reality did not turn out as expected. working on aws sagemaker was more complicated than i \nexpected, even from the very first step of transferring data and setting up the configuration for running \nthe model. \nevaluation \nworking with aws notebook instances was a whole new experience for me. i was totally caught off \nguards thinking that it would be the same as working with anaconda jupyter notebooks. i realized \nthat i was thinking too simple and there were far more variables that i had not anticipated. \nnonetheless, the concrete knowledge that i acquired during this week was the method of transferring \nand extracting data from another notebook instance. \nplanning \nfrom this week’s lesson, i got a better hold of my technical gaps and the need for a technical \nupskilling in the future. i plan to take some introductory courses to aws cloud platforms and to do \nmore individual projects in order to gain more technical knowledge and experience. \nthe tasks for the upcoming week would still focus on the successful implementation of gan(s).  \n \nweek 9 \ndescription \nthe main goal for week 9 was to successfully generate synthetic faces from a gan model. if \nsuccessful, we would also be required to evaluate the outcomes using suitable evaluation metrics. \ni continued from the technical challenges that i encountered last week. i searched for the solutions to \nconfiguration setups online. i found some tutorials on implementing stylegan2 on different datasets \nand github issue threads of people having the same problems. however, all tutorials and the majority \nof users ran the model on google colab platform, which was very different from sagemaker. hence, \n24 \n \nsome of their available solutions were not applicable to our case. i tried all different solutions following \nthese threads, tutorials, and stackoverflow. in the end, i managed to install all of the required \nconfigurations, but the code did not work.  \ni proceeded to fixing some apparent errors, such as loading data and resizing images to the required \ninput size. then, i reached to a dead end with the error of “gpu not found”. i attempted all sort of ways, \nensuring the gpu was available, and even changing the “custom_ops” setup code from “gpu” to “xla \ngpu” to match with the aws gpu devices. the code progressed to one additional line and stopped \nfunctioning again with a new bug. at this point, we decided to stop and looking for an alternative. \nin addition to working on the gan implementation, we started looking into image sharpening methods \nand found some gans (e.g., sr-gan) that could enhance the image resolution. \nthe outcomes of this week included the partial stylegan2 working codes on aws sagemaker \nnotebook and a brief review in some super resolution gans. \ninterpretation \nhaving encountered a number of technical difficulties, our experiment on stylegan2 came to a \nstandstill. we felt lots of pressure to produce an output as we had no progress to report to mike this \nweek and the internship was coming to an end soon. i felt disappointed and frustrated with myself, but \nnothing more could be done for that piece of code. we asked matineh for technical help, but despite \ntrying her best, she was not able to solve our problems either. we had to accept and move on. \nevaluation \nthis was a challenging week both technically and mentally. my failure led to doubts in myself. i \nagain realized my technical incompetency and knowledge inadequacy. regardless, this week was a \ngood lesson. i learned some tips on how to customise the default configuration of amazon and how to \nuse kernel to solve this issue. besides, i found myself lucky that i was not alone in this project. i had \narunabh to discuss, share and overcome our roadblocks together. \nplanning \nthis week’s failure further reinforced my plan and determination to improve my technical skills \nwhenever i have spare time in the future.  \nthe tasks for the upcoming week again involved generating the gan transformed faces. additionally, \nwe would also research more on gans that boost image quality. \n \nweek 10 \ndescription \nthe main goal for week 10 was still attempting to succeed in implementing gan model on truuth’s \ndataset.  \ndue to last week’s failure, we decided to turn to another alternative of stylegan2 – the adapted pytorch \nversion, instead of the original tensorflow version, as it was said to be less buggy.  \ni looked up and followed any available online tutorials and github instructions to run the model. yet, \nwith the pytorch version, i still met with configuration issues. reading all these relevant threads on \ngithub issues, i managed to install all the required configurations, including the correct cuda and \npytorch versions. however, the problem lay with the library package itself. the necessary library was \nbased on c++, which was incompatible with the g linux platform of aws sagemaker. \n25 \n \nlearning from the last lesson, we decided to only spend a few more days with this code and tried to \nfind and move on to a new solution quickly, since we did not have much time left. since the tutorials \nand threads on google colab were dominant, i decided to carry out a quick stylegan2 implementation \non my google colab instead aws platform. this time, i was successful in making the model run, \nthough not able to train on truuth’s dataset due to the free gpu limit. i reported this result to matineh \nand she agreed that the next intern could collaborate with the engineering team to work on this \nstylegan2 solution again. \napart from this side experiment, we looked at different adapted versions of stylegan2 and found two \npromising style-based age and gender transformer gans with full implementation code and training \nlayers. we decided to test that during the next week. \non the other note, we found a public api that deployed a super resolution gan model to deblur the \ninput image. the api returned a satisfactorily sharp image when we tested it with a blurry sample. we \nreported the results to the team and matineh was very happy with it. we then proceeded to build a \nsimple pipeline connecting with the api to enhance the quality of any truuth’s image dataset. \nthe outcomes of this week included: (1) the partial stylegan2 working codes for the pytorch version \non aws sagemaker notebook and google colab and (2) a pipeline to deblur input images using a \npublicly available and accessible api. \ninterpretation \nthis week, we still failed to produce a tangible output, but the mood was slightly better than the \nprevious week. i assume it was due to the fact that we were not dead set on one solution. since we \nresolved to move on from our ideal solution once, we felt less for the second time. additionally, we \ngot our hope up with the two newly found transformers, so we did not fall into a desperate state with \nno backup. nevertheless, the pressure remained stronger than before as deadline was approaching and \nmike and matineh still had expectations for our project. \nevaluation \nthis was another technically challenging week but less intensive than before. i knew my limits and \ntook the better course of actions in accordance with those limits. i was able to be more productive, \nfeel less stressful and be mindful of our ultimate project goal. besides, i also acquired the interesting \ndiscovery about the super resolution gan and api. this would be particularly useful for truuth’s \nbusiness cases at any stage in both facial liveness and document verification tasks. \nplanning \ni learned a lot from the failure and this experience in many aspects, especially in terms of moving \nforward with new alternatives and staying on track with the final goal. i would employ these lessons \nin my future data science or any other projects. \nthe tasks for the upcoming week were to successfully generate the synthetic images from the newly \nfounded gan models and to start the final documentation on confluence. \n \nweek 11 \ndescription \nthe main goal for week 11 was to generate the age and gender transformed faces from truuth’s face \ndataset and to document all of our research and experiments so far on confluence pages.  \n26 \n \nthis week, we attempted to implement the two potential style-based transformer for age and gender \nwith readily available pre-trained layers we found from last week’s research. we initially met with some \ndifficulties, such as in importing the dlib library or aligning faces but were able to resolve all of them \nafterwards.  \nwe were successful in generating the single image output for both models and presented the results to \nthe team. mike and matineh were impressed with the results. mike had some concerns over the potential \nbias of gans and whether fraudulent activities may use gan-based techniques to bypass the system. \nmeanwhile, matineh was quite convinced of the use of gans in augmenting and expanding the facial \ndataset. we then held a discussion around mike’s questions. at the end of the meeting, we all agreed \non the next step to batch process the whole truuth’s dataset. \nin addition, i wrote a code to solve the problem of picking the best frame out of multiple frames for an \nimage sample, which was an important selection step of the input images. all of our input images should \nbe the frame with the best quality (i.e., highest resolution) for each live and fake samples. \nthe outcomes of this week included: (1) the working codes for age and gender single-image transformer \non aws sagemaker notebook and (2) partial documentation of our experiments on confluence. \ninterpretation \nwe felt happy and relief that we finally produced some convincing and valid results. we would not \nhave to chase a new model, but instead focus on producing larger outputs with the current models.  \nfrom our meeting with mike, i could really feel that much as being idealistic, mike was also being \ncareful with his thoughts of some worst-case scenarios from real-world gan usage. he always tried \nto look at a bigger picture and consider different possibilities altogether. this was one of the great \nqualities that i wanted to learn from him. \nevaluation \nthis is a particularly rewarding week as i knew our journey was coming to an end but not fruitless or \nempty-handed. i gained new knowledge about the two stylegan2 adapted models and a much deeper \ninsight into the facial dataset. since i passed the configuration obstacles this week, i was able to reach \nand learn better about other steps in implementing the gan models. from this successful attempt of \nimplementing the gan model, i regained a bit of my confidence. i knew that resilience was an \nimportant factor that helped me to pull through my failures and to wait for successes. this would be \nhelpful in data science research projects where many unknown variables present. \nplanning \ni find being resilient and patient would help in data science research projects where many unknown \nvariables present. along with addressing my weaknesses, i also need to refine and enhance my \nstrengths in order to climb the career ladder. \nthe tasks for the upcoming week were to start batch processing on truuth’s dataset for each transformer \nand finalise the documentation on confluence. \n \nweek 12 \ndescription \nthe main goal for week 12 included the batch processing of truuth’s face dataset for age and gender \ngan and to finish documenting the process on confluence pages.  \n27 \n \nwe slightly modified our single-image transformation code to perform batch processing. the age \ninference code was harder to deal with than the gender transformer code. but overall, we had no troubles \nfixing them. the execution took a while for gender and longer for age. \nthe only problem occurred when i happened to find out that some of the input images were mislabelled \nin the original dataset. some of the fake images were wrongly classified as live images, which would \nhave certain adverse effect on the accuracy of the liveness model. i reported my findings to matineh \nand proceeded on to perform a quality control inspection on all images. i picked out all the misclassified \ndata and relabelled them. i also created a new cleaned dataset so other people could work with this \ninstead of the faulty dataset in the future. \nafter correcting the dataset, we carried out the batch processing again as well as checking the outputs \nfor any errors or misalignment.  \ni wrote the results display and analysis on confluence to evaluate the quality of each transformer gan’s \noutputs and discuss the future improvement in the gan-based data augmentation space. apart from \nthis, we wrapped up our duties by filling in details of our main experiments and implementation on \nconfluence. we also added detailed instructions on how to run our aws notebooks for future users. \nwe had a supervisor feedback session with mike and matineh on thursday. they seemed to be happy \nwith the results and gave all of us good evaluation of our work. \nthe outcomes of this week included: (1) the working codes for age and gender single-image transformer \non aws sagemaker notebook; (2) the complete documentation of our experiments on confluence; and \n(3) the gan output analysis and evaluation report. \ninterpretation \nwe overcame the hardest part last week, so this week was just slightly building up on last week’s task \nand came smoothly for us. however, i admitted it was a mistake on our part for not checking the input \ndata beforehand. we were overconfident, assuming that the given dataset was accurate. it was lucky \nthat we spot the errors in time to make changes. \nevaluation \nthis was a rewarding week as we finally completed our project goal with good results. i also learned a \nlesson to be more careful from the start to the end point of the project and to at least have the dataset \nvalidated before processing it further. again, i felt lucky to have arunabh as a teammate on this \nproject where we overcame difficultis together and helped each other out with different parts of the \ntasks. i also felt thankful to mike and matineh for being patient with our progress, especially during \nthe weeks when we experienced roadblocks. \nplanning \ni find this internship extremely valuable. it provided me an opportunity to experience the job of a data \nscientist and to learn on the job. it also allowed me to reassess and address my strengths and \nweaknesses. finally, i plan to reinforce all the knowledge and skills gained from this internship \nexperience by practicing them in more data science projects in the future. \n",
    "page": null,
    "goal": "Reflective journal Entities",
    "children": [
        {
            "id": "1.1",
            "name": "week 1",
            "nodeType": "title",
            "text": "week 1",
            "page": null,
            "goal": "week 1",
            "children": []
        },
        {
            "id": "1.2",
            "name": "week 1 description",
            "nodeType": "paragraph",
            "text": "week 1 \ndescription \nthe first goal to be achieved during this week was to complete the onboarding procedure, which was \nimportant in order to receive the company account and access to the internal system. the second goal \nwas to create an internship project plan regarding truuth’s liveness data augmentation. this project \nplan would be included in my internship proposal and provide high-level milestones for my future work \nprogress and reference. \nthe first day of my internship started with a virtual meet & greet session with the team including the \nceo mike, the liveness team lead, also my direct supervisor, matineh and two other interns, jennifer \n15 \n \nand arunabh. i was briefly introduced the company’s products, goals, functions, team members and \neach person’s role and tasks. then, for the next session, matineh held a mini workshop on how to use \nthe confluence page to document our work and how to access and use the amazon web services \nmachine learning platforms (sagemaker) to obtain the data and create notebooks to train and deploy \nmodels. in addition, during this week, i spent some time to complete some forms and go through the \npolicy and security procedures of the company. \nthe outcomes of my first week consisted of finishing the onboarding steps, getting to know my \ncolleagues at truuth, learning about the internal system, and submitting my project plan. \ninterpretation \nthe first week always came with a large amount of new information. it was my first time ever being \nexposed to atlassian’s confluence and aws’s platforms. i learned that i must always close the \nnotebook properly as aws charged the usage per hour. there were instances of companies being \ncharged an absurd amount just because someone forgot to end the working session. additionally, i \nlearned about the gantt chart and how to use it for scheduling the project tasks and milestones. \nevaluation \nlearning new things was always exciting for me. first of all, my first-hand experience with aws was \ndefinitely interesting and useful for my career as it was commonly used in companies. second, \nestablishing a plan for my internship project was helpful as it gave me a better insight on each step \nrequired to carry out the project. third, it was also enjoyable to meet with mike and matineh, who were \nthe experienced professionals in the industry. i believed that i would learn a lot from them in terms of \nbusiness perspectives, technical knowledge, and professional mannerisms. \nwhile it was rewarding, getting acquainted with my new colleagues was difficult for me at the same \ntime as i was more of an introvert person and was not good at starting the conversation. i also felt \nintimidating as an inexperienced intern when i learned that we would have to report daily to not only \nmatineh, but also mike and that he would frequently join our daily catchup. in addition, although it was \nnot really a difficult experience, waiting for the company account and the system access to be granted \nwas a long process. the related response and communication often arrived late and outside of the \nbusiness hours. i realized that this situation tended to happen when these tasks involved outsourcing the \nexternal service. \nplanning \nthe first and foremost task for the following week involved conducting a deep literature review on the \ncurrent state-of-the-art academic papers on the general adversarial networks (gans) on human face \nimages. thereon, i would classify the relevant gans into different functions and build a comprehensive \nlist accordingly.",
            "page": null,
            "goal": "week 1 \ndescription \nthe first goal to be achieved during this week was to complete the onboarding procedure, which was \nimportant in order to receive the company account and access to the internal system. the second goal \nwas to create an internship project plan regarding truuth’s liveness data augmentation. this project \nplan would be included in my internship proposal and provide high-level milestones for my future work \nprogress and reference. \nthe first day of my internship started with a virtual meet & greet session with the team including the \nceo mike, the liveness team lead, also my direct supervisor, matineh and two other interns, jennifer \n15 \n \nand arunabh. i was briefly introduced the company’s products, goals, functions, team members and \neach person’s role and tasks. then, for the next session, matineh held a mini workshop on how to use \nthe confluence page to document our work and how to access and use the amazon web services \nmachine learning platforms (sagemaker) to obtain the data and create notebooks to train and deploy \nmodels. in addition, during this week, i spent some time to complete some forms and go through the \npolicy and security procedures of the company. \nthe outcomes of my first week consisted of finishing the onboarding steps, getting to know my \ncolleagues at truuth, learning about the internal system, and submitting my project plan. \ninterpretation \nthe first week always came with a large amount of new information. it was my first time ever being \nexposed to atlassian’s confluence and aws’s platforms. i learned that i must always close the \nnotebook properly as aws charged the usage per hour. there were instances of companies being \ncharged an absurd amount just because someone forgot to end the working session. additionally, i \nlearned about the gantt chart and how to use it for scheduling the project tasks and milestones. \nevaluation \nlearning new things was always exciting for me. first of all, my first-hand experience with aws was \ndefinitely interesting and useful for my career as it was commonly used in companies. second, \nestablishing a plan for my internship project was helpful as it gave me a better insight on each step \nrequired to carry out the project. third, it was also enjoyable to meet with mike and matineh, who were \nthe experienced professionals in the industry. i believed that i would learn a lot from them in terms of \nbusiness perspectives, technical knowledge, and professional mannerisms. \nwhile it was rewarding, getting acquainted with my new colleagues was difficult for me at the same \ntime as i was more of an introvert person and was not good at starting the conversation. i also felt \nintimidating as an inexperienced intern when i learned that we would have to report daily to not only \nmatineh, but also mike and that he would frequently join our daily catchup. in addition, although it was \nnot really a difficult experience, waiting for the company account and the system access to be granted \nwas a long process. the related response and communication often arrived late and outside of the \nbusiness hours. i realized that this situation tended to happen when these tasks involved outsourcing the \nexternal service. \nplanning \nthe first and foremost task for the following week involved conducting a deep literature review on the \ncurrent state-of-the-art academic papers on the general adversarial networks (gans) on human face \nimages. thereon, i would classify the relevant gans into different functions and build a comprehensive \nlist accordingly.",
            "children": []
        },
        {
            "id": "1.3",
            "name": "week 2",
            "nodeType": "title",
            "text": "week 2",
            "page": null,
            "goal": "week 2",
            "children": []
        },
        {
            "id": "1.4",
            "name": "week 2 description",
            "nodeType": "paragraph",
            "text": "week 2 \ndescription \nthe goal to be accomplished for the second week mainly involved reviewing the current state-of the-\nart general adversarial network (gan) models that were developed for generating synthetic human face \nimages. during the process, i needed to build a list of potential gans that were relevant to the project \nand categorize their functions. ultimately, i was required to document the summary of each gan along \nwith their pros and cons and any technical challenges. \nthe activities first involved researching on the most advanced and high-performing gans that were \nrelevant to my project problem. i looked through various recent articles from different online sources, \n16 \n \nmainly on google scholar and paper with codes. once i found a seemingly useful gan, i noted its \nname and the main application as well as the paper and code links. then, i proceeded to group these \nmodels into different categories, such as age, gender, race, and gender.  \nhere, i divided the task with arunabh, in which each of us would carry out the individual review on \ndifferent gans to be more efficient. next, i carefully read, summarized, and compared each gan in \nthe same category with special notes on the training and execution time and requirements. i created a \nconfluence page for both of us to record our summaries and findings regarding the relevant gan \nmodels. finally, we briefly presented our work to mike and matineh during the meetings. \nthe outcomes of this week included a thorough review and comparison between different gan models \non creating synthetic human face images, which comprised the summary of the paper and the model \narchitecture, the advantages and disadvantages, the technical gaps, the datasets required, special notes \non the training process and the links to other relevant materials. \ninterpretation \nduring the second week, i had to take in a massive amount of knowledge regarding to the conceptual \nframework of different general adversarial networks. i also gained some skills in online researching for \nthe suitable gan models on google scholar and paper with code. this was my first-time discovering \npaper with code. it was a very useful repository that aggregated various academic papers along with \ntheir datasets and code implementation and compared their models on different performance metrics \nand scale. in addition, i acquired some experience from presenting my review to the liveness team. \nevaluation \nthe discovery of different concepts of the general adversarial networks was rewarding. i was amazed \nby the new advances in image processing and by the hyperreal quality of some synthetic image. i have \nnever questioned the mechanisms of facial changing technology before (e.g., some mobile app filters). \nhad it not been for this project, i might not be exposed to this area of machine learning so soon. besides, \nthe presentation of the review on the state-of-the-art was also a great experience as it was an opportunity \nto practice and boost my confidence in speaking and presenting in front of others. \nhowever, as i was new to this area of image processing in machine learning, understanding the new \ntechnical and mathematical concepts was a great challenge for me. i spent lots of time just to digest a \nsingle article. the task became slightly better when i found some similar patterns or structures between \nsome models and was able to connect the points.  \nanother difficult task was to get ready to speak about my literature review. i needed to arrange my \nthoughts to deliver the findings concisely and coherently. moreover, i had to prepare myself to answer \nquestions coming in later, some of which i did not even know the answer. \nplanning \nthe main task for the upcoming week would be to narrow down the list to a few best gan models for \neach category. then, the implementation and testing would start with the model for age estimation on \nface image and any trial progress would also be documented. other than that, i needed to continue to \nlook for any better model or solution to the project problem.",
            "page": null,
            "goal": "week 2 \ndescription \nthe goal to be accomplished for the second week mainly involved reviewing the current state-of the-\nart general adversarial network (gan) models that were developed for generating synthetic human face \nimages. during the process, i needed to build a list of potential gans that were relevant to the project \nand categorize their functions. ultimately, i was required to document the summary of each gan along \nwith their pros and cons and any technical challenges. \nthe activities first involved researching on the most advanced and high-performing gans that were \nrelevant to my project problem. i looked through various recent articles from different online sources, \n16 \n \nmainly on google scholar and paper with codes. once i found a seemingly useful gan, i noted its \nname and the main application as well as the paper and code links. then, i proceeded to group these \nmodels into different categories, such as age, gender, race, and gender.  \nhere, i divided the task with arunabh, in which each of us would carry out the individual review on \ndifferent gans to be more efficient. next, i carefully read, summarized, and compared each gan in \nthe same category with special notes on the training and execution time and requirements. i created a \nconfluence page for both of us to record our summaries and findings regarding the relevant gan \nmodels. finally, we briefly presented our work to mike and matineh during the meetings. \nthe outcomes of this week included a thorough review and comparison between different gan models \non creating synthetic human face images, which comprised the summary of the paper and the model \narchitecture, the advantages and disadvantages, the technical gaps, the datasets required, special notes \non the training process and the links to other relevant materials. \ninterpretation \nduring the second week, i had to take in a massive amount of knowledge regarding to the conceptual \nframework of different general adversarial networks. i also gained some skills in online researching for \nthe suitable gan models on google scholar and paper with code. this was my first-time discovering \npaper with code. it was a very useful repository that aggregated various academic papers along with \ntheir datasets and code implementation and compared their models on different performance metrics \nand scale. in addition, i acquired some experience from presenting my review to the liveness team. \nevaluation \nthe discovery of different concepts of the general adversarial networks was rewarding. i was amazed \nby the new advances in image processing and by the hyperreal quality of some synthetic image. i have \nnever questioned the mechanisms of facial changing technology before (e.g., some mobile app filters). \nhad it not been for this project, i might not be exposed to this area of machine learning so soon. besides, \nthe presentation of the review on the state-of-the-art was also a great experience as it was an opportunity \nto practice and boost my confidence in speaking and presenting in front of others. \nhowever, as i was new to this area of image processing in machine learning, understanding the new \ntechnical and mathematical concepts was a great challenge for me. i spent lots of time just to digest a \nsingle article. the task became slightly better when i found some similar patterns or structures between \nsome models and was able to connect the points.  \nanother difficult task was to get ready to speak about my literature review. i needed to arrange my \nthoughts to deliver the findings concisely and coherently. moreover, i had to prepare myself to answer \nquestions coming in later, some of which i did not even know the answer. \nplanning \nthe main task for the upcoming week would be to narrow down the list to a few best gan models for \neach category. then, the implementation and testing would start with the model for age estimation on \nface image and any trial progress would also be documented. other than that, i needed to continue to \nlook for any better model or solution to the project problem.",
            "children": []
        },
        {
            "id": "1.5",
            "name": "week 3",
            "nodeType": "title",
            "text": "week 3",
            "page": null,
            "goal": "week 3",
            "children": []
        },
        {
            "id": "1.6",
            "name": "week 3 description",
            "nodeType": "paragraph",
            "text": "week 3 \ndescription \nthe main goal for the third week was to replicate the code implementation of the chosen gan technique \nin facial aging category and to document any findings or issues encountered during the process.  \n17 \n \nthe activities for this week were more technical. i started to experiment with the gra-gan model \nwhich would simultaneously transform the gender, race, and age of an input image. i attempted to find \nand use the available code and training weight on the author’s github. however, i met with numerous \nchallenges and ended up failing this task. there was a github code link for the model; however, the full \ncode implementation and instructions, the training weights and the required datasets were not provided. \nthe option of training the model from scratch was also not viable because it took the authors around \none week to train the model with the full gpu processing capacity.  \nsimilarly, arunabh also experienced several difficulties in doing the same task on a different gan (i.e., \nage-cgan). the other models we found also had the same issues. at this stage, we reached a dead end \nand upon the daily meeting, we were advised by matineh to only look at the models with the full code \nand pre-trained weights available to deploy the model directly and avoid building everything from \nscratch. i went back to explore other possible solutions since then. \nthe primary outcome of this week was the failure to implement the gra-gan model and the \nrealization of a multitude of possible technical gaps associated with replicating the academic papers. \nupon digesting the paper in more depth, i also discovered several other issues associated with the state-\nof-the-art gans for the style-based racial transformation. for example, the quality of the generated \nimages from the current best models was still insufficient as the output clearly exhibited much irregular \nand unrealistic acuity to the human eyes. additionally, the final output was a transformed centered crop \nof the input image and not yet a complete face. hence, although the model was a state-of-the-art, it was \nyet applicable to the real-life business cases. \ninterpretation \nthis week, i gained a lot of new experience from the technical task. firstly, the majority of gans was \nimplemented using in pytorch, of which i was completely unfamiliar. so, i spent some time to search \nand pick up some basics from a brief online guide. secondly, i obtained some skills in finding the \nsources of different face datasets and how to read different types of zipped data (e.g., .tar files). thirdly, \ni learned what to look out for in my next gan research attempt from the mistakes and errors \nencountered during my failure. finally, although i decided to discard this solution, i had had better \nunderstanding of gra-gan and its issues from this trial. \nevaluation \nsince it was not a very fruitful week, there was not much rewarding experience to be spoken of. the \nonly fact i could be slightly proud of would be the success in discovering and reading a new type of \ndata file. i suppose i could think of this mini accomplishment as gaining a reusable skill in reading the \ndata before model implementation. \nit was certainly a difficult week when all i could report to the team was about my failed experiments. i \nhad to let go of an unsuccessful solution and i felt quite disappointed in myself for not being capable \nenough to solve the problem. at the same time, i acknowledged that this was just one tiny bit of the \nmany challenges that people in research roles would meet. this made me to further appreciate the skills \nand persistence of the researchers, innovators, and pioneers.  \nadditionally, i also experienced technical challenges in handling pytorch codes. i did not have sufficient \ntime to learn the basics thoroughly and could only learn as much as i went. finally, the subpar image \nquality of most of the gans’ output popped up as a significant novel challenge to be solved. \nplanning \nthe focus for the following week would be to find a new direction to the project. in other word, i should \nresearch and come up with a new model solution to the business problem. \n \n18",
            "page": null,
            "goal": "week 3 \ndescription \nthe main goal for the third week was to replicate the code implementation of the chosen gan technique \nin facial aging category and to document any findings or issues encountered during the process.  \n17 \n \nthe activities for this week were more technical. i started to experiment with the gra-gan model \nwhich would simultaneously transform the gender, race, and age of an input image. i attempted to find \nand use the available code and training weight on the author’s github. however, i met with numerous \nchallenges and ended up failing this task. there was a github code link for the model; however, the full \ncode implementation and instructions, the training weights and the required datasets were not provided. \nthe option of training the model from scratch was also not viable because it took the authors around \none week to train the model with the full gpu processing capacity.  \nsimilarly, arunabh also experienced several difficulties in doing the same task on a different gan (i.e., \nage-cgan). the other models we found also had the same issues. at this stage, we reached a dead end \nand upon the daily meeting, we were advised by matineh to only look at the models with the full code \nand pre-trained weights available to deploy the model directly and avoid building everything from \nscratch. i went back to explore other possible solutions since then. \nthe primary outcome of this week was the failure to implement the gra-gan model and the \nrealization of a multitude of possible technical gaps associated with replicating the academic papers. \nupon digesting the paper in more depth, i also discovered several other issues associated with the state-\nof-the-art gans for the style-based racial transformation. for example, the quality of the generated \nimages from the current best models was still insufficient as the output clearly exhibited much irregular \nand unrealistic acuity to the human eyes. additionally, the final output was a transformed centered crop \nof the input image and not yet a complete face. hence, although the model was a state-of-the-art, it was \nyet applicable to the real-life business cases. \ninterpretation \nthis week, i gained a lot of new experience from the technical task. firstly, the majority of gans was \nimplemented using in pytorch, of which i was completely unfamiliar. so, i spent some time to search \nand pick up some basics from a brief online guide. secondly, i obtained some skills in finding the \nsources of different face datasets and how to read different types of zipped data (e.g., .tar files). thirdly, \ni learned what to look out for in my next gan research attempt from the mistakes and errors \nencountered during my failure. finally, although i decided to discard this solution, i had had better \nunderstanding of gra-gan and its issues from this trial. \nevaluation \nsince it was not a very fruitful week, there was not much rewarding experience to be spoken of. the \nonly fact i could be slightly proud of would be the success in discovering and reading a new type of \ndata file. i suppose i could think of this mini accomplishment as gaining a reusable skill in reading the \ndata before model implementation. \nit was certainly a difficult week when all i could report to the team was about my failed experiments. i \nhad to let go of an unsuccessful solution and i felt quite disappointed in myself for not being capable \nenough to solve the problem. at the same time, i acknowledged that this was just one tiny bit of the \nmany challenges that people in research roles would meet. this made me to further appreciate the skills \nand persistence of the researchers, innovators, and pioneers.  \nadditionally, i also experienced technical challenges in handling pytorch codes. i did not have sufficient \ntime to learn the basics thoroughly and could only learn as much as i went. finally, the subpar image \nquality of most of the gans’ output popped up as a significant novel challenge to be solved. \nplanning \nthe focus for the following week would be to find a new direction to the project. in other word, i should \nresearch and come up with a new model solution to the business problem. \n \n18",
            "children": []
        },
        {
            "id": "1.7",
            "name": "week 4",
            "nodeType": "title",
            "text": "week 4",
            "page": null,
            "goal": "week 4",
            "children": []
        },
        {
            "id": "1.8",
            "name": "week 4 description",
            "nodeType": "paragraph",
            "text": "week 4 \ndescription \nthe primary goal for the fourth week was to identify a new approach to solve the dataset problem. the \nnew gan model should have at least all the necessary codes, training weights and partial datasets \navailable. \nmy activities for this week started with looking for the alternative gan solutions that were: (1) the \nmost recent state-of-the-art, (2) capable of full replication, (3) producing sufficiently high-quality \noutput, and (4) satisfying other criteria related to my project problem. this time, i did not just look at \nthe academic papers only, but also visited other sources, such as webpages, blogs, and videos regarding \ngans for human face images.  \ni found stylegan, first developed by nvidia in 2019, was one of the current best state-of-the-art and \nwas being implemented for generating realistic human ai face photos for real-life uses. this model \napproach ticked most of the boxes and had the best output quality compared to all previous models i \nfound so far. however, it still raised a material concern due to its unconditional characteristic that gave \nthe users little control over the aspects of the generated photos.  \ni had a lot of discussions with arunabh throughout the process and brought up these findings with the \nteam during the meetings. i was suggested by matineh to give it a go but also paying attention to the \nmodel-specific issue at the same time. \nthe outcomes of the week included the thorough review, documentation and discussions regarding the \nstyle-based generator and its variants. i added a new category for unconditional gans to the current \nconfluence page and documented all the relevant summaries and notes. \ninterpretation \nduring the fourth week, i gained the knowledge about the style-based generator and some of its variants \n(e.g., stylegan2). i learned about its conceptual framework, findings, and results through a variety of \nchannels, such as the original paper, the github and the introductory videos. i also noticed that the \nstylegan was one of the prevailing approaches that attracted significant attention and focus for further \nfuture development. \nevaluation \nthe discovery of the style-based generators was eye-opening to me. i was amazed by nvidia’s \ninnovation and progress in creating the stylegan architecture and by its impressive synthetic human \nimages with a high resolution and a realistic look that was indistinguishable to the human eye. \nfurthermore, it was a relief to find a prospective novel solution to the project. this temporarily got me \nout of the roadblock i encountered last week. \nas usual, it was challenging for me to quickly grasp and digest the new technical concepts. but i found \nthe task easier this time thanks to my learning experience with other models in the previous weeks.  \nhowever, the main anxiety came from the new concern about the characteristics of the style-based \ngenerators. as this matter was not a concern to the model’s original purposes, but was specific to our \nuse case, i was unsure how to tackle it. nevertheless, i would research more next week to broaden my \nknowledge and perspective and to come up with some useful ideas. \nfinally, it was slightly worrisome when i realized that the progress and performance of the current state-\nof-the-art conditional gans were still far behind the unconditional ones, especially in terms of the \nimage quality. this would leave me with limited feasible solutions for my project problem. \n19 \n \nplanning \nthe main task for the next week would be to carry out extensive study and to prepare for the \nimplementation of the style-based generators. i needed to figure out whether the stylegan approach \ncould actually address our project problem.",
            "page": null,
            "goal": "week 4 \ndescription \nthe primary goal for the fourth week was to identify a new approach to solve the dataset problem. the \nnew gan model should have at least all the necessary codes, training weights and partial datasets \navailable. \nmy activities for this week started with looking for the alternative gan solutions that were: (1) the \nmost recent state-of-the-art, (2) capable of full replication, (3) producing sufficiently high-quality \noutput, and (4) satisfying other criteria related to my project problem. this time, i did not just look at \nthe academic papers only, but also visited other sources, such as webpages, blogs, and videos regarding \ngans for human face images.  \ni found stylegan, first developed by nvidia in 2019, was one of the current best state-of-the-art and \nwas being implemented for generating realistic human ai face photos for real-life uses. this model \napproach ticked most of the boxes and had the best output quality compared to all previous models i \nfound so far. however, it still raised a material concern due to its unconditional characteristic that gave \nthe users little control over the aspects of the generated photos.  \ni had a lot of discussions with arunabh throughout the process and brought up these findings with the \nteam during the meetings. i was suggested by matineh to give it a go but also paying attention to the \nmodel-specific issue at the same time. \nthe outcomes of the week included the thorough review, documentation and discussions regarding the \nstyle-based generator and its variants. i added a new category for unconditional gans to the current \nconfluence page and documented all the relevant summaries and notes. \ninterpretation \nduring the fourth week, i gained the knowledge about the style-based generator and some of its variants \n(e.g., stylegan2). i learned about its conceptual framework, findings, and results through a variety of \nchannels, such as the original paper, the github and the introductory videos. i also noticed that the \nstylegan was one of the prevailing approaches that attracted significant attention and focus for further \nfuture development. \nevaluation \nthe discovery of the style-based generators was eye-opening to me. i was amazed by nvidia’s \ninnovation and progress in creating the stylegan architecture and by its impressive synthetic human \nimages with a high resolution and a realistic look that was indistinguishable to the human eye. \nfurthermore, it was a relief to find a prospective novel solution to the project. this temporarily got me \nout of the roadblock i encountered last week. \nas usual, it was challenging for me to quickly grasp and digest the new technical concepts. but i found \nthe task easier this time thanks to my learning experience with other models in the previous weeks.  \nhowever, the main anxiety came from the new concern about the characteristics of the style-based \ngenerators. as this matter was not a concern to the model’s original purposes, but was specific to our \nuse case, i was unsure how to tackle it. nevertheless, i would research more next week to broaden my \nknowledge and perspective and to come up with some useful ideas. \nfinally, it was slightly worrisome when i realized that the progress and performance of the current state-\nof-the-art conditional gans were still far behind the unconditional ones, especially in terms of the \nimage quality. this would leave me with limited feasible solutions for my project problem. \n19 \n \nplanning \nthe main task for the next week would be to carry out extensive study and to prepare for the \nimplementation of the style-based generators. i needed to figure out whether the stylegan approach \ncould actually address our project problem.",
            "children": []
        },
        {
            "id": "1.9",
            "name": "week 5",
            "nodeType": "title",
            "text": "week 5",
            "page": null,
            "goal": "week 5",
            "children": []
        },
        {
            "id": "1.10",
            "name": "week 5 description",
            "nodeType": "paragraph",
            "text": "week 5 \ndescription \nthe goals to be accomplished for the fifth week were primarily to conduct research to validate the \nstylegan approach to truuth’s data augmentation case and to propose an actionable solution \naccordingly.  \nmy activities for this week started with reviewing the details in the literature of the style-based \ngenerators again, noting down their weaknesses and some known issues and finding any of its active \nimplementations. from my discussions with arunabh, we both found that almost any gans, even the \nhigh-performing ones, would perform poorly on a small dataset, and that the distribution of the final \noutput of stylegans would depend on the original distribution of the input dataset. this meant that \nstylegan could produce a biased set of images given an imbalanced initial dataset, which added \nconcerns to the current challenges of our project. \nthen, we proceeded to look for the relevant works on handling these issues. we compared our findings \nand agreed upon a set of different solutions with both unconditional and conditional gan approaches. \nwe then presented our findings and proposed solutions to mike and matineh during our meetings.  \nthe outcomes of the week included offering a set of potential solutions to our project problem. arunabh \ncreated a new confluence page for us to document the proposed solutions along with the rationale and \nthe reference of the related academic papers and techniques. however, we were not completely \nsuccessful with our deliverables, which would be described in more detail in the difficult experience \npart. \ninterpretation \nfor this week, i gained some more comprehensive knowledge about the style-based generators, \nspecifically stylegan2 and its known issues. in addition to the papers that debugged the biased \nproblem of the stylegan2, i found some relevant supporting frameworks, such as pixel2style2pixel, \nwhich assists in mapping different types of input images to the latent space required in the style-based \narchitectures. \nevaluation \na rewarding experience for this week was that we had materialized our research so far into a clearer set \nof different approaches for the project problem. i felt better that our approaches were narrowed down \nand became more explicit. \nthe difficult experiences stemmed from several major challenges we met this week. first of all, i had \nyet found an answer for ensuring a certain criterion of the output generated under the approach using \nthe unconditional gans. secondly, i was yet able to solve the issues of the current conditional gans \napproach. moreover, i was quite disappointed to find that there was little to no disclosure of the real-\nlife cases of using the gan-based augmented datasets in facial liveness recognition, let alone the \nstylegan-based. the only paper we found was the application in the medical domain on x-ray and \nct scan images, which was quite far from our business case.  \n20 \n \nhence, it might have looked uncertain when we discussed our solutions during the team meeting. mike \nsaid he felt confused and questioned the current prospects and application of gan-based approaches to \nenlarge the dataset. he would like us to come up with a recommendation on how to move forward with \nthe project in the upcoming week. if necessary, we might need to set aside the current project idea and \nturn to a different project problem. \ni was intimidated by his remarks, but i understood that he wanted the better for all of us. it was likely \nthat, from his experience working with the r&d team, he might have caught a sense of uncertainty of \nwhere the project was heading at this stage.  \nplanning \nfrom mike’s feedback, my task for the following week would be to re-evaluate and validate the current \napproach to see if it can bring forward a tangible outcome and to propose how to either move forward \nwith or move on from the current approach.",
            "page": null,
            "goal": "week 5 \ndescription \nthe goals to be accomplished for the fifth week were primarily to conduct research to validate the \nstylegan approach to truuth’s data augmentation case and to propose an actionable solution \naccordingly.  \nmy activities for this week started with reviewing the details in the literature of the style-based \ngenerators again, noting down their weaknesses and some known issues and finding any of its active \nimplementations. from my discussions with arunabh, we both found that almost any gans, even the \nhigh-performing ones, would perform poorly on a small dataset, and that the distribution of the final \noutput of stylegans would depend on the original distribution of the input dataset. this meant that \nstylegan could produce a biased set of images given an imbalanced initial dataset, which added \nconcerns to the current challenges of our project. \nthen, we proceeded to look for the relevant works on handling these issues. we compared our findings \nand agreed upon a set of different solutions with both unconditional and conditional gan approaches. \nwe then presented our findings and proposed solutions to mike and matineh during our meetings.  \nthe outcomes of the week included offering a set of potential solutions to our project problem. arunabh \ncreated a new confluence page for us to document the proposed solutions along with the rationale and \nthe reference of the related academic papers and techniques. however, we were not completely \nsuccessful with our deliverables, which would be described in more detail in the difficult experience \npart. \ninterpretation \nfor this week, i gained some more comprehensive knowledge about the style-based generators, \nspecifically stylegan2 and its known issues. in addition to the papers that debugged the biased \nproblem of the stylegan2, i found some relevant supporting frameworks, such as pixel2style2pixel, \nwhich assists in mapping different types of input images to the latent space required in the style-based \narchitectures. \nevaluation \na rewarding experience for this week was that we had materialized our research so far into a clearer set \nof different approaches for the project problem. i felt better that our approaches were narrowed down \nand became more explicit. \nthe difficult experiences stemmed from several major challenges we met this week. first of all, i had \nyet found an answer for ensuring a certain criterion of the output generated under the approach using \nthe unconditional gans. secondly, i was yet able to solve the issues of the current conditional gans \napproach. moreover, i was quite disappointed to find that there was little to no disclosure of the real-\nlife cases of using the gan-based augmented datasets in facial liveness recognition, let alone the \nstylegan-based. the only paper we found was the application in the medical domain on x-ray and \nct scan images, which was quite far from our business case.  \n20 \n \nhence, it might have looked uncertain when we discussed our solutions during the team meeting. mike \nsaid he felt confused and questioned the current prospects and application of gan-based approaches to \nenlarge the dataset. he would like us to come up with a recommendation on how to move forward with \nthe project in the upcoming week. if necessary, we might need to set aside the current project idea and \nturn to a different project problem. \ni was intimidated by his remarks, but i understood that he wanted the better for all of us. it was likely \nthat, from his experience working with the r&d team, he might have caught a sense of uncertainty of \nwhere the project was heading at this stage.  \nplanning \nfrom mike’s feedback, my task for the following week would be to re-evaluate and validate the current \napproach to see if it can bring forward a tangible outcome and to propose how to either move forward \nwith or move on from the current approach.",
            "children": []
        },
        {
            "id": "1.11",
            "name": "week 6",
            "nodeType": "title",
            "text": "week 6",
            "page": null,
            "goal": "week 6",
            "children": []
        },
        {
            "id": "1.12",
            "name": "week 6 description",
            "nodeType": "paragraph",
            "text": "week 6 \ndescription \nthe main goal for the sixth week involved offering recommendations on how to proceed further with \nthe ongoing project. i needed to check whether the general idea of using gans to expand the dataset \nwas feasible for our business case and determine what the next steps would be.  \nmy activities for the week started with finding and reviewing the literature in the practice of data \naugmentation for facial recognition and relevant tasks. i was still unable to find any research on the \napplication of gan to enlarge the live datasets in the facial liveness tasks. however, i discovered \nseveral papers that adopted gan techniques to generate spoofing data for the facial liveness tasks. on \nthe other hand, i found more experiments on using gan-based data augmentation for other facial \nrecognition tasks, more prominently in identity verification (e.g., face, iris, and fingerprints).  \nfrom my findings, i answered mike’s question on the feasibility of using gan to augment the dataset \nfor the facial liveness task and proved that there would be merits to truuth’s business case if the solution \ncould be implemented successfully. then, we discussed with mike on the next steps and settled upon \ntrying one approach for the next phase. at the end, mike asked for the hypotheses and the more detailed \nproposal of the chosen gan approach to enlarge the dataset. \nthe outcomes of this week were: (1) the validation of the feasibility of our current project and approach, \nand (2) the agreement on the next steps and the solution to be focused on for implementation and testing. \ni created a new confluence page that documented my reviews and comments on the current progress \nof using gan-based augmented datasets for relevant facial recognition tasks and another page for the \nnext steps to be carried out that were suggested by mike. \ninterpretation \nfor this week, i learned more about the case-specific application of gan models in facial recognition \ntasks. i also discovered a few approaches that addressed the challenges of stylegan2 in dealing with \nthe minority class. i also gained valuable experience in how to bring up the problem and solution more \neffectively through our team interaction with mike. more importantly, i also got to understand more \nabout mike’s viewpoint. \n21 \n \nevaluation \ni was happy to learn some use cases of gans model in facial recognition tasks. even though there was \nno result that exactly matched our business problem, the cases i found were close enough to relate and \ncheck the effect of the gan application.  \nadditionally, i felt excited about some interesting experiments where gans were used to generate the \nenhanced spoof image for the facial liveness task either from just spoof images with different \npresentation attack instruments or the mixture of the live and spoof images. this indicated that there \nwere valid approaches in applying the gan architectures to augment the spoof datasets.  \nfinally, i also felt relieved after getting mike’s understanding of our progress and challenges and having \nreached an agreement and clarity on what we were supposed to do next. \nthe most difficult experience for me during this week was the first meeting with mike. although i had \nquite anticipated it, i still experienced some anxiety and pressure, especially when knowing that there \nwas no available academic paper that had the matching application for us to refer the whole approach \nto and for mike to have a quality assurance. \nbefore the meeting, i and arunabh had briefly discussed what to present to mike. however, there was \ninsufficient time to bring up everything in the short meeting, and mike had to leave early for another \nclient meeting. we were not able to convey all our findings and that meeting became tense as we did \nnot deliver what mike had expected from us.  \ni also felt guilty for letting arunabh initiating that meeting alone and feeling depressed afterwards. i \ndid not find the chance to have a word to clarify and support his discussion during that meeting. so, i \ndecided to initiate the talk for the next meeting and paved the way for arunabh’s pitch by briefly \nexplaining to mike why we could not find one perfect paper/solution that matched exactly our business \nproblem. then, arunabh could proceed to talk about several proposed solutions that we had come up \nwith before. \ni was glad that the second meeting became smoother. however, i understood what mike was worried \nabout. it was rather easy to get lost in the research phase and it was his role to prevent us from jumping \ninto that rabbit hole. \nplanning \nthe tasks for the upcoming week involved creating a more detailed approach with the selected gan \nmodel and proposing some hypotheses to better visualize and crystalize the outcomes of implementing \nthe solution from the available data and knowledge.",
            "page": null,
            "goal": "week 6 \ndescription \nthe main goal for the sixth week involved offering recommendations on how to proceed further with \nthe ongoing project. i needed to check whether the general idea of using gans to expand the dataset \nwas feasible for our business case and determine what the next steps would be.  \nmy activities for the week started with finding and reviewing the literature in the practice of data \naugmentation for facial recognition and relevant tasks. i was still unable to find any research on the \napplication of gan to enlarge the live datasets in the facial liveness tasks. however, i discovered \nseveral papers that adopted gan techniques to generate spoofing data for the facial liveness tasks. on \nthe other hand, i found more experiments on using gan-based data augmentation for other facial \nrecognition tasks, more prominently in identity verification (e.g., face, iris, and fingerprints).  \nfrom my findings, i answered mike’s question on the feasibility of using gan to augment the dataset \nfor the facial liveness task and proved that there would be merits to truuth’s business case if the solution \ncould be implemented successfully. then, we discussed with mike on the next steps and settled upon \ntrying one approach for the next phase. at the end, mike asked for the hypotheses and the more detailed \nproposal of the chosen gan approach to enlarge the dataset. \nthe outcomes of this week were: (1) the validation of the feasibility of our current project and approach, \nand (2) the agreement on the next steps and the solution to be focused on for implementation and testing. \ni created a new confluence page that documented my reviews and comments on the current progress \nof using gan-based augmented datasets for relevant facial recognition tasks and another page for the \nnext steps to be carried out that were suggested by mike. \ninterpretation \nfor this week, i learned more about the case-specific application of gan models in facial recognition \ntasks. i also discovered a few approaches that addressed the challenges of stylegan2 in dealing with \nthe minority class. i also gained valuable experience in how to bring up the problem and solution more \neffectively through our team interaction with mike. more importantly, i also got to understand more \nabout mike’s viewpoint. \n21 \n \nevaluation \ni was happy to learn some use cases of gans model in facial recognition tasks. even though there was \nno result that exactly matched our business problem, the cases i found were close enough to relate and \ncheck the effect of the gan application.  \nadditionally, i felt excited about some interesting experiments where gans were used to generate the \nenhanced spoof image for the facial liveness task either from just spoof images with different \npresentation attack instruments or the mixture of the live and spoof images. this indicated that there \nwere valid approaches in applying the gan architectures to augment the spoof datasets.  \nfinally, i also felt relieved after getting mike’s understanding of our progress and challenges and having \nreached an agreement and clarity on what we were supposed to do next. \nthe most difficult experience for me during this week was the first meeting with mike. although i had \nquite anticipated it, i still experienced some anxiety and pressure, especially when knowing that there \nwas no available academic paper that had the matching application for us to refer the whole approach \nto and for mike to have a quality assurance. \nbefore the meeting, i and arunabh had briefly discussed what to present to mike. however, there was \ninsufficient time to bring up everything in the short meeting, and mike had to leave early for another \nclient meeting. we were not able to convey all our findings and that meeting became tense as we did \nnot deliver what mike had expected from us.  \ni also felt guilty for letting arunabh initiating that meeting alone and feeling depressed afterwards. i \ndid not find the chance to have a word to clarify and support his discussion during that meeting. so, i \ndecided to initiate the talk for the next meeting and paved the way for arunabh’s pitch by briefly \nexplaining to mike why we could not find one perfect paper/solution that matched exactly our business \nproblem. then, arunabh could proceed to talk about several proposed solutions that we had come up \nwith before. \ni was glad that the second meeting became smoother. however, i understood what mike was worried \nabout. it was rather easy to get lost in the research phase and it was his role to prevent us from jumping \ninto that rabbit hole. \nplanning \nthe tasks for the upcoming week involved creating a more detailed approach with the selected gan \nmodel and proposing some hypotheses to better visualize and crystalize the outcomes of implementing \nthe solution from the available data and knowledge.",
            "children": []
        },
        {
            "id": "1.13",
            "name": "week 7",
            "nodeType": "title",
            "text": "week 7",
            "page": null,
            "goal": "week 7",
            "children": []
        },
        {
            "id": "1.14",
            "name": "week 7 description",
            "nodeType": "paragraph",
            "text": "week 7 \ndescription \nthe main goals for the seventh week involved building a more comprehensive approach with the \nselected gan model and providing some hypotheses to better visualize the outcomes of implementing \nthe solution from the available data and knowledge. \nthis week was rather special. everyone in our team, including arunabh, jennifer and i, would \nparticipate in a cyber security hackathon on thursday and friday. so, on monday, we asked mike and \nmatineh for the permission to be absent and reduce the workload for this week.  \nsince i was busy with mid-term assignments and hackathon, not much work had been done and there \nwas nothing new to report with the team. what i did during the first half of the week was mainly the \n22 \n \nextension of the previous week. i tried to refine the last proposal and draft up some hypotheses regarding \nhow much the original dataset could be enlarged from implementing a transformer gan. additionally, \ni found some new models that might enhance and address the issues of stylegan2. \nthen, on the first day of the hackathon, we met mike for the first time in person. he attended the \nhackathon for half of the day. matineh was also present at the event as a member of big data society \n- the organizing team. together with the truuth cohorts, we had conversations about the company, their \nupcoming plan and about their position and ambition in the data security and biometric market. on the \nsecond day, we took part in the data lake security challenge, presented our solution, and luckily got \nthe second place in the data lake security challenge. \nthe outcomes of this week were: (1) the refined proposed approach for data generation, and (2) the \nhypotheses on the new dataset size. \ninterpretation \nat first, we were quite nervous about asking mike to delay our work for our hackathon attendance. but \nit turned out that he was very supportive of such events and really encouraged us to join. i realized that \nmike always tried his best to keep updated with the industry and expand his networks with clients, \ninvestors, and partners. despite his busy schedule, he still sat the hackathon for a morning to connect \nwith the guest speakers. \nfrom the casual conversation with mike, i was deeply impressed by the way he carried his pitch about \ntruuth, which really showed his persuasion and entrepreneurial skills. he managed to inspire our \nhackathon team, most of whom were also truuth’s interns. hence, we tried to incorporate truuth’s \nbusiness solution as part of the security layers and developed further on it. this really validated his \nability to influence people. \nevaluation \nfor this week, i experienced a lot of things for the first time. i had never participated in a hackathon \nevent or gone in-depth into the cyber security topics before. this is also my first-time tackling a less-\n24-hour challenge and having to speak in front of such a large audience of almost 100 people. this \nhackathon event was a great learning curve for me. it was challenging but also eye-opening. i again \nfeel thankful towards prof. amin, mike and matineh, as well as my teammate, for enabling me to join \nthis event. \nplanning \nfrom this week’s experience, i realized the great benefits of joining hackathons and seminars. i decided \nthat i would always do my best to attend and make use of the similar opportunities in the future. \nmoreover, learning from mike, i would also work on improving my communication and networking \nskills and take every chance to connect with others in the industry. \nthe tasks for the upcoming week mainly involved generating synthetic images with a gan model of \nour choice.",
            "page": null,
            "goal": "week 7 \ndescription \nthe main goals for the seventh week involved building a more comprehensive approach with the \nselected gan model and providing some hypotheses to better visualize the outcomes of implementing \nthe solution from the available data and knowledge. \nthis week was rather special. everyone in our team, including arunabh, jennifer and i, would \nparticipate in a cyber security hackathon on thursday and friday. so, on monday, we asked mike and \nmatineh for the permission to be absent and reduce the workload for this week.  \nsince i was busy with mid-term assignments and hackathon, not much work had been done and there \nwas nothing new to report with the team. what i did during the first half of the week was mainly the \n22 \n \nextension of the previous week. i tried to refine the last proposal and draft up some hypotheses regarding \nhow much the original dataset could be enlarged from implementing a transformer gan. additionally, \ni found some new models that might enhance and address the issues of stylegan2. \nthen, on the first day of the hackathon, we met mike for the first time in person. he attended the \nhackathon for half of the day. matineh was also present at the event as a member of big data society \n- the organizing team. together with the truuth cohorts, we had conversations about the company, their \nupcoming plan and about their position and ambition in the data security and biometric market. on the \nsecond day, we took part in the data lake security challenge, presented our solution, and luckily got \nthe second place in the data lake security challenge. \nthe outcomes of this week were: (1) the refined proposed approach for data generation, and (2) the \nhypotheses on the new dataset size. \ninterpretation \nat first, we were quite nervous about asking mike to delay our work for our hackathon attendance. but \nit turned out that he was very supportive of such events and really encouraged us to join. i realized that \nmike always tried his best to keep updated with the industry and expand his networks with clients, \ninvestors, and partners. despite his busy schedule, he still sat the hackathon for a morning to connect \nwith the guest speakers. \nfrom the casual conversation with mike, i was deeply impressed by the way he carried his pitch about \ntruuth, which really showed his persuasion and entrepreneurial skills. he managed to inspire our \nhackathon team, most of whom were also truuth’s interns. hence, we tried to incorporate truuth’s \nbusiness solution as part of the security layers and developed further on it. this really validated his \nability to influence people. \nevaluation \nfor this week, i experienced a lot of things for the first time. i had never participated in a hackathon \nevent or gone in-depth into the cyber security topics before. this is also my first-time tackling a less-\n24-hour challenge and having to speak in front of such a large audience of almost 100 people. this \nhackathon event was a great learning curve for me. it was challenging but also eye-opening. i again \nfeel thankful towards prof. amin, mike and matineh, as well as my teammate, for enabling me to join \nthis event. \nplanning \nfrom this week’s experience, i realized the great benefits of joining hackathons and seminars. i decided \nthat i would always do my best to attend and make use of the similar opportunities in the future. \nmoreover, learning from mike, i would also work on improving my communication and networking \nskills and take every chance to connect with others in the industry. \nthe tasks for the upcoming week mainly involved generating synthetic images with a gan model of \nour choice.",
            "children": []
        },
        {
            "id": "1.15",
            "name": "week 8",
            "nodeType": "title",
            "text": "week 8",
            "page": null,
            "goal": "week 8",
            "children": []
        },
        {
            "id": "1.16",
            "name": "week 8 description",
            "nodeType": "paragraph",
            "text": "week 8 \ndescription \nthe main goal for week 8 was to start experimenting with our first choice of gan model. \nwe did not have a good start for this week as i got a flu and arunabh tested positive for covid. so, we \ngave a prior notice to the team and were absent from the monday meeting. i returned to work on \nwednesday, when i felt slightly better, and my head was clearer. \n23 \n \ni looked for the official stylegan2 implementation on github and began my replication attempts. the \nprocess did not go smoothly. the first problem we needed to tackle was obtaining the dataset. we were \ngiven the path to the dataset in one of the sagemaker notebooks. however, we found that we could not \nmove or import the dataset directly from one notebook instance to another. hence, we had to zip the \ndata file in the original notebook, downloaded it to our local machine, then uploaded and unzipped it in \nour working instance. only then could we get to start working with the gan model. \nagain, i met a lot of technical challenges when i began implementing the gan model following the \nofficial github instructions. they were mainly incompatible configuration issues between the \nrequirements for stylegan2 code implementation and aws sagemaker platform. for example, the \nimplementation required tensorflow 1.14, while amazon only offered tensorflow 2.0. at this stage, i \nput my work on hold for next week. \nthe outcomes of this week included getting the dataset in the right location and having the partial \nstylegan2 working codes on aws sagemaker notebook. \ninterpretation \ni felt bad about being sick and absent, but my supervisors were very understanding about our \ncircumstances. this made me relieved, but at the same time, slightly worried about slowing our work \nprogress. this led us to try to catch up as soon as we got better. \nat first, when i got hold of the github repository, i was very excited, thinking that the implementation \nprocess would go smooth and i could take what i learned in class (i.e., tensorflow) to practice. but \nthe reality did not turn out as expected. working on aws sagemaker was more complicated than i \nexpected, even from the very first step of transferring data and setting up the configuration for running \nthe model. \nevaluation \nworking with aws notebook instances was a whole new experience for me. i was totally caught off \nguards thinking that it would be the same as working with anaconda jupyter notebooks. i realized \nthat i was thinking too simple and there were far more variables that i had not anticipated. \nnonetheless, the concrete knowledge that i acquired during this week was the method of transferring \nand extracting data from another notebook instance. \nplanning \nfrom this week’s lesson, i got a better hold of my technical gaps and the need for a technical \nupskilling in the future. i plan to take some introductory courses to aws cloud platforms and to do \nmore individual projects in order to gain more technical knowledge and experience. \nthe tasks for the upcoming week would still focus on the successful implementation of gan(s).",
            "page": null,
            "goal": "week 8 \ndescription \nthe main goal for week 8 was to start experimenting with our first choice of gan model. \nwe did not have a good start for this week as i got a flu and arunabh tested positive for covid. so, we \ngave a prior notice to the team and were absent from the monday meeting. i returned to work on \nwednesday, when i felt slightly better, and my head was clearer. \n23 \n \ni looked for the official stylegan2 implementation on github and began my replication attempts. the \nprocess did not go smoothly. the first problem we needed to tackle was obtaining the dataset. we were \ngiven the path to the dataset in one of the sagemaker notebooks. however, we found that we could not \nmove or import the dataset directly from one notebook instance to another. hence, we had to zip the \ndata file in the original notebook, downloaded it to our local machine, then uploaded and unzipped it in \nour working instance. only then could we get to start working with the gan model. \nagain, i met a lot of technical challenges when i began implementing the gan model following the \nofficial github instructions. they were mainly incompatible configuration issues between the \nrequirements for stylegan2 code implementation and aws sagemaker platform. for example, the \nimplementation required tensorflow 1.14, while amazon only offered tensorflow 2.0. at this stage, i \nput my work on hold for next week. \nthe outcomes of this week included getting the dataset in the right location and having the partial \nstylegan2 working codes on aws sagemaker notebook. \ninterpretation \ni felt bad about being sick and absent, but my supervisors were very understanding about our \ncircumstances. this made me relieved, but at the same time, slightly worried about slowing our work \nprogress. this led us to try to catch up as soon as we got better. \nat first, when i got hold of the github repository, i was very excited, thinking that the implementation \nprocess would go smooth and i could take what i learned in class (i.e., tensorflow) to practice. but \nthe reality did not turn out as expected. working on aws sagemaker was more complicated than i \nexpected, even from the very first step of transferring data and setting up the configuration for running \nthe model. \nevaluation \nworking with aws notebook instances was a whole new experience for me. i was totally caught off \nguards thinking that it would be the same as working with anaconda jupyter notebooks. i realized \nthat i was thinking too simple and there were far more variables that i had not anticipated. \nnonetheless, the concrete knowledge that i acquired during this week was the method of transferring \nand extracting data from another notebook instance. \nplanning \nfrom this week’s lesson, i got a better hold of my technical gaps and the need for a technical \nupskilling in the future. i plan to take some introductory courses to aws cloud platforms and to do \nmore individual projects in order to gain more technical knowledge and experience. \nthe tasks for the upcoming week would still focus on the successful implementation of gan(s).",
            "children": []
        },
        {
            "id": "1.17",
            "name": "week 9",
            "nodeType": "title",
            "text": "week 9",
            "page": null,
            "goal": "week 9",
            "children": []
        },
        {
            "id": "1.18",
            "name": "week 9 description",
            "nodeType": "paragraph",
            "text": "week 9 \ndescription \nthe main goal for week 9 was to successfully generate synthetic faces from a gan model. if \nsuccessful, we would also be required to evaluate the outcomes using suitable evaluation metrics. \ni continued from the technical challenges that i encountered last week. i searched for the solutions to \nconfiguration setups online. i found some tutorials on implementing stylegan2 on different datasets \nand github issue threads of people having the same problems. however, all tutorials and the majority \nof users ran the model on google colab platform, which was very different from sagemaker. hence, \n24 \n \nsome of their available solutions were not applicable to our case. i tried all different solutions following \nthese threads, tutorials, and stackoverflow. in the end, i managed to install all of the required \nconfigurations, but the code did not work.  \ni proceeded to fixing some apparent errors, such as loading data and resizing images to the required \ninput size. then, i reached to a dead end with the error of “gpu not found”. i attempted all sort of ways, \nensuring the gpu was available, and even changing the “custom_ops” setup code from “gpu” to “xla \ngpu” to match with the aws gpu devices. the code progressed to one additional line and stopped \nfunctioning again with a new bug. at this point, we decided to stop and looking for an alternative. \nin addition to working on the gan implementation, we started looking into image sharpening methods \nand found some gans (e.g., sr-gan) that could enhance the image resolution. \nthe outcomes of this week included the partial stylegan2 working codes on aws sagemaker \nnotebook and a brief review in some super resolution gans. \ninterpretation \nhaving encountered a number of technical difficulties, our experiment on stylegan2 came to a \nstandstill. we felt lots of pressure to produce an output as we had no progress to report to mike this \nweek and the internship was coming to an end soon. i felt disappointed and frustrated with myself, but \nnothing more could be done for that piece of code. we asked matineh for technical help, but despite \ntrying her best, she was not able to solve our problems either. we had to accept and move on. \nevaluation \nthis was a challenging week both technically and mentally. my failure led to doubts in myself. i \nagain realized my technical incompetency and knowledge inadequacy. regardless, this week was a \ngood lesson. i learned some tips on how to customise the default configuration of amazon and how to \nuse kernel to solve this issue. besides, i found myself lucky that i was not alone in this project. i had \narunabh to discuss, share and overcome our roadblocks together. \nplanning \nthis week’s failure further reinforced my plan and determination to improve my technical skills \nwhenever i have spare time in the future.  \nthe tasks for the upcoming week again involved generating the gan transformed faces. additionally, \nwe would also research more on gans that boost image quality.",
            "page": null,
            "goal": "week 9 \ndescription \nthe main goal for week 9 was to successfully generate synthetic faces from a gan model. if \nsuccessful, we would also be required to evaluate the outcomes using suitable evaluation metrics. \ni continued from the technical challenges that i encountered last week. i searched for the solutions to \nconfiguration setups online. i found some tutorials on implementing stylegan2 on different datasets \nand github issue threads of people having the same problems. however, all tutorials and the majority \nof users ran the model on google colab platform, which was very different from sagemaker. hence, \n24 \n \nsome of their available solutions were not applicable to our case. i tried all different solutions following \nthese threads, tutorials, and stackoverflow. in the end, i managed to install all of the required \nconfigurations, but the code did not work.  \ni proceeded to fixing some apparent errors, such as loading data and resizing images to the required \ninput size. then, i reached to a dead end with the error of “gpu not found”. i attempted all sort of ways, \nensuring the gpu was available, and even changing the “custom_ops” setup code from “gpu” to “xla \ngpu” to match with the aws gpu devices. the code progressed to one additional line and stopped \nfunctioning again with a new bug. at this point, we decided to stop and looking for an alternative. \nin addition to working on the gan implementation, we started looking into image sharpening methods \nand found some gans (e.g., sr-gan) that could enhance the image resolution. \nthe outcomes of this week included the partial stylegan2 working codes on aws sagemaker \nnotebook and a brief review in some super resolution gans. \ninterpretation \nhaving encountered a number of technical difficulties, our experiment on stylegan2 came to a \nstandstill. we felt lots of pressure to produce an output as we had no progress to report to mike this \nweek and the internship was coming to an end soon. i felt disappointed and frustrated with myself, but \nnothing more could be done for that piece of code. we asked matineh for technical help, but despite \ntrying her best, she was not able to solve our problems either. we had to accept and move on. \nevaluation \nthis was a challenging week both technically and mentally. my failure led to doubts in myself. i \nagain realized my technical incompetency and knowledge inadequacy. regardless, this week was a \ngood lesson. i learned some tips on how to customise the default configuration of amazon and how to \nuse kernel to solve this issue. besides, i found myself lucky that i was not alone in this project. i had \narunabh to discuss, share and overcome our roadblocks together. \nplanning \nthis week’s failure further reinforced my plan and determination to improve my technical skills \nwhenever i have spare time in the future.  \nthe tasks for the upcoming week again involved generating the gan transformed faces. additionally, \nwe would also research more on gans that boost image quality.",
            "children": []
        },
        {
            "id": "1.19",
            "name": "week 10",
            "nodeType": "title",
            "text": "week 10",
            "page": null,
            "goal": "week 10",
            "children": []
        },
        {
            "id": "1.20",
            "name": "week 10 description",
            "nodeType": "paragraph",
            "text": "week 10 \ndescription \nthe main goal for week 10 was still attempting to succeed in implementing gan model on truuth’s \ndataset.  \ndue to last week’s failure, we decided to turn to another alternative of stylegan2 – the adapted pytorch \nversion, instead of the original tensorflow version, as it was said to be less buggy.  \ni looked up and followed any available online tutorials and github instructions to run the model. yet, \nwith the pytorch version, i still met with configuration issues. reading all these relevant threads on \ngithub issues, i managed to install all the required configurations, including the correct cuda and \npytorch versions. however, the problem lay with the library package itself. the necessary library was \nbased on c++, which was incompatible with the g linux platform of aws sagemaker. \n25 \n \nlearning from the last lesson, we decided to only spend a few more days with this code and tried to \nfind and move on to a new solution quickly, since we did not have much time left. since the tutorials \nand threads on google colab were dominant, i decided to carry out a quick stylegan2 implementation \non my google colab instead aws platform. this time, i was successful in making the model run, \nthough not able to train on truuth’s dataset due to the free gpu limit. i reported this result to matineh \nand she agreed that the next intern could collaborate with the engineering team to work on this \nstylegan2 solution again. \napart from this side experiment, we looked at different adapted versions of stylegan2 and found two \npromising style-based age and gender transformer gans with full implementation code and training \nlayers. we decided to test that during the next week. \non the other note, we found a public api that deployed a super resolution gan model to deblur the \ninput image. the api returned a satisfactorily sharp image when we tested it with a blurry sample. we \nreported the results to the team and matineh was very happy with it. we then proceeded to build a \nsimple pipeline connecting with the api to enhance the quality of any truuth’s image dataset. \nthe outcomes of this week included: (1) the partial stylegan2 working codes for the pytorch version \non aws sagemaker notebook and google colab and (2) a pipeline to deblur input images using a \npublicly available and accessible api. \ninterpretation \nthis week, we still failed to produce a tangible output, but the mood was slightly better than the \nprevious week. i assume it was due to the fact that we were not dead set on one solution. since we \nresolved to move on from our ideal solution once, we felt less for the second time. additionally, we \ngot our hope up with the two newly found transformers, so we did not fall into a desperate state with \nno backup. nevertheless, the pressure remained stronger than before as deadline was approaching and \nmike and matineh still had expectations for our project. \nevaluation \nthis was another technically challenging week but less intensive than before. i knew my limits and \ntook the better course of actions in accordance with those limits. i was able to be more productive, \nfeel less stressful and be mindful of our ultimate project goal. besides, i also acquired the interesting \ndiscovery about the super resolution gan and api. this would be particularly useful for truuth’s \nbusiness cases at any stage in both facial liveness and document verification tasks. \nplanning \ni learned a lot from the failure and this experience in many aspects, especially in terms of moving \nforward with new alternatives and staying on track with the final goal. i would employ these lessons \nin my future data science or any other projects. \nthe tasks for the upcoming week were to successfully generate the synthetic images from the newly \nfounded gan models and to start the final documentation on confluence.",
            "page": null,
            "goal": "week 10 \ndescription \nthe main goal for week 10 was still attempting to succeed in implementing gan model on truuth’s \ndataset.  \ndue to last week’s failure, we decided to turn to another alternative of stylegan2 – the adapted pytorch \nversion, instead of the original tensorflow version, as it was said to be less buggy.  \ni looked up and followed any available online tutorials and github instructions to run the model. yet, \nwith the pytorch version, i still met with configuration issues. reading all these relevant threads on \ngithub issues, i managed to install all the required configurations, including the correct cuda and \npytorch versions. however, the problem lay with the library package itself. the necessary library was \nbased on c++, which was incompatible with the g linux platform of aws sagemaker. \n25 \n \nlearning from the last lesson, we decided to only spend a few more days with this code and tried to \nfind and move on to a new solution quickly, since we did not have much time left. since the tutorials \nand threads on google colab were dominant, i decided to carry out a quick stylegan2 implementation \non my google colab instead aws platform. this time, i was successful in making the model run, \nthough not able to train on truuth’s dataset due to the free gpu limit. i reported this result to matineh \nand she agreed that the next intern could collaborate with the engineering team to work on this \nstylegan2 solution again. \napart from this side experiment, we looked at different adapted versions of stylegan2 and found two \npromising style-based age and gender transformer gans with full implementation code and training \nlayers. we decided to test that during the next week. \non the other note, we found a public api that deployed a super resolution gan model to deblur the \ninput image. the api returned a satisfactorily sharp image when we tested it with a blurry sample. we \nreported the results to the team and matineh was very happy with it. we then proceeded to build a \nsimple pipeline connecting with the api to enhance the quality of any truuth’s image dataset. \nthe outcomes of this week included: (1) the partial stylegan2 working codes for the pytorch version \non aws sagemaker notebook and google colab and (2) a pipeline to deblur input images using a \npublicly available and accessible api. \ninterpretation \nthis week, we still failed to produce a tangible output, but the mood was slightly better than the \nprevious week. i assume it was due to the fact that we were not dead set on one solution. since we \nresolved to move on from our ideal solution once, we felt less for the second time. additionally, we \ngot our hope up with the two newly found transformers, so we did not fall into a desperate state with \nno backup. nevertheless, the pressure remained stronger than before as deadline was approaching and \nmike and matineh still had expectations for our project. \nevaluation \nthis was another technically challenging week but less intensive than before. i knew my limits and \ntook the better course of actions in accordance with those limits. i was able to be more productive, \nfeel less stressful and be mindful of our ultimate project goal. besides, i also acquired the interesting \ndiscovery about the super resolution gan and api. this would be particularly useful for truuth’s \nbusiness cases at any stage in both facial liveness and document verification tasks. \nplanning \ni learned a lot from the failure and this experience in many aspects, especially in terms of moving \nforward with new alternatives and staying on track with the final goal. i would employ these lessons \nin my future data science or any other projects. \nthe tasks for the upcoming week were to successfully generate the synthetic images from the newly \nfounded gan models and to start the final documentation on confluence.",
            "children": []
        },
        {
            "id": "1.21",
            "name": "week 11",
            "nodeType": "title",
            "text": "week 11",
            "page": null,
            "goal": "week 11",
            "children": []
        },
        {
            "id": "1.22",
            "name": "week 11 description",
            "nodeType": "paragraph",
            "text": "week 11 \ndescription \nthe main goal for week 11 was to generate the age and gender transformed faces from truuth’s face \ndataset and to document all of our research and experiments so far on confluence pages.  \n26 \n \nthis week, we attempted to implement the two potential style-based transformer for age and gender \nwith readily available pre-trained layers we found from last week’s research. we initially met with some \ndifficulties, such as in importing the dlib library or aligning faces but were able to resolve all of them \nafterwards.  \nwe were successful in generating the single image output for both models and presented the results to \nthe team. mike and matineh were impressed with the results. mike had some concerns over the potential \nbias of gans and whether fraudulent activities may use gan-based techniques to bypass the system. \nmeanwhile, matineh was quite convinced of the use of gans in augmenting and expanding the facial \ndataset. we then held a discussion around mike’s questions. at the end of the meeting, we all agreed \non the next step to batch process the whole truuth’s dataset. \nin addition, i wrote a code to solve the problem of picking the best frame out of multiple frames for an \nimage sample, which was an important selection step of the input images. all of our input images should \nbe the frame with the best quality (i.e., highest resolution) for each live and fake samples. \nthe outcomes of this week included: (1) the working codes for age and gender single-image transformer \non aws sagemaker notebook and (2) partial documentation of our experiments on confluence. \ninterpretation \nwe felt happy and relief that we finally produced some convincing and valid results. we would not \nhave to chase a new model, but instead focus on producing larger outputs with the current models.  \nfrom our meeting with mike, i could really feel that much as being idealistic, mike was also being \ncareful with his thoughts of some worst-case scenarios from real-world gan usage. he always tried \nto look at a bigger picture and consider different possibilities altogether. this was one of the great \nqualities that i wanted to learn from him. \nevaluation \nthis is a particularly rewarding week as i knew our journey was coming to an end but not fruitless or \nempty-handed. i gained new knowledge about the two stylegan2 adapted models and a much deeper \ninsight into the facial dataset. since i passed the configuration obstacles this week, i was able to reach \nand learn better about other steps in implementing the gan models. from this successful attempt of \nimplementing the gan model, i regained a bit of my confidence. i knew that resilience was an \nimportant factor that helped me to pull through my failures and to wait for successes. this would be \nhelpful in data science research projects where many unknown variables present. \nplanning \ni find being resilient and patient would help in data science research projects where many unknown \nvariables present. along with addressing my weaknesses, i also need to refine and enhance my \nstrengths in order to climb the career ladder. \nthe tasks for the upcoming week were to start batch processing on truuth’s dataset for each transformer \nand finalise the documentation on confluence.",
            "page": null,
            "goal": "week 11 \ndescription \nthe main goal for week 11 was to generate the age and gender transformed faces from truuth’s face \ndataset and to document all of our research and experiments so far on confluence pages.  \n26 \n \nthis week, we attempted to implement the two potential style-based transformer for age and gender \nwith readily available pre-trained layers we found from last week’s research. we initially met with some \ndifficulties, such as in importing the dlib library or aligning faces but were able to resolve all of them \nafterwards.  \nwe were successful in generating the single image output for both models and presented the results to \nthe team. mike and matineh were impressed with the results. mike had some concerns over the potential \nbias of gans and whether fraudulent activities may use gan-based techniques to bypass the system. \nmeanwhile, matineh was quite convinced of the use of gans in augmenting and expanding the facial \ndataset. we then held a discussion around mike’s questions. at the end of the meeting, we all agreed \non the next step to batch process the whole truuth’s dataset. \nin addition, i wrote a code to solve the problem of picking the best frame out of multiple frames for an \nimage sample, which was an important selection step of the input images. all of our input images should \nbe the frame with the best quality (i.e., highest resolution) for each live and fake samples. \nthe outcomes of this week included: (1) the working codes for age and gender single-image transformer \non aws sagemaker notebook and (2) partial documentation of our experiments on confluence. \ninterpretation \nwe felt happy and relief that we finally produced some convincing and valid results. we would not \nhave to chase a new model, but instead focus on producing larger outputs with the current models.  \nfrom our meeting with mike, i could really feel that much as being idealistic, mike was also being \ncareful with his thoughts of some worst-case scenarios from real-world gan usage. he always tried \nto look at a bigger picture and consider different possibilities altogether. this was one of the great \nqualities that i wanted to learn from him. \nevaluation \nthis is a particularly rewarding week as i knew our journey was coming to an end but not fruitless or \nempty-handed. i gained new knowledge about the two stylegan2 adapted models and a much deeper \ninsight into the facial dataset. since i passed the configuration obstacles this week, i was able to reach \nand learn better about other steps in implementing the gan models. from this successful attempt of \nimplementing the gan model, i regained a bit of my confidence. i knew that resilience was an \nimportant factor that helped me to pull through my failures and to wait for successes. this would be \nhelpful in data science research projects where many unknown variables present. \nplanning \ni find being resilient and patient would help in data science research projects where many unknown \nvariables present. along with addressing my weaknesses, i also need to refine and enhance my \nstrengths in order to climb the career ladder. \nthe tasks for the upcoming week were to start batch processing on truuth’s dataset for each transformer \nand finalise the documentation on confluence.",
            "children": []
        },
        {
            "id": "1.23",
            "name": "week 12",
            "nodeType": "title",
            "text": "week 12",
            "page": null,
            "goal": "week 12",
            "children": []
        },
        {
            "id": "1.24",
            "name": "week 12 description",
            "nodeType": "paragraph",
            "text": "week 12 \ndescription \nthe main goal for week 12 included the batch processing of truuth’s face dataset for age and gender \ngan and to finish documenting the process on confluence pages.  \n27 \n \nwe slightly modified our single-image transformation code to perform batch processing. the age \ninference code was harder to deal with than the gender transformer code. but overall, we had no troubles \nfixing them. the execution took a while for gender and longer for age. \nthe only problem occurred when i happened to find out that some of the input images were mislabelled \nin the original dataset. some of the fake images were wrongly classified as live images, which would \nhave certain adverse effect on the accuracy of the liveness model. i reported my findings to matineh \nand proceeded on to perform a quality control inspection on all images. i picked out all the misclassified \ndata and relabelled them. i also created a new cleaned dataset so other people could work with this \ninstead of the faulty dataset in the future. \nafter correcting the dataset, we carried out the batch processing again as well as checking the outputs \nfor any errors or misalignment.  \ni wrote the results display and analysis on confluence to evaluate the quality of each transformer gan’s \noutputs and discuss the future improvement in the gan-based data augmentation space. apart from \nthis, we wrapped up our duties by filling in details of our main experiments and implementation on \nconfluence. we also added detailed instructions on how to run our aws notebooks for future users. \nwe had a supervisor feedback session with mike and matineh on thursday. they seemed to be happy \nwith the results and gave all of us good evaluation of our work. \nthe outcomes of this week included: (1) the working codes for age and gender single-image transformer \non aws sagemaker notebook; (2) the complete documentation of our experiments on confluence; and \n(3) the gan output analysis and evaluation report. \ninterpretation \nwe overcame the hardest part last week, so this week was just slightly building up on last week’s task \nand came smoothly for us. however, i admitted it was a mistake on our part for not checking the input \ndata beforehand. we were overconfident, assuming that the given dataset was accurate. it was lucky \nthat we spot the errors in time to make changes. \nevaluation \nthis was a rewarding week as we finally completed our project goal with good results. i also learned a \nlesson to be more careful from the start to the end point of the project and to at least have the dataset \nvalidated before processing it further. again, i felt lucky to have arunabh as a teammate on this \nproject where we overcame difficultis together and helped each other out with different parts of the \ntasks. i also felt thankful to mike and matineh for being patient with our progress, especially during \nthe weeks when we experienced roadblocks. \nplanning \ni find this internship extremely valuable. it provided me an opportunity to experience the job of a data \nscientist and to learn on the job. it also allowed me to reassess and address my strengths and \nweaknesses. finally, i plan to reinforce all the knowledge and skills gained from this internship \nexperience by practicing them in more data science projects in the future.",
            "page": null,
            "goal": "week 12 \ndescription \nthe main goal for week 12 included the batch processing of truuth’s face dataset for age and gender \ngan and to finish documenting the process on confluence pages.  \n27 \n \nwe slightly modified our single-image transformation code to perform batch processing. the age \ninference code was harder to deal with than the gender transformer code. but overall, we had no troubles \nfixing them. the execution took a while for gender and longer for age. \nthe only problem occurred when i happened to find out that some of the input images were mislabelled \nin the original dataset. some of the fake images were wrongly classified as live images, which would \nhave certain adverse effect on the accuracy of the liveness model. i reported my findings to matineh \nand proceeded on to perform a quality control inspection on all images. i picked out all the misclassified \ndata and relabelled them. i also created a new cleaned dataset so other people could work with this \ninstead of the faulty dataset in the future. \nafter correcting the dataset, we carried out the batch processing again as well as checking the outputs \nfor any errors or misalignment.  \ni wrote the results display and analysis on confluence to evaluate the quality of each transformer gan’s \noutputs and discuss the future improvement in the gan-based data augmentation space. apart from \nthis, we wrapped up our duties by filling in details of our main experiments and implementation on \nconfluence. we also added detailed instructions on how to run our aws notebooks for future users. \nwe had a supervisor feedback session with mike and matineh on thursday. they seemed to be happy \nwith the results and gave all of us good evaluation of our work. \nthe outcomes of this week included: (1) the working codes for age and gender single-image transformer \non aws sagemaker notebook; (2) the complete documentation of our experiments on confluence; and \n(3) the gan output analysis and evaluation report. \ninterpretation \nwe overcame the hardest part last week, so this week was just slightly building up on last week’s task \nand came smoothly for us. however, i admitted it was a mistake on our part for not checking the input \ndata beforehand. we were overconfident, assuming that the given dataset was accurate. it was lucky \nthat we spot the errors in time to make changes. \nevaluation \nthis was a rewarding week as we finally completed our project goal with good results. i also learned a \nlesson to be more careful from the start to the end point of the project and to at least have the dataset \nvalidated before processing it further. again, i felt lucky to have arunabh as a teammate on this \nproject where we overcame difficultis together and helped each other out with different parts of the \ntasks. i also felt thankful to mike and matineh for being patient with our progress, especially during \nthe weeks when we experienced roadblocks. \nplanning \ni find this internship extremely valuable. it provided me an opportunity to experience the job of a data \nscientist and to learn on the job. it also allowed me to reassess and address my strengths and \nweaknesses. finally, i plan to reinforce all the knowledge and skills gained from this internship \nexperience by practicing them in more data science projects in the future.",
            "children": []
        }
    ]
}