{
    "id": "1",
    "name": "Reflective journal Entities",
    "nodeType": "section",
    "text": "week 2\ninternship midterm report \n \ncomp8851 major project internship stream       \n                                         3 june 2022 \n \n13 \nweek 3 \ngoals, activities and outcomes \nduring this week, i had to direct the ai venture cv enhancing project of this week. i created a 10-minute daily meeting to \nhelp the team grow as i grew more comfortable with the scrum master path. as a scrum master, it was my responsibility \nto guarantee that scrum values, principles, and procedures were followed. the team also attempts to eliminate roadblocks \nto productivity. as a scrum master, i supervised guiding the scrum process and ensuring that everyone on the team follows \nthe scrum framework. likewise, i also checked and verified the jira tool to track and report progress. the scrum master \noversees making sure the team follows the scrum methodology and removes roadblocks to their progress (karabiyik et al., \n2020). the scrum master is not a project manager, but rather a servant leader who assists the team in self-organizing and \nrealising its full potential (spiegler et al., 2021). jira is a project management and tracking solution for scrum projects \n(spiegler et al., 2021). it can be used to generate and manage issues, assign tasks to members of the team, and keep track \nof the project's progress. \nverifying the data, extracting the roles, recording the data, and assisting in the creation of a profile of seek data were all \nduties for this week. we examined the upper and lower limits of contract roles in the database as soon as they were ready. \nwe recognised the data, the pool was already clean, and we were eager for more progress and wanted to do better, so the \nmacquarie intern team worked swiftly in relate to that. \nnew knowledge, skills, and experience \ni gained a better grasp of how the scrum master ensures the team following the processes and principles of scrum. the \nscrum master is a servant-leader who assists the team in self-organizing and staying focused on the sprint goal, rather than \na traditional project manager. the scrum master also serves as a coach and facilitator, assisting the team in identifying and \neliminating roadblocks to development (mishra & otaiwi, 2020). the scrum master progression is a method of learning \nand mastering the scrum framework (bolloju et al., 2018). the course begins with an overview of scrum, followed by a \nseries of workshops covering various facets of scrum. \nin addition, i understood the responsibilities of a data analyst include identifying data, extracting roles, recording data, and \nassisting with profile creation. the team determined the main data sets and attributes required to support the study in \ncollaboration with the data team. analysts require assistance with data modelling and visualisation. \nrewarding experience \nit was an immensely satisfying experience for me to be a member of a team that was tasked with identifying the data, \nextracting the roles, recording the data, and assisting in the building of a data profile. the team came up with a solution \nafter successfully identifying the data, extracting the roles, capturing the data, and creating a profile for the data. the team's \nsuccess was aided by the fact that each team member was able to offer their specific set of talents and knowledge to the \nproject. \ndifficult experience \nthe responsibilities were difficult to complete and took a lot of time as well as effort. however, i completed the tasks, and \nit was a challenging as well as exciting process at the same time. \ntask for the upcoming week \nthe frequency analysis technique will be used for the next week to analyse the skills necessary for the task and feed it into \nthe training module. this will aid us in determining what abilities are required for the assignment and how we can best \nprepare those. the frequency analysis method is a statistical strategy to analysing and feeding the required skill task to the \ntraining module. this strategy is used to identify the most important skills needed for a certain endeavour and then set aside \ntime to train those talents. this method is frequently used to train the data of new employees or to retrain the data of existing \nemployees for a new task. \nweek 4 \ngoals, activities and outcomes \ninternship midterm report \n \ncomp8851 major project internship stream       \n                                         3 june 2022 \n \n14 \nfor this week, we looked at the relationship between experience and pay rate. we were under a lot of strain since we had \nto analyse our data to figure out the right relationship between years of experience and rate factor. we urged our supervisor \nto apply the most efficient way to improve the analysis. we were concerned that our data was not clean enough for testing, \ndespite our wish to use spss. we discovered a high association between years of experience and salary rate after analysing \nour data. a person with greater experience, for example, will get a higher wage. we were unable to fulfil the week's goal \ndue to a misunderstanding of the anticipated model. \nnew knowledge, skills, and experience \nbecause of the nltk library, we were able to gain a lot of experience during the week. working in such a vast and well-\norganized library was a fantastic experience for me. this week, i feel like i learnt a lot about natural language processing. \nin the future, i am interested in knowing more about it. to help with these duties, i've also learnt how to develop custom \nfunctions. to aid me in doing these duties, i have learnt how to develop bespoke corpora and wordlists. furthermore, i \nhave improved my understanding of how to use python for text mining. \nteamwork is crucial in high-pressure situations to get the job done efficiently and effectively. it is easier to solve problems \nand come up with new solutions when everyone is working towards a same goal. additionally, teamwork can aid in the \nreduction of stress and the development of morale. it is critical for people to be able to rely on one another while they are \nworking together under duress. this means that team members must be able to trust one another and know that they can \nrely on one another to carry out their responsibilities. it is also critical that team members communicate well with one \nanother. they can coordinate their efforts and ensure that everyone is on the same page this way. \nrewarding experience \nthere is nothing more satisfying than being able to operate as a team under duress and emerge victorious. a sense of \nsatisfaction and companionship that comes with conquering a challenge. when you're working on a project as a group, \nunder duress, it is critical that everyone is on the same page and working towards the same goal. when lives are on the \nline, there is no room for error. to be effective in this type of work setting, you must have trust with team members. there \nmust be open lines of communication and mutual respect. if a group can function effectively under duress, they will be \nsuccessful. this is a genuinely fulfilling experience when you come together as a team. \ndifficult experience \nit is simple to begin a task, but it is not necessarily simple to complete it. this is especially true if the work at hand is \ndifficult. it can be tough to find the motivation to continue with a challenging work. it is all too simple to become \ndiscouraged and give up. hence, it is vital for me to know that i am not alone in my struggles while i am working on a \nchallenging endeavour. it is not uncommon for people to struggle with challenging activities. the secret to accomplishing \ndifficult jobs is to find a way to keep going. breaking the task down into smaller, more manageable portions is one approach \nto do this. \ntask for the upcoming week \nfor the next week, we will be working on the same task as this week. we should apply the frequency analysis method to \nanalyse the skill necessary for the activity once more, and feed that information into the training module. after that, we'll \nknow what talents are required for the job and how to prepare for it as effectively as possible. we also need to understand \nthe notion of servant leadership. \nweek 5 \ngoals, activities and outcomes \nthe task we worked on this week was the same as the one we worked on the week before. we used the frequency analysis \nmethod once more to analyse the skill necessary for the task and feed that data into the training module. we were able to \ndetermine what abilities were required for the data and how to train the data to attain the greatest results by doing so. we \nlooked at how experience affects salary rates in this week's study. we were able to discover a plausible association between \nyears of experience and rate factor after analysing our data. we used nltk to clean up the data, fill in missing values, \neliminate stop words and non-alphabetic letters, and build a function as a second step in the frequency analysis. the \ninternship midterm report \n \ncomp8851 major project internship stream       \n                                         3 june 2022 \n \n15 \nfrequency of words in business analyst and data engineer requirements, as well as data analyst requirements, were \ndiscovered. \nlikewise, our supervisor callum employed hr advisors with company experience to better grasp the cv skills. as a result, \nshe invited us to weekly meetings and gave insights to accessories. as a result, there was enhancement in the project \ndevelopment, and everything was updated on jira. \nnew knowledge, skills, and experience \nduring this week, i learned how to mine text using python. to assist me with these duties, i learnt how to construct custom \nfunctions. to aid me in doing these duties, i learnt how to develop customised corpora and word lists. in addition, i now \nhave a better grasp of how to use python for text mining. similarly, i also learned about servant leadership, which is a \nleadership concept where the leader's primary motivation is to serve others (eva et al., 2019). it can be done in a variety of \nways, including offering support and direction to team members, and taking up duties and responsibilities that might \notherwise fall to others. \nrewarding experience \nworking as a scrum master was a highly fulfilling experience. we discovered that it was a fantastic approach to assist \nteams collaborate more effectively and efficiently, as well as a fantastic tool to gain a greater insight of a team's inner \nworkings. scrum masters, as previously said, may be an asset to a company by assisting in the improvement of \ncommunication and collaboration among the organization's teams. \ndifficult experience \nit was a difficult experience for me to be the scrum master for my team. i was responsible for keeping the team on track \nand ensuring that everyone was doing their job. it was a lot of work, and i had to keep track of everything. \ntask for the upcoming week \nthe assessment for the following week was to propose new keywords and phrases for gtp3 based on skill frequency \nanalysis. \n \nweek 6 \ngoals, activities and outcomes \ngoals are met through finding data, extracting important roles, recording data, and creating a profile that may be utilised \nto establish data correlations. after the contract roles have been defined, the database has been used to analyse skillsets \nand requirements to match them to contract opportunities. following to that, phrase extraction was a challenging part in \nthis segment where we had to extract certain phrases for skill sets and requirements. my objective was to find the phrase \nthat appears the most frequently among a group of phrases. when i utilised the frequency analysis function, it just counted \nthe number of words, not the frequency with which they appeared. i would be grateful if there was a way to search for a \nterm and count how many times it appears in a document. meanwhile, callum also proposed that we could make more \ngraphs to show how the re-queried and skill data outputs interact with one another. \nnew knowledge, skills, and experience \nduring this week, i learned about gpt-3 which is a natural language processing platform that allows developers to train \nand deploy ai models. text classification, entity recognition, and sentiment analysis are just a few of the functions available \nin the programme. gpt-3 enables programmers to create programmes that can understand and respond to natural language \ninputs (dale, 2021). gtp 3 is a toolkit that enables the creation, testing, and deployment of chatbots and other \nconversational apps (pilipiszyn & openai, 2021). natural language processing, dialogue management, and a chatbot \ndevelopment tool are among the characteristics of the tool. \nrewarding experience \nusing the gpt-3 open-source ai model was a fantastic experience. i was able to use a range of data sets to train the model \nand get good results. the model also performed well when applied to new data sets. the gpt3 open-ai was a very enjoyable \ninternship midterm report \n \ncomp8851 major project internship stream       \n                                         3 june 2022 \n \n16 \nexperience for me. i was able to learn a lot about how the system works and how i may apply it to my own ai projects. \nthis is something i would recommend to anyone interested in learning more about open-ai or improving their own ai \nprojects. \ndifficult experience \nfor a variety of reasons, i found it challenging to apply the gpt-3 open-ai model. the model is initially very huge and \nrequires a lot of computer resources to run. furthermore, there is insufficient documentation, and the usage of model is \nunclear. to add to that, the model is always evolving, making it tough to keep up. \ntask for the upcoming week \nfor the next week, we will be working on building a generative pre-trained transformer. as a result, we plan to construct \na modified text using a pretrained model. to accomplish this, we will be using a pre-trained model to build customised \ntexts from scratch. following to that, we will make usage of a pre-trained model to fine-tune a new model for a given \npurpose. the task seems to be feasible, for example, to use a pre-trained model to generate creative techniques or product \ndescriptions. it is also likely to fine-tune a new model based on a pre-trained model for a specific purpose, such as sentiment \nanalysis or named entity identification. \n \nweek 7 \ngoals, activities and outcomes \nnot much of activity, goal, or outcome happened in this week. we were unable to contact with the supervisors regarding \nthe project development. however, this week was invested for self-enhancement, research, as well as analysis. i worked \non getting an insight on vectorization, transformation and rnn models etc. \nnew knowledge, skills, and experience \ni was able to successfully construct the lstm as well as rnn models. likewise, i also gained an understanding of \nconverting words to vectors with the usage of embeddings. this was a fantastic learning opportunity for me, and i am \nlooking forward to using these skills in upcoming days. \nrewarding experience \nthe implementations in relate to lstm as well as rnn models produced an excellent result as per the expectations. this \nweek was a lot of fun watching the cv enhancement project take shape, and i was excited to keep working on it. \ndifficult experience \ncallum's hr members were not actively involved in the creation of scrum meetings, and the group was unable to construct \na model. the group was undecided as to whether we should design a model or wait for something new to be introduced. it \nhad been a rather uneventful week. i started constructing lstm as well as rnn models to share with my team, and i was \nlooking for ways to integrate keywords in phrases. i also demonstrated the team insights on how we may develop a website \nutilising flash models and, if necessary, incorporate our model onto it. as week 8 was approaching, i was concerned about \nnot completing the model and presenting it to the university. \ntask for the upcoming week \nno task has been assigned for upcoming week and i was waiting for a meeting with callum for better understanding of the \nproject development.  \n \nweek 8 \ngoals, activities and outcomes \nafter a zoom meeting with callum and other team members, i got an understanding of the project development for this \nweek. the data structure and keywords that we extracted showed anomalies. the extraction of keywords that we fetched \ninternship midterm report \n \ncomp8851 major project internship stream       \n                                         3 june 2022 \n \n17 \nwas not good enough to improve cvs. callum instructed us to improve and refine our data cleaning part and extract the \nrelevant keywords from the data set. \nnew knowledge, skills, and experience \nduring the analysis, i realised how important is the structure of words in english for the cv enhancement. similarly, it \nwas equally important for us to do the data cleaning part precisely and be aware of keywords and remove adjectives from \nthe extracted keywords. \nrewarding experience \nmeeting with callum, who is an expert in the industry, was a rewarding experience. the group was able to better \ncomprehend the project development and enhance the technical skills with the guidance from him. \ndifficult experience \nit was difficult for the team to analyse and remove anomalies from the extracted keywords. however, we were able to get \nrid of difficulties by communicating and cooperating with each other within the team. \ntask for the upcoming week \nas suggested by callum, we were advised on working with the data cleaning part and making fetched keywords more \nprecise. to add to that, upcoming week could be utilized on evaluating the skills required for certain role using a frequency \nanalysis method and that information should be sent into the training module. likewise, we need to find out approaches to \ntrain models efficiently after cleaning/refining the extracted keywords. \n \nweek 9 \ngoals, activities and outcomes \nduring this week, we did a lot of analysis and brainstorming to improve the cv enhancement project. we were able to \ndeduce the framework for extracting keywords but were unable to locate them in the data. also, our team faced complexities \nwith the data structure. likewise, i proposed the group work on text generation techniques as well, resulting to that, i \nhanded the team a structure based on rnn model. \nnew knowledge, skills, and experience \n as the project progressed, there were few complications; however, we were able to develop our efficiency by conducting \nresearch and self-evaluation. this helped me in learning key skills and strategies to be followed for time management and \nfor being efficient. we were also able to communicate more effectively and work together to overcome the challenges of \nthe project. \nrewarding experience \nit was genuinely satisfying for me to find effective ways to solve difficult tasks. we were able to accomplish more and \nunderstand from each other in the team by working collectively. \ndifficult experience \nas an intern, we had a perception that it would be beneficial for us to receive advice on specific tools/techniques and \npresentations on accomplishing milestones. on this project, we mostly worked alone. even though callum was always \nthere for us, i realised as being in a group of data scientists, we collectively as a team, must shape this project over time. \nnobody ever showed us how to put the system together. however, we were aware of all these things and welcomed the \nchallenges because we knew we already have the necessary education and experience required in this field. \ntask for the upcoming week \nfor the upcoming week, allocated tasks will be data augmentation, machine learning and model building. likewise, we \nwill also be working on using various techniques to enhance the cv project and try to make it more accurate. \n \ninternship midterm report \n \ncomp8851 major project internship stream       \n                                         3 june 2022 \n \n18 \nweek 10 \ngoals, activities and outcomes \nthe objective of this week was to conduct a research and work on approaches for improving cv performance. i researched \nand read about popular strategies including data augmentation, transfer learning, and model assembly. i also tried out some \nof these strategies on the cv project. i gathered our group for our cv enhancement project to demonstrate how gpt-3 \nworks and how private data may be created. once gpt-3 has obtained the confidential data, we may not require the list or \ncsv file. gpt-3, in my perspective, could manage it all. i was concerned that this might not be in accordance with what \ncallum suggested earlier. however, to succeed, you must sometimes take a risk.  \nfirstly, we had a meeting with a commonwealth bank full stack developer to obtain some tips on how to develop the \nsystem we were envisioning. despite his efforts, he was unable to offer assistance because ml modelling was something \nhe did not understand. furthermore, we decided to seek assistance from professor amin on the structure of the cv enhancer \nproject. professor responded with an insightful article in the field of recruiting automation. that article improved the \ndirection of our effort and was a huge benefit to us.  \nas a result, we created ivi, a chatbot-based sms service that facilitates users to communicate and submit questions. ivi \nemploys a decision tree paradigm in which nodes are created using a prompt. callum, on the other hand, was not pleased \nwith the idea of ivi, so we had to create a new method. \nnew knowledge, skills, and experience \nartificial intelligence technology that is made available to the public for usage and modification is referred to as open-\nsource ai. this term generally refers to ai software that is provided under an open-source licence, which allows users to \nview and edit the source code without restriction.  similarly, twilio is a cloud-based messaging platform that enables \ncompanies to engage with their consumers using chatbots and other messaging apps. it enables companies to build, manage, \nand implement chatbots on a range of messaging platforms, such as facebook messenger, skype, whatsapp, and twitter \netc.  \nlikewise, i got an insight on render that is a web-based design platform that allows designers and businesses to build, \ndistribute, and manage custom websites and online storefronts. users can construct professional-looking websites in \nminutes using render.com, even if they have no prior coding or design skills. render.com also includes several built-in \nfeatures and tools, such as ecommerce support, search engine optimization, social network integration, and so on. \nrewarding experience \ni was extremely happy with the progress of project development this week. discovering efficient solutions to complicated \nchallenges was certainly satisfying for me. \ndifficult experience \ndebugging the gpt-3 code was the highly challenging task this week. i had some difficulties for operating the code \nappropriately, however, i was able to overcome the problem in the end. \ntask for the upcoming week \nthe task for the forthcoming week will be getting insights on the usages of new model by studying through exploration \nand analysis. similarly, we will also cover several parts of data visualisation. \n \nweek 11 \ngoals, activities and outcomes \nduring this week, callum organised a meeting to help us understand the system development. he identified the action \nverbs and explained how the past tense language functions to execute the decision tree model. he also explained how to \ninternship midterm report \n \ncomp8851 major project internship stream       \n                                         3 june 2022 \n \n19 \nget rid of prejudiced terms. following to that, he also conducted a gap workshop where our data science team went \nthrough a real-world job scenario. on the other hand, we also did the required data visualisation and data analysis part. \nnew knowledge, skills, and experience \nthis week, i learned further about tools and techniques required for the enhancement of accuracy and performance of our \nsystem. i also had hands-on experience using these strategies on a real-world task. this was a fantastic learning opportunity \nfor me, and i am looking forward to using these tactics in my upcoming projects.  \nrewarding experience \nthe outcomes of this week’s effort delighted me greatly. it felt great to see the cv enhancement project go live and \ndemonstrating it with callum and other team members. to add to that, i am really looking forward to continuing working \non this project even after the internship as it profoundly connects to real-world scenario, and it facilitates us to get various \ninsights on any specific industry and job market. \ndifficult experience \nwe implemented several parts of the system on various platforms and notebook files, so compiling all those in a same \nplace was a bit hectic. \ntask for the upcoming week \nthe final week’s task will be wrapping up the implementation and system development. following to that, we are required \nto do appropriate data analysis such as creating word cloud, clusters, visualising plots/charts. the next week’s task will be \ncomprised of project deliverables and having an insight on key takeaways & learnings from this internship opportunity. \n \nweek 12 \ngoals, activities and outcomes \nto maximise the project development and wrap up the project accomplishment, we had several meetings this week for \nbrainstorming, and compilation. initially, we split the activities into four different categories based on the functionalities. \nthe first part comprised of exploratory data analysis such as creation of bar charts/plots etc. for demonstration of various \nrelationships between the variables and getting significant insights through it. similarly, the second part included data \ncleaning, extraction of proper keywords and creation of clusters based on variables such as rate, skills etc. we used knn \nalgorithm for the implementation of clustering.  \nlikewise, the third part incorporated the gpt-3 implementation and execution of structured sentences. in this part, we \nfetched several data for sample action verbs/ tools etc. for our reference. also, we split the sentences into several tokens \nand matched those elements with the defined dictionaries of sample action verbs and tools etc. to add to that, we also \nfocused on measuring the degree of action verbs fetched and set the strong action verbs at first with the appropriate \nstructure. last part holds the documentation, compiling, implementing, debugging, and finally delivering the project.  \nduring this week, i worked on the second and third part along with ugur, my team member for the project. we explored \ndifferent possibilities on establishing correlation between variables such as role, pay rate and skills etc. similarly, we \ncategorised the data into three different roles as data analyst, data engineer and business analyst. after the data extraction \ncomes the cleaning part, where we used different libraries such as nlp, nltk and spacy etc. similarly, we used k-nearest \nneighbours’ algorithm for the second part for clustering.  \nfinally, after getting the extracted and refined keywords, we had to classify those appropriately. the important attributes \nfor each classification were then obtained. we researched and used several classification techniques for this classification \nproblem. for this project, callum requested to our team to employ the decision tree method, and we achieved a 78% \naccuracy on that. furthermore, the model can be improved by using larger datasets, extracting other relevant keywords, \napplying bi-gram tokens in place of unigrams, and enhancing the data pipelines using programmes like pyspark. \ninternship midterm report \n \ncomp8851 major project internship stream       \n                                         3 june 2022 \n \n20 \nnew knowledge, skills, and experience \nin python, aitextgen is a sophisticated library for creating text documents. it comes with several built-in classes for \nconstructing various forms of text documents, such as character strings, paragraphs, and headings etc. likewise, we learned \nabout several clustering and classification techniques in python. the supervised machine learning clustering technique k-\nnearest neighbours (knn) is an easy and simple method that can be utilized to handle both categorization as well as \nregression issues. likewise, we also discovered various text processing libraries in relate to natural language processing, \nvisualisation tools, and libraries in relate to data cleaning. \nrewarding experience \ncollaborating with other members of the team was a fantastic experience. despite the obstacles, we were able to operate \nefficiently and achieve our weekly objectives. we delivered the project as requested by callum and i feel proud of what \nwe did during these 12 weeks. it was a genuinely satisfying experience for overcoming the challenges and accomplish the \nobjectives given.  \ndifficult experience \nto my understanding, this project is huge and could not have been completed in 12 weeks’ time. however, we pushed \nour limits and tried our best to the extent we could. resulting to that, it somehow impacted on myself getting exhausted \nduring my part-time work and other activities. \n \n",
    "page": null,
    "goal": "Reflective journal Entities",
    "children": [
        {
            "id": "1.1",
            "name": "week 2",
            "nodeType": "title",
            "text": "week 2",
            "page": null,
            "goal": "week 2",
            "children": []
        },
        {
            "id": "1.2",
            "name": "week 2 internship",
            "nodeType": "paragraph",
            "text": "week 2\ninternship midterm report \n \ncomp8851 major project internship stream       \n                                         3 june 2022 \n \n13",
            "page": null,
            "goal": "week 2\ninternship midterm report \n \ncomp8851 major project internship stream       \n                                         3 june 2022 \n \n13",
            "children": []
        },
        {
            "id": "1.3",
            "name": "week 3",
            "nodeType": "title",
            "text": "week 3",
            "page": null,
            "goal": "week 3",
            "children": []
        },
        {
            "id": "1.4",
            "name": "week 3 goals,",
            "nodeType": "paragraph",
            "text": "week 3 \ngoals, activities and outcomes \nduring this week, i had to direct the ai venture cv enhancing project of this week. i created a 10-minute daily meeting to \nhelp the team grow as i grew more comfortable with the scrum master path. as a scrum master, it was my responsibility \nto guarantee that scrum values, principles, and procedures were followed. the team also attempts to eliminate roadblocks \nto productivity. as a scrum master, i supervised guiding the scrum process and ensuring that everyone on the team follows \nthe scrum framework. likewise, i also checked and verified the jira tool to track and report progress. the scrum master \noversees making sure the team follows the scrum methodology and removes roadblocks to their progress (karabiyik et al., \n2020). the scrum master is not a project manager, but rather a servant leader who assists the team in self-organizing and \nrealising its full potential (spiegler et al., 2021). jira is a project management and tracking solution for scrum projects \n(spiegler et al., 2021). it can be used to generate and manage issues, assign tasks to members of the team, and keep track \nof the project's progress. \nverifying the data, extracting the roles, recording the data, and assisting in the creation of a profile of seek data were all \nduties for this week. we examined the upper and lower limits of contract roles in the database as soon as they were ready. \nwe recognised the data, the pool was already clean, and we were eager for more progress and wanted to do better, so the \nmacquarie intern team worked swiftly in relate to that. \nnew knowledge, skills, and experience \ni gained a better grasp of how the scrum master ensures the team following the processes and principles of scrum. the \nscrum master is a servant-leader who assists the team in self-organizing and staying focused on the sprint goal, rather than \na traditional project manager. the scrum master also serves as a coach and facilitator, assisting the team in identifying and \neliminating roadblocks to development (mishra & otaiwi, 2020). the scrum master progression is a method of learning \nand mastering the scrum framework (bolloju et al., 2018). the course begins with an overview of scrum, followed by a \nseries of workshops covering various facets of scrum. \nin addition, i understood the responsibilities of a data analyst include identifying data, extracting roles, recording data, and \nassisting with profile creation. the team determined the main data sets and attributes required to support the study in \ncollaboration with the data team. analysts require assistance with data modelling and visualisation. \nrewarding experience \nit was an immensely satisfying experience for me to be a member of a team that was tasked with identifying the data, \nextracting the roles, recording the data, and assisting in the building of a data profile. the team came up with a solution \nafter successfully identifying the data, extracting the roles, capturing the data, and creating a profile for the data. the team's \nsuccess was aided by the fact that each team member was able to offer their specific set of talents and knowledge to the \nproject. \ndifficult experience \nthe responsibilities were difficult to complete and took a lot of time as well as effort. however, i completed the tasks, and \nit was a challenging as well as exciting process at the same time. \ntask for the upcoming week \nthe frequency analysis technique will be used for the next week to analyse the skills necessary for the task and feed it into \nthe training module. this will aid us in determining what abilities are required for the assignment and how we can best \nprepare those. the frequency analysis method is a statistical strategy to analysing and feeding the required skill task to the \ntraining module. this strategy is used to identify the most important skills needed for a certain endeavour and then set aside \ntime to train those talents. this method is frequently used to train the data of new employees or to retrain the data of existing \nemployees for a new task.",
            "page": null,
            "goal": "week 3 \ngoals, activities and outcomes \nduring this week, i had to direct the ai venture cv enhancing project of this week. i created a 10-minute daily meeting to \nhelp the team grow as i grew more comfortable with the scrum master path. as a scrum master, it was my responsibility \nto guarantee that scrum values, principles, and procedures were followed. the team also attempts to eliminate roadblocks \nto productivity. as a scrum master, i supervised guiding the scrum process and ensuring that everyone on the team follows \nthe scrum framework. likewise, i also checked and verified the jira tool to track and report progress. the scrum master \noversees making sure the team follows the scrum methodology and removes roadblocks to their progress (karabiyik et al., \n2020). the scrum master is not a project manager, but rather a servant leader who assists the team in self-organizing and \nrealising its full potential (spiegler et al., 2021). jira is a project management and tracking solution for scrum projects \n(spiegler et al., 2021). it can be used to generate and manage issues, assign tasks to members of the team, and keep track \nof the project's progress. \nverifying the data, extracting the roles, recording the data, and assisting in the creation of a profile of seek data were all \nduties for this week. we examined the upper and lower limits of contract roles in the database as soon as they were ready. \nwe recognised the data, the pool was already clean, and we were eager for more progress and wanted to do better, so the \nmacquarie intern team worked swiftly in relate to that. \nnew knowledge, skills, and experience \ni gained a better grasp of how the scrum master ensures the team following the processes and principles of scrum. the \nscrum master is a servant-leader who assists the team in self-organizing and staying focused on the sprint goal, rather than \na traditional project manager. the scrum master also serves as a coach and facilitator, assisting the team in identifying and \neliminating roadblocks to development (mishra & otaiwi, 2020). the scrum master progression is a method of learning \nand mastering the scrum framework (bolloju et al., 2018). the course begins with an overview of scrum, followed by a \nseries of workshops covering various facets of scrum. \nin addition, i understood the responsibilities of a data analyst include identifying data, extracting roles, recording data, and \nassisting with profile creation. the team determined the main data sets and attributes required to support the study in \ncollaboration with the data team. analysts require assistance with data modelling and visualisation. \nrewarding experience \nit was an immensely satisfying experience for me to be a member of a team that was tasked with identifying the data, \nextracting the roles, recording the data, and assisting in the building of a data profile. the team came up with a solution \nafter successfully identifying the data, extracting the roles, capturing the data, and creating a profile for the data. the team's \nsuccess was aided by the fact that each team member was able to offer their specific set of talents and knowledge to the \nproject. \ndifficult experience \nthe responsibilities were difficult to complete and took a lot of time as well as effort. however, i completed the tasks, and \nit was a challenging as well as exciting process at the same time. \ntask for the upcoming week \nthe frequency analysis technique will be used for the next week to analyse the skills necessary for the task and feed it into \nthe training module. this will aid us in determining what abilities are required for the assignment and how we can best \nprepare those. the frequency analysis method is a statistical strategy to analysing and feeding the required skill task to the \ntraining module. this strategy is used to identify the most important skills needed for a certain endeavour and then set aside \ntime to train those talents. this method is frequently used to train the data of new employees or to retrain the data of existing \nemployees for a new task.",
            "children": []
        },
        {
            "id": "1.5",
            "name": "week 4",
            "nodeType": "title",
            "text": "week 4",
            "page": null,
            "goal": "week 4",
            "children": []
        },
        {
            "id": "1.6",
            "name": "week 4 goals,",
            "nodeType": "paragraph",
            "text": "week 4 \ngoals, activities and outcomes \ninternship midterm report \n \ncomp8851 major project internship stream       \n                                         3 june 2022 \n \n14 \nfor this week, we looked at the relationship between experience and pay rate. we were under a lot of strain since we had \nto analyse our data to figure out the right relationship between years of experience and rate factor. we urged our supervisor \nto apply the most efficient way to improve the analysis. we were concerned that our data was not clean enough for testing, \ndespite our wish to use spss. we discovered a high association between years of experience and salary rate after analysing \nour data. a person with greater experience, for example, will get a higher wage. we were unable to fulfil the week's goal \ndue to a misunderstanding of the anticipated model. \nnew knowledge, skills, and experience \nbecause of the nltk library, we were able to gain a lot of experience during the week. working in such a vast and well-\norganized library was a fantastic experience for me. this week, i feel like i learnt a lot about natural language processing. \nin the future, i am interested in knowing more about it. to help with these duties, i've also learnt how to develop custom \nfunctions. to aid me in doing these duties, i have learnt how to develop bespoke corpora and wordlists. furthermore, i \nhave improved my understanding of how to use python for text mining. \nteamwork is crucial in high-pressure situations to get the job done efficiently and effectively. it is easier to solve problems \nand come up with new solutions when everyone is working towards a same goal. additionally, teamwork can aid in the \nreduction of stress and the development of morale. it is critical for people to be able to rely on one another while they are \nworking together under duress. this means that team members must be able to trust one another and know that they can \nrely on one another to carry out their responsibilities. it is also critical that team members communicate well with one \nanother. they can coordinate their efforts and ensure that everyone is on the same page this way. \nrewarding experience \nthere is nothing more satisfying than being able to operate as a team under duress and emerge victorious. a sense of \nsatisfaction and companionship that comes with conquering a challenge. when you're working on a project as a group, \nunder duress, it is critical that everyone is on the same page and working towards the same goal. when lives are on the \nline, there is no room for error. to be effective in this type of work setting, you must have trust with team members. there \nmust be open lines of communication and mutual respect. if a group can function effectively under duress, they will be \nsuccessful. this is a genuinely fulfilling experience when you come together as a team. \ndifficult experience \nit is simple to begin a task, but it is not necessarily simple to complete it. this is especially true if the work at hand is \ndifficult. it can be tough to find the motivation to continue with a challenging work. it is all too simple to become \ndiscouraged and give up. hence, it is vital for me to know that i am not alone in my struggles while i am working on a \nchallenging endeavour. it is not uncommon for people to struggle with challenging activities. the secret to accomplishing \ndifficult jobs is to find a way to keep going. breaking the task down into smaller, more manageable portions is one approach \nto do this. \ntask for the upcoming week \nfor the next week, we will be working on the same task as this week. we should apply the frequency analysis method to \nanalyse the skill necessary for the activity once more, and feed that information into the training module. after that, we'll \nknow what talents are required for the job and how to prepare for it as effectively as possible. we also need to understand \nthe notion of servant leadership.",
            "page": null,
            "goal": "week 4 \ngoals, activities and outcomes \ninternship midterm report \n \ncomp8851 major project internship stream       \n                                         3 june 2022 \n \n14 \nfor this week, we looked at the relationship between experience and pay rate. we were under a lot of strain since we had \nto analyse our data to figure out the right relationship between years of experience and rate factor. we urged our supervisor \nto apply the most efficient way to improve the analysis. we were concerned that our data was not clean enough for testing, \ndespite our wish to use spss. we discovered a high association between years of experience and salary rate after analysing \nour data. a person with greater experience, for example, will get a higher wage. we were unable to fulfil the week's goal \ndue to a misunderstanding of the anticipated model. \nnew knowledge, skills, and experience \nbecause of the nltk library, we were able to gain a lot of experience during the week. working in such a vast and well-\norganized library was a fantastic experience for me. this week, i feel like i learnt a lot about natural language processing. \nin the future, i am interested in knowing more about it. to help with these duties, i've also learnt how to develop custom \nfunctions. to aid me in doing these duties, i have learnt how to develop bespoke corpora and wordlists. furthermore, i \nhave improved my understanding of how to use python for text mining. \nteamwork is crucial in high-pressure situations to get the job done efficiently and effectively. it is easier to solve problems \nand come up with new solutions when everyone is working towards a same goal. additionally, teamwork can aid in the \nreduction of stress and the development of morale. it is critical for people to be able to rely on one another while they are \nworking together under duress. this means that team members must be able to trust one another and know that they can \nrely on one another to carry out their responsibilities. it is also critical that team members communicate well with one \nanother. they can coordinate their efforts and ensure that everyone is on the same page this way. \nrewarding experience \nthere is nothing more satisfying than being able to operate as a team under duress and emerge victorious. a sense of \nsatisfaction and companionship that comes with conquering a challenge. when you're working on a project as a group, \nunder duress, it is critical that everyone is on the same page and working towards the same goal. when lives are on the \nline, there is no room for error. to be effective in this type of work setting, you must have trust with team members. there \nmust be open lines of communication and mutual respect. if a group can function effectively under duress, they will be \nsuccessful. this is a genuinely fulfilling experience when you come together as a team. \ndifficult experience \nit is simple to begin a task, but it is not necessarily simple to complete it. this is especially true if the work at hand is \ndifficult. it can be tough to find the motivation to continue with a challenging work. it is all too simple to become \ndiscouraged and give up. hence, it is vital for me to know that i am not alone in my struggles while i am working on a \nchallenging endeavour. it is not uncommon for people to struggle with challenging activities. the secret to accomplishing \ndifficult jobs is to find a way to keep going. breaking the task down into smaller, more manageable portions is one approach \nto do this. \ntask for the upcoming week \nfor the next week, we will be working on the same task as this week. we should apply the frequency analysis method to \nanalyse the skill necessary for the activity once more, and feed that information into the training module. after that, we'll \nknow what talents are required for the job and how to prepare for it as effectively as possible. we also need to understand \nthe notion of servant leadership.",
            "children": []
        },
        {
            "id": "1.7",
            "name": "week 5",
            "nodeType": "title",
            "text": "week 5",
            "page": null,
            "goal": "week 5",
            "children": []
        },
        {
            "id": "1.8",
            "name": "week 5 goals,",
            "nodeType": "paragraph",
            "text": "week 5 \ngoals, activities and outcomes \nthe task we worked on this week was the same as the one we worked on the week before. we used the frequency analysis \nmethod once more to analyse the skill necessary for the task and feed that data into the training module. we were able to \ndetermine what abilities were required for the data and how to train the data to attain the greatest results by doing so. we \nlooked at how experience affects salary rates in this week's study. we were able to discover a plausible association between \nyears of experience and rate factor after analysing our data. we used nltk to clean up the data, fill in missing values, \neliminate stop words and non-alphabetic letters, and build a function as a second step in the frequency analysis. the \ninternship midterm report \n \ncomp8851 major project internship stream       \n                                         3 june 2022 \n \n15 \nfrequency of words in business analyst and data engineer requirements, as well as data analyst requirements, were \ndiscovered. \nlikewise, our supervisor callum employed hr advisors with company experience to better grasp the cv skills. as a result, \nshe invited us to weekly meetings and gave insights to accessories. as a result, there was enhancement in the project \ndevelopment, and everything was updated on jira. \nnew knowledge, skills, and experience \nduring this week, i learned how to mine text using python. to assist me with these duties, i learnt how to construct custom \nfunctions. to aid me in doing these duties, i learnt how to develop customised corpora and word lists. in addition, i now \nhave a better grasp of how to use python for text mining. similarly, i also learned about servant leadership, which is a \nleadership concept where the leader's primary motivation is to serve others (eva et al., 2019). it can be done in a variety of \nways, including offering support and direction to team members, and taking up duties and responsibilities that might \notherwise fall to others. \nrewarding experience \nworking as a scrum master was a highly fulfilling experience. we discovered that it was a fantastic approach to assist \nteams collaborate more effectively and efficiently, as well as a fantastic tool to gain a greater insight of a team's inner \nworkings. scrum masters, as previously said, may be an asset to a company by assisting in the improvement of \ncommunication and collaboration among the organization's teams. \ndifficult experience \nit was a difficult experience for me to be the scrum master for my team. i was responsible for keeping the team on track \nand ensuring that everyone was doing their job. it was a lot of work, and i had to keep track of everything. \ntask for the upcoming week \nthe assessment for the following week was to propose new keywords and phrases for gtp3 based on skill frequency \nanalysis.",
            "page": null,
            "goal": "week 5 \ngoals, activities and outcomes \nthe task we worked on this week was the same as the one we worked on the week before. we used the frequency analysis \nmethod once more to analyse the skill necessary for the task and feed that data into the training module. we were able to \ndetermine what abilities were required for the data and how to train the data to attain the greatest results by doing so. we \nlooked at how experience affects salary rates in this week's study. we were able to discover a plausible association between \nyears of experience and rate factor after analysing our data. we used nltk to clean up the data, fill in missing values, \neliminate stop words and non-alphabetic letters, and build a function as a second step in the frequency analysis. the \ninternship midterm report \n \ncomp8851 major project internship stream       \n                                         3 june 2022 \n \n15 \nfrequency of words in business analyst and data engineer requirements, as well as data analyst requirements, were \ndiscovered. \nlikewise, our supervisor callum employed hr advisors with company experience to better grasp the cv skills. as a result, \nshe invited us to weekly meetings and gave insights to accessories. as a result, there was enhancement in the project \ndevelopment, and everything was updated on jira. \nnew knowledge, skills, and experience \nduring this week, i learned how to mine text using python. to assist me with these duties, i learnt how to construct custom \nfunctions. to aid me in doing these duties, i learnt how to develop customised corpora and word lists. in addition, i now \nhave a better grasp of how to use python for text mining. similarly, i also learned about servant leadership, which is a \nleadership concept where the leader's primary motivation is to serve others (eva et al., 2019). it can be done in a variety of \nways, including offering support and direction to team members, and taking up duties and responsibilities that might \notherwise fall to others. \nrewarding experience \nworking as a scrum master was a highly fulfilling experience. we discovered that it was a fantastic approach to assist \nteams collaborate more effectively and efficiently, as well as a fantastic tool to gain a greater insight of a team's inner \nworkings. scrum masters, as previously said, may be an asset to a company by assisting in the improvement of \ncommunication and collaboration among the organization's teams. \ndifficult experience \nit was a difficult experience for me to be the scrum master for my team. i was responsible for keeping the team on track \nand ensuring that everyone was doing their job. it was a lot of work, and i had to keep track of everything. \ntask for the upcoming week \nthe assessment for the following week was to propose new keywords and phrases for gtp3 based on skill frequency \nanalysis.",
            "children": []
        },
        {
            "id": "1.9",
            "name": "week 6",
            "nodeType": "title",
            "text": "week 6",
            "page": null,
            "goal": "week 6",
            "children": []
        },
        {
            "id": "1.10",
            "name": "week 6 goals,",
            "nodeType": "paragraph",
            "text": "week 6 \ngoals, activities and outcomes \ngoals are met through finding data, extracting important roles, recording data, and creating a profile that may be utilised \nto establish data correlations. after the contract roles have been defined, the database has been used to analyse skillsets \nand requirements to match them to contract opportunities. following to that, phrase extraction was a challenging part in \nthis segment where we had to extract certain phrases for skill sets and requirements. my objective was to find the phrase \nthat appears the most frequently among a group of phrases. when i utilised the frequency analysis function, it just counted \nthe number of words, not the frequency with which they appeared. i would be grateful if there was a way to search for a \nterm and count how many times it appears in a document. meanwhile, callum also proposed that we could make more \ngraphs to show how the re-queried and skill data outputs interact with one another. \nnew knowledge, skills, and experience \nduring this week, i learned about gpt-3 which is a natural language processing platform that allows developers to train \nand deploy ai models. text classification, entity recognition, and sentiment analysis are just a few of the functions available \nin the programme. gpt-3 enables programmers to create programmes that can understand and respond to natural language \ninputs (dale, 2021). gtp 3 is a toolkit that enables the creation, testing, and deployment of chatbots and other \nconversational apps (pilipiszyn & openai, 2021). natural language processing, dialogue management, and a chatbot \ndevelopment tool are among the characteristics of the tool. \nrewarding experience \nusing the gpt-3 open-source ai model was a fantastic experience. i was able to use a range of data sets to train the model \nand get good results. the model also performed well when applied to new data sets. the gpt3 open-ai was a very enjoyable \ninternship midterm report \n \ncomp8851 major project internship stream       \n                                         3 june 2022 \n \n16 \nexperience for me. i was able to learn a lot about how the system works and how i may apply it to my own ai projects. \nthis is something i would recommend to anyone interested in learning more about open-ai or improving their own ai \nprojects. \ndifficult experience \nfor a variety of reasons, i found it challenging to apply the gpt-3 open-ai model. the model is initially very huge and \nrequires a lot of computer resources to run. furthermore, there is insufficient documentation, and the usage of model is \nunclear. to add to that, the model is always evolving, making it tough to keep up. \ntask for the upcoming week \nfor the next week, we will be working on building a generative pre-trained transformer. as a result, we plan to construct \na modified text using a pretrained model. to accomplish this, we will be using a pre-trained model to build customised \ntexts from scratch. following to that, we will make usage of a pre-trained model to fine-tune a new model for a given \npurpose. the task seems to be feasible, for example, to use a pre-trained model to generate creative techniques or product \ndescriptions. it is also likely to fine-tune a new model based on a pre-trained model for a specific purpose, such as sentiment \nanalysis or named entity identification.",
            "page": null,
            "goal": "week 6 \ngoals, activities and outcomes \ngoals are met through finding data, extracting important roles, recording data, and creating a profile that may be utilised \nto establish data correlations. after the contract roles have been defined, the database has been used to analyse skillsets \nand requirements to match them to contract opportunities. following to that, phrase extraction was a challenging part in \nthis segment where we had to extract certain phrases for skill sets and requirements. my objective was to find the phrase \nthat appears the most frequently among a group of phrases. when i utilised the frequency analysis function, it just counted \nthe number of words, not the frequency with which they appeared. i would be grateful if there was a way to search for a \nterm and count how many times it appears in a document. meanwhile, callum also proposed that we could make more \ngraphs to show how the re-queried and skill data outputs interact with one another. \nnew knowledge, skills, and experience \nduring this week, i learned about gpt-3 which is a natural language processing platform that allows developers to train \nand deploy ai models. text classification, entity recognition, and sentiment analysis are just a few of the functions available \nin the programme. gpt-3 enables programmers to create programmes that can understand and respond to natural language \ninputs (dale, 2021). gtp 3 is a toolkit that enables the creation, testing, and deployment of chatbots and other \nconversational apps (pilipiszyn & openai, 2021). natural language processing, dialogue management, and a chatbot \ndevelopment tool are among the characteristics of the tool. \nrewarding experience \nusing the gpt-3 open-source ai model was a fantastic experience. i was able to use a range of data sets to train the model \nand get good results. the model also performed well when applied to new data sets. the gpt3 open-ai was a very enjoyable \ninternship midterm report \n \ncomp8851 major project internship stream       \n                                         3 june 2022 \n \n16 \nexperience for me. i was able to learn a lot about how the system works and how i may apply it to my own ai projects. \nthis is something i would recommend to anyone interested in learning more about open-ai or improving their own ai \nprojects. \ndifficult experience \nfor a variety of reasons, i found it challenging to apply the gpt-3 open-ai model. the model is initially very huge and \nrequires a lot of computer resources to run. furthermore, there is insufficient documentation, and the usage of model is \nunclear. to add to that, the model is always evolving, making it tough to keep up. \ntask for the upcoming week \nfor the next week, we will be working on building a generative pre-trained transformer. as a result, we plan to construct \na modified text using a pretrained model. to accomplish this, we will be using a pre-trained model to build customised \ntexts from scratch. following to that, we will make usage of a pre-trained model to fine-tune a new model for a given \npurpose. the task seems to be feasible, for example, to use a pre-trained model to generate creative techniques or product \ndescriptions. it is also likely to fine-tune a new model based on a pre-trained model for a specific purpose, such as sentiment \nanalysis or named entity identification.",
            "children": []
        },
        {
            "id": "1.11",
            "name": "week 7",
            "nodeType": "title",
            "text": "week 7",
            "page": null,
            "goal": "week 7",
            "children": []
        },
        {
            "id": "1.12",
            "name": "week 7 goals,",
            "nodeType": "paragraph",
            "text": "week 7 \ngoals, activities and outcomes \nnot much of activity, goal, or outcome happened in this week. we were unable to contact with the supervisors regarding \nthe project development. however, this week was invested for self-enhancement, research, as well as analysis. i worked \non getting an insight on vectorization, transformation and rnn models etc. \nnew knowledge, skills, and experience \ni was able to successfully construct the lstm as well as rnn models. likewise, i also gained an understanding of \nconverting words to vectors with the usage of embeddings. this was a fantastic learning opportunity for me, and i am \nlooking forward to using these skills in upcoming days. \nrewarding experience \nthe implementations in relate to lstm as well as rnn models produced an excellent result as per the expectations. this \nweek was a lot of fun watching the cv enhancement project take shape, and i was excited to keep working on it. \ndifficult experience \ncallum's hr members were not actively involved in the creation of scrum meetings, and the group was unable to construct \na model. the group was undecided as to whether we should design a model or wait for something new to be introduced. it \nhad been a rather uneventful week. i started constructing lstm as well as rnn models to share with my team, and i was \nlooking for ways to integrate keywords in phrases. i also demonstrated the team insights on how we may develop a website \nutilising flash models and, if necessary, incorporate our model onto it. as",
            "page": null,
            "goal": "week 7 \ngoals, activities and outcomes \nnot much of activity, goal, or outcome happened in this week. we were unable to contact with the supervisors regarding \nthe project development. however, this week was invested for self-enhancement, research, as well as analysis. i worked \non getting an insight on vectorization, transformation and rnn models etc. \nnew knowledge, skills, and experience \ni was able to successfully construct the lstm as well as rnn models. likewise, i also gained an understanding of \nconverting words to vectors with the usage of embeddings. this was a fantastic learning opportunity for me, and i am \nlooking forward to using these skills in upcoming days. \nrewarding experience \nthe implementations in relate to lstm as well as rnn models produced an excellent result as per the expectations. this \nweek was a lot of fun watching the cv enhancement project take shape, and i was excited to keep working on it. \ndifficult experience \ncallum's hr members were not actively involved in the creation of scrum meetings, and the group was unable to construct \na model. the group was undecided as to whether we should design a model or wait for something new to be introduced. it \nhad been a rather uneventful week. i started constructing lstm as well as rnn models to share with my team, and i was \nlooking for ways to integrate keywords in phrases. i also demonstrated the team insights on how we may develop a website \nutilising flash models and, if necessary, incorporate our model onto it. as",
            "children": []
        },
        {
            "id": "1.13",
            "name": "week 8",
            "nodeType": "title",
            "text": "week 8",
            "page": null,
            "goal": "week 8",
            "children": []
        },
        {
            "id": "1.14",
            "name": "week 8 was",
            "nodeType": "paragraph",
            "text": "week 8 was approaching, i was concerned about \nnot completing the model and presenting it to the university. \ntask for the upcoming week \nno task has been assigned for upcoming week and i was waiting for a meeting with callum for better understanding of the \nproject development.  \n \nweek 8 \ngoals, activities and outcomes \nafter a zoom meeting with callum and other team members, i got an understanding of the project development for this \nweek. the data structure and keywords that we extracted showed anomalies. the extraction of keywords that we fetched \ninternship midterm report \n \ncomp8851 major project internship stream       \n                                         3 june 2022 \n \n17 \nwas not good enough to improve cvs. callum instructed us to improve and refine our data cleaning part and extract the \nrelevant keywords from the data set. \nnew knowledge, skills, and experience \nduring the analysis, i realised how important is the structure of words in english for the cv enhancement. similarly, it \nwas equally important for us to do the data cleaning part precisely and be aware of keywords and remove adjectives from \nthe extracted keywords. \nrewarding experience \nmeeting with callum, who is an expert in the industry, was a rewarding experience. the group was able to better \ncomprehend the project development and enhance the technical skills with the guidance from him. \ndifficult experience \nit was difficult for the team to analyse and remove anomalies from the extracted keywords. however, we were able to get \nrid of difficulties by communicating and cooperating with each other within the team. \ntask for the upcoming week \nas suggested by callum, we were advised on working with the data cleaning part and making fetched keywords more \nprecise. to add to that, upcoming week could be utilized on evaluating the skills required for certain role using a frequency \nanalysis method and that information should be sent into the training module. likewise, we need to find out approaches to \ntrain models efficiently after cleaning/refining the extracted keywords.",
            "page": null,
            "goal": "week 8 was approaching, i was concerned about \nnot completing the model and presenting it to the university. \ntask for the upcoming week \nno task has been assigned for upcoming week and i was waiting for a meeting with callum for better understanding of the \nproject development.  \n \nweek 8 \ngoals, activities and outcomes \nafter a zoom meeting with callum and other team members, i got an understanding of the project development for this \nweek. the data structure and keywords that we extracted showed anomalies. the extraction of keywords that we fetched \ninternship midterm report \n \ncomp8851 major project internship stream       \n                                         3 june 2022 \n \n17 \nwas not good enough to improve cvs. callum instructed us to improve and refine our data cleaning part and extract the \nrelevant keywords from the data set. \nnew knowledge, skills, and experience \nduring the analysis, i realised how important is the structure of words in english for the cv enhancement. similarly, it \nwas equally important for us to do the data cleaning part precisely and be aware of keywords and remove adjectives from \nthe extracted keywords. \nrewarding experience \nmeeting with callum, who is an expert in the industry, was a rewarding experience. the group was able to better \ncomprehend the project development and enhance the technical skills with the guidance from him. \ndifficult experience \nit was difficult for the team to analyse and remove anomalies from the extracted keywords. however, we were able to get \nrid of difficulties by communicating and cooperating with each other within the team. \ntask for the upcoming week \nas suggested by callum, we were advised on working with the data cleaning part and making fetched keywords more \nprecise. to add to that, upcoming week could be utilized on evaluating the skills required for certain role using a frequency \nanalysis method and that information should be sent into the training module. likewise, we need to find out approaches to \ntrain models efficiently after cleaning/refining the extracted keywords.",
            "children": []
        },
        {
            "id": "1.15",
            "name": "week 9",
            "nodeType": "title",
            "text": "week 9",
            "page": null,
            "goal": "week 9",
            "children": []
        },
        {
            "id": "1.16",
            "name": "week 9 goals,",
            "nodeType": "paragraph",
            "text": "week 9 \ngoals, activities and outcomes \nduring this week, we did a lot of analysis and brainstorming to improve the cv enhancement project. we were able to \ndeduce the framework for extracting keywords but were unable to locate them in the data. also, our team faced complexities \nwith the data structure. likewise, i proposed the group work on text generation techniques as well, resulting to that, i \nhanded the team a structure based on rnn model. \nnew knowledge, skills, and experience \n as the project progressed, there were few complications; however, we were able to develop our efficiency by conducting \nresearch and self-evaluation. this helped me in learning key skills and strategies to be followed for time management and \nfor being efficient. we were also able to communicate more effectively and work together to overcome the challenges of \nthe project. \nrewarding experience \nit was genuinely satisfying for me to find effective ways to solve difficult tasks. we were able to accomplish more and \nunderstand from each other in the team by working collectively. \ndifficult experience \nas an intern, we had a perception that it would be beneficial for us to receive advice on specific tools/techniques and \npresentations on accomplishing milestones. on this project, we mostly worked alone. even though callum was always \nthere for us, i realised as being in a group of data scientists, we collectively as a team, must shape this project over time. \nnobody ever showed us how to put the system together. however, we were aware of all these things and welcomed the \nchallenges because we knew we already have the necessary education and experience required in this field. \ntask for the upcoming week \nfor the upcoming week, allocated tasks will be data augmentation, machine learning and model building. likewise, we \nwill also be working on using various techniques to enhance the cv project and try to make it more accurate. \n \ninternship midterm report \n \ncomp8851 major project internship stream       \n                                         3 june 2022 \n \n18",
            "page": null,
            "goal": "week 9 \ngoals, activities and outcomes \nduring this week, we did a lot of analysis and brainstorming to improve the cv enhancement project. we were able to \ndeduce the framework for extracting keywords but were unable to locate them in the data. also, our team faced complexities \nwith the data structure. likewise, i proposed the group work on text generation techniques as well, resulting to that, i \nhanded the team a structure based on rnn model. \nnew knowledge, skills, and experience \n as the project progressed, there were few complications; however, we were able to develop our efficiency by conducting \nresearch and self-evaluation. this helped me in learning key skills and strategies to be followed for time management and \nfor being efficient. we were also able to communicate more effectively and work together to overcome the challenges of \nthe project. \nrewarding experience \nit was genuinely satisfying for me to find effective ways to solve difficult tasks. we were able to accomplish more and \nunderstand from each other in the team by working collectively. \ndifficult experience \nas an intern, we had a perception that it would be beneficial for us to receive advice on specific tools/techniques and \npresentations on accomplishing milestones. on this project, we mostly worked alone. even though callum was always \nthere for us, i realised as being in a group of data scientists, we collectively as a team, must shape this project over time. \nnobody ever showed us how to put the system together. however, we were aware of all these things and welcomed the \nchallenges because we knew we already have the necessary education and experience required in this field. \ntask for the upcoming week \nfor the upcoming week, allocated tasks will be data augmentation, machine learning and model building. likewise, we \nwill also be working on using various techniques to enhance the cv project and try to make it more accurate. \n \ninternship midterm report \n \ncomp8851 major project internship stream       \n                                         3 june 2022 \n \n18",
            "children": []
        },
        {
            "id": "1.17",
            "name": "week 10",
            "nodeType": "title",
            "text": "week 10",
            "page": null,
            "goal": "week 10",
            "children": []
        },
        {
            "id": "1.18",
            "name": "week 10 goals,",
            "nodeType": "paragraph",
            "text": "week 10 \ngoals, activities and outcomes \nthe objective of this week was to conduct a research and work on approaches for improving cv performance. i researched \nand read about popular strategies including data augmentation, transfer learning, and model assembly. i also tried out some \nof these strategies on the cv project. i gathered our group for our cv enhancement project to demonstrate how gpt-3 \nworks and how private data may be created. once gpt-3 has obtained the confidential data, we may not require the list or \ncsv file. gpt-3, in my perspective, could manage it all. i was concerned that this might not be in accordance with what \ncallum suggested earlier. however, to succeed, you must sometimes take a risk.  \nfirstly, we had a meeting with a commonwealth bank full stack developer to obtain some tips on how to develop the \nsystem we were envisioning. despite his efforts, he was unable to offer assistance because ml modelling was something \nhe did not understand. furthermore, we decided to seek assistance from professor amin on the structure of the cv enhancer \nproject. professor responded with an insightful article in the field of recruiting automation. that article improved the \ndirection of our effort and was a huge benefit to us.  \nas a result, we created ivi, a chatbot-based sms service that facilitates users to communicate and submit questions. ivi \nemploys a decision tree paradigm in which nodes are created using a prompt. callum, on the other hand, was not pleased \nwith the idea of ivi, so we had to create a new method. \nnew knowledge, skills, and experience \nartificial intelligence technology that is made available to the public for usage and modification is referred to as open-\nsource ai. this term generally refers to ai software that is provided under an open-source licence, which allows users to \nview and edit the source code without restriction.  similarly, twilio is a cloud-based messaging platform that enables \ncompanies to engage with their consumers using chatbots and other messaging apps. it enables companies to build, manage, \nand implement chatbots on a range of messaging platforms, such as facebook messenger, skype, whatsapp, and twitter \netc.  \nlikewise, i got an insight on render that is a web-based design platform that allows designers and businesses to build, \ndistribute, and manage custom websites and online storefronts. users can construct professional-looking websites in \nminutes using render.com, even if they have no prior coding or design skills. render.com also includes several built-in \nfeatures and tools, such as ecommerce support, search engine optimization, social network integration, and so on. \nrewarding experience \ni was extremely happy with the progress of project development this week. discovering efficient solutions to complicated \nchallenges was certainly satisfying for me. \ndifficult experience \ndebugging the gpt-3 code was the highly challenging task this week. i had some difficulties for operating the code \nappropriately, however, i was able to overcome the problem in the end. \ntask for the upcoming week \nthe task for the forthcoming week will be getting insights on the usages of new model by studying through exploration \nand analysis. similarly, we will also cover several parts of data visualisation.",
            "page": null,
            "goal": "week 10 \ngoals, activities and outcomes \nthe objective of this week was to conduct a research and work on approaches for improving cv performance. i researched \nand read about popular strategies including data augmentation, transfer learning, and model assembly. i also tried out some \nof these strategies on the cv project. i gathered our group for our cv enhancement project to demonstrate how gpt-3 \nworks and how private data may be created. once gpt-3 has obtained the confidential data, we may not require the list or \ncsv file. gpt-3, in my perspective, could manage it all. i was concerned that this might not be in accordance with what \ncallum suggested earlier. however, to succeed, you must sometimes take a risk.  \nfirstly, we had a meeting with a commonwealth bank full stack developer to obtain some tips on how to develop the \nsystem we were envisioning. despite his efforts, he was unable to offer assistance because ml modelling was something \nhe did not understand. furthermore, we decided to seek assistance from professor amin on the structure of the cv enhancer \nproject. professor responded with an insightful article in the field of recruiting automation. that article improved the \ndirection of our effort and was a huge benefit to us.  \nas a result, we created ivi, a chatbot-based sms service that facilitates users to communicate and submit questions. ivi \nemploys a decision tree paradigm in which nodes are created using a prompt. callum, on the other hand, was not pleased \nwith the idea of ivi, so we had to create a new method. \nnew knowledge, skills, and experience \nartificial intelligence technology that is made available to the public for usage and modification is referred to as open-\nsource ai. this term generally refers to ai software that is provided under an open-source licence, which allows users to \nview and edit the source code without restriction.  similarly, twilio is a cloud-based messaging platform that enables \ncompanies to engage with their consumers using chatbots and other messaging apps. it enables companies to build, manage, \nand implement chatbots on a range of messaging platforms, such as facebook messenger, skype, whatsapp, and twitter \netc.  \nlikewise, i got an insight on render that is a web-based design platform that allows designers and businesses to build, \ndistribute, and manage custom websites and online storefronts. users can construct professional-looking websites in \nminutes using render.com, even if they have no prior coding or design skills. render.com also includes several built-in \nfeatures and tools, such as ecommerce support, search engine optimization, social network integration, and so on. \nrewarding experience \ni was extremely happy with the progress of project development this week. discovering efficient solutions to complicated \nchallenges was certainly satisfying for me. \ndifficult experience \ndebugging the gpt-3 code was the highly challenging task this week. i had some difficulties for operating the code \nappropriately, however, i was able to overcome the problem in the end. \ntask for the upcoming week \nthe task for the forthcoming week will be getting insights on the usages of new model by studying through exploration \nand analysis. similarly, we will also cover several parts of data visualisation.",
            "children": []
        },
        {
            "id": "1.19",
            "name": "week 11",
            "nodeType": "title",
            "text": "week 11",
            "page": null,
            "goal": "week 11",
            "children": []
        },
        {
            "id": "1.20",
            "name": "week 11 goals,",
            "nodeType": "paragraph",
            "text": "week 11 \ngoals, activities and outcomes \nduring this week, callum organised a meeting to help us understand the system development. he identified the action \nverbs and explained how the past tense language functions to execute the decision tree model. he also explained how to \ninternship midterm report \n \ncomp8851 major project internship stream       \n                                         3 june 2022 \n \n19 \nget rid of prejudiced terms. following to that, he also conducted a gap workshop where our data science team went \nthrough a real-world job scenario. on the other hand, we also did the required data visualisation and data analysis part. \nnew knowledge, skills, and experience \nthis week, i learned further about tools and techniques required for the enhancement of accuracy and performance of our \nsystem. i also had hands-on experience using these strategies on a real-world task. this was a fantastic learning opportunity \nfor me, and i am looking forward to using these tactics in my upcoming projects.  \nrewarding experience \nthe outcomes of this week’s effort delighted me greatly. it felt great to see the cv enhancement project go live and \ndemonstrating it with callum and other team members. to add to that, i am really looking forward to continuing working \non this project even after the internship as it profoundly connects to real-world scenario, and it facilitates us to get various \ninsights on any specific industry and job market. \ndifficult experience \nwe implemented several parts of the system on various platforms and notebook files, so compiling all those in a same \nplace was a bit hectic. \ntask for the upcoming week \nthe final week’s task will be wrapping up the implementation and system development. following to that, we are required \nto do appropriate data analysis such as creating word cloud, clusters, visualising plots/charts. the next week’s task will be \ncomprised of project deliverables and having an insight on key takeaways & learnings from this internship opportunity.",
            "page": null,
            "goal": "week 11 \ngoals, activities and outcomes \nduring this week, callum organised a meeting to help us understand the system development. he identified the action \nverbs and explained how the past tense language functions to execute the decision tree model. he also explained how to \ninternship midterm report \n \ncomp8851 major project internship stream       \n                                         3 june 2022 \n \n19 \nget rid of prejudiced terms. following to that, he also conducted a gap workshop where our data science team went \nthrough a real-world job scenario. on the other hand, we also did the required data visualisation and data analysis part. \nnew knowledge, skills, and experience \nthis week, i learned further about tools and techniques required for the enhancement of accuracy and performance of our \nsystem. i also had hands-on experience using these strategies on a real-world task. this was a fantastic learning opportunity \nfor me, and i am looking forward to using these tactics in my upcoming projects.  \nrewarding experience \nthe outcomes of this week’s effort delighted me greatly. it felt great to see the cv enhancement project go live and \ndemonstrating it with callum and other team members. to add to that, i am really looking forward to continuing working \non this project even after the internship as it profoundly connects to real-world scenario, and it facilitates us to get various \ninsights on any specific industry and job market. \ndifficult experience \nwe implemented several parts of the system on various platforms and notebook files, so compiling all those in a same \nplace was a bit hectic. \ntask for the upcoming week \nthe final week’s task will be wrapping up the implementation and system development. following to that, we are required \nto do appropriate data analysis such as creating word cloud, clusters, visualising plots/charts. the next week’s task will be \ncomprised of project deliverables and having an insight on key takeaways & learnings from this internship opportunity.",
            "children": []
        },
        {
            "id": "1.21",
            "name": "week 12",
            "nodeType": "title",
            "text": "week 12",
            "page": null,
            "goal": "week 12",
            "children": []
        },
        {
            "id": "1.22",
            "name": "week 12 goals,",
            "nodeType": "paragraph",
            "text": "week 12 \ngoals, activities and outcomes \nto maximise the project development and wrap up the project accomplishment, we had several meetings this week for \nbrainstorming, and compilation. initially, we split the activities into four different categories based on the functionalities. \nthe first part comprised of exploratory data analysis such as creation of bar charts/plots etc. for demonstration of various \nrelationships between the variables and getting significant insights through it. similarly, the second part included data \ncleaning, extraction of proper keywords and creation of clusters based on variables such as rate, skills etc. we used knn \nalgorithm for the implementation of clustering.  \nlikewise, the third part incorporated the gpt-3 implementation and execution of structured sentences. in this part, we \nfetched several data for sample action verbs/ tools etc. for our reference. also, we split the sentences into several tokens \nand matched those elements with the defined dictionaries of sample action verbs and tools etc. to add to that, we also \nfocused on measuring the degree of action verbs fetched and set the strong action verbs at first with the appropriate \nstructure. last part holds the documentation, compiling, implementing, debugging, and finally delivering the project.  \nduring this week, i worked on the second and third part along with ugur, my team member for the project. we explored \ndifferent possibilities on establishing correlation between variables such as role, pay rate and skills etc. similarly, we \ncategorised the data into three different roles as data analyst, data engineer and business analyst. after the data extraction \ncomes the cleaning part, where we used different libraries such as nlp, nltk and spacy etc. similarly, we used k-nearest \nneighbours’ algorithm for the second part for clustering.  \nfinally, after getting the extracted and refined keywords, we had to classify those appropriately. the important attributes \nfor each classification were then obtained. we researched and used several classification techniques for this classification \nproblem. for this project, callum requested to our team to employ the decision tree method, and we achieved a 78% \naccuracy on that. furthermore, the model can be improved by using larger datasets, extracting other relevant keywords, \napplying bi-gram tokens in place of unigrams, and enhancing the data pipelines using programmes like pyspark. \ninternship midterm report \n \ncomp8851 major project internship stream       \n                                         3 june 2022 \n \n20 \nnew knowledge, skills, and experience \nin python, aitextgen is a sophisticated library for creating text documents. it comes with several built-in classes for \nconstructing various forms of text documents, such as character strings, paragraphs, and headings etc. likewise, we learned \nabout several clustering and classification techniques in python. the supervised machine learning clustering technique k-\nnearest neighbours (knn) is an easy and simple method that can be utilized to handle both categorization as well as \nregression issues. likewise, we also discovered various text processing libraries in relate to natural language processing, \nvisualisation tools, and libraries in relate to data cleaning. \nrewarding experience \ncollaborating with other members of the team was a fantastic experience. despite the obstacles, we were able to operate \nefficiently and achieve our weekly objectives. we delivered the project as requested by callum and i feel proud of what \nwe did during these 12 weeks. it was a genuinely satisfying experience for overcoming the challenges and accomplish the \nobjectives given.  \ndifficult experience \nto my understanding, this project is huge and could not have been completed in 12 weeks’ time. however, we pushed \nour limits and tried our best to the extent we could. resulting to that, it somehow impacted on myself getting exhausted \nduring my part-time work and other activities.",
            "page": null,
            "goal": "week 12 \ngoals, activities and outcomes \nto maximise the project development and wrap up the project accomplishment, we had several meetings this week for \nbrainstorming, and compilation. initially, we split the activities into four different categories based on the functionalities. \nthe first part comprised of exploratory data analysis such as creation of bar charts/plots etc. for demonstration of various \nrelationships between the variables and getting significant insights through it. similarly, the second part included data \ncleaning, extraction of proper keywords and creation of clusters based on variables such as rate, skills etc. we used knn \nalgorithm for the implementation of clustering.  \nlikewise, the third part incorporated the gpt-3 implementation and execution of structured sentences. in this part, we \nfetched several data for sample action verbs/ tools etc. for our reference. also, we split the sentences into several tokens \nand matched those elements with the defined dictionaries of sample action verbs and tools etc. to add to that, we also \nfocused on measuring the degree of action verbs fetched and set the strong action verbs at first with the appropriate \nstructure. last part holds the documentation, compiling, implementing, debugging, and finally delivering the project.  \nduring this week, i worked on the second and third part along with ugur, my team member for the project. we explored \ndifferent possibilities on establishing correlation between variables such as role, pay rate and skills etc. similarly, we \ncategorised the data into three different roles as data analyst, data engineer and business analyst. after the data extraction \ncomes the cleaning part, where we used different libraries such as nlp, nltk and spacy etc. similarly, we used k-nearest \nneighbours’ algorithm for the second part for clustering.  \nfinally, after getting the extracted and refined keywords, we had to classify those appropriately. the important attributes \nfor each classification were then obtained. we researched and used several classification techniques for this classification \nproblem. for this project, callum requested to our team to employ the decision tree method, and we achieved a 78% \naccuracy on that. furthermore, the model can be improved by using larger datasets, extracting other relevant keywords, \napplying bi-gram tokens in place of unigrams, and enhancing the data pipelines using programmes like pyspark. \ninternship midterm report \n \ncomp8851 major project internship stream       \n                                         3 june 2022 \n \n20 \nnew knowledge, skills, and experience \nin python, aitextgen is a sophisticated library for creating text documents. it comes with several built-in classes for \nconstructing various forms of text documents, such as character strings, paragraphs, and headings etc. likewise, we learned \nabout several clustering and classification techniques in python. the supervised machine learning clustering technique k-\nnearest neighbours (knn) is an easy and simple method that can be utilized to handle both categorization as well as \nregression issues. likewise, we also discovered various text processing libraries in relate to natural language processing, \nvisualisation tools, and libraries in relate to data cleaning. \nrewarding experience \ncollaborating with other members of the team was a fantastic experience. despite the obstacles, we were able to operate \nefficiently and achieve our weekly objectives. we delivered the project as requested by callum and i feel proud of what \nwe did during these 12 weeks. it was a genuinely satisfying experience for overcoming the challenges and accomplish the \nobjectives given.  \ndifficult experience \nto my understanding, this project is huge and could not have been completed in 12 weeks’ time. however, we pushed \nour limits and tried our best to the extent we could. resulting to that, it somehow impacted on myself getting exhausted \nduring my part-time work and other activities.",
            "children": []
        }
    ]
}