{
    "id": "1",
    "name": "Reflective journal Entities",
    "nodeType": "section",
    "text": "week 1 \ngoals, activities, outcomes \ngoals: my goals for week 1 is to finalise the company that will be sponsoring me for my internship \nprogram, complete all the onboarding process and get to know more about the company. \nactivities: i had done lots of researches on the companies which i was intending to apply and \ncontacted the company to express my interest in joining their internship program. after receiving \nresponse from truuth, i was invited for the first round of interview with sai, who would potentially \nbe my team leader if i were admitted into the program. i passed the first round of interview by \nrelating my previous experiences with the current project - document authentication which i hope i \nwould be given the opportunity to be involved in. i was then invited to the second round of \ninterview whereby i had to present on a given topic – document authentication by doing some \nresearches and reading through some academic papers. after acing both interviews, i was then \ninvited to have a virtual meet-up with nick who is the co-founder of truuth to discuss about the \nonboarding process. i then started to prepare the internship proposal and fill up the mq internship \nform before sending those back to the company to ask for their review and signature.  \noutcomes: i had successfully been admitted into truuth internship program after completing all the \nonboarding process and sending back all the required documents to the unit convener for further \nreview and assessment. after doing researches on the company, i also had a better overview \nunderstanding on the background, visions and goals that truuth is trying to achieve as an \norganisation. \nnew knowledge, skills and experiences \nknowledge: i gained some knowledge on different types of identity falsification method and \ntechniques to overcome each of them after doing some researches on document authentication. in \naddition, i also had a better understanding towards the company’s background, competitors, \nmarkets and customers. \nskills: i had developed researching skills while doing some researches on the assigned topic. i have \nalso developed communication skills while interacting with the company back and forth. \nexperience: i gained some interview experience after going through multiple rounds of interview \nwith truuth. i also had the opportunity to get an overview on the real projects, problems and \nchallenges currently faced by the corporate world. \nrewarding experience \nthe interview experience was particularly rewarding as i managed to enhance my interviewing skills \nand learnt to be more confident with myself. also, it was a good reflection on myself to assess \nwhether my previous experiences and my current knowledge were sufficient to prepare me for \nemployment. \ndifficult experience \nthe topic on identity falsification techniques and methods in fraudulent documents detection were \nrelatively new to me as i was not from a cybersecurity background had never been in touch with this \ntopic before. however, i managed to overcome the challenge by spending a few hours each day to \n21 \n \ncarry out in-depth research and review lots of academic papers to brush up my knowledge in this \nfield. i was really glad that my efforts paid off when i received accolade from my team leader, sai on \nthe writeup that i had voluntarily done to summarise on the document falsification research topic. \nupcoming task \nthe task assigned to me for the upcoming week is to complete the required training and onboarding \nprocedures and also start to get myself familiar with the products and services offered in truuth. \n \n9.2 week 2 \ngoals, activities, outcomes \ngoals: to complete the required training and onboarding procedures with truuth and have a better \nunderstanding towards the company in terms of the products offered, tools, technology and \nplatforms used at the end of the week. \nactivities: the first thing i had done early of this week is to complete my training and some leftover \nonboarding process. one of my first steps in onboarding was to provide my identity documents for \nverification which could be done via truuth id submission. the truuth id is a product developed by \nthe company itself in carrying out identity document verification. that was a great opportunity for \nme to have a user experience on the product and have a better understanding towards the products \ndeveloped by the company. furthermore, part of the onboarding training process was to undergo \nthe security and awareness training as part of the company’s information security management \nsystem policy. also, i was required to encrypt and install anti-virus on my device as a form of \nprotection towards the company’s confidentiality. the last step of the onboarding process was to get \nmyself familiar with the company’s policies which all the employees should abide by strictly. \nthroughout the week, i was also being introduced on the tools, technologies and platforms used by \nthe company and the products and solution offered by the comapny such as truuth’s kyc, identity, \nbiopass, verify, liveness and facekey. \noutcomes: i had successfully completed all the onboarding process and gotten myself familiarised \naround with different types of tools and technology platforms such as the microsoft teams, \nconfluence and aws platform that i would be actively using throughout my internship program. \nafter completing the security and awareness training, i had also gained some knowledge in \ncybersecurity protection and the standard procedures to comply with in a company during the event \nof cyberattack.  \nnew knowledge, skills and experiences \nknowledge: while completing the security and awareness training, i realised the importance of \nemployees in having some basic fundamental knowledge in the cybersecurity space no matter which \nindustry they are in to prevent any forms of cyberattack such as ransomware, supply chain attacks, \nsocial engineering, business email compromise, watering hole and others. also, i had a better \nunderstanding on how the products and solutions from truuth work and the target customers for \neach of the product. \nskills: throughout the week, i had developed self-learning and problem-solving skills by learning to \novercome and solve challenges independently without being overly reliant and dependent on \nothers. \n22 \n \nexperience: the valuable experience i had gained this week is the opportunity to get to know the \npeople in my team. they are all extremely friendly and helpful in assisting me to get familiar around \nthe work the team was currently working on. \nrewarding experience  \nit was particularly rewarding to be exposed to different types of tools and technology platforms \nbeing used in the company. i was extremely fortunate to have the chance to learn and get my hands \non the confluence platform developed by atlassian which is actively being used in the company to \ncapture project requirements, assign tasks, manage multiple projects simultaneously and most \nimportantly, to collaborate with one another. this made me realised that being a data scientist in \nthe real corporate world, it is not just all about being proficient in technical skills. it is also extremely \nvital to have the skills such as communication, teamwork and collaboration especially while working \nwith a team to complete a project. \nchallenging experience \nthere were quite a lot of tools, technologies and platforms used by the company which i had never \ncome across before especially on the aws platform. it was a bit of a challenge at the start for me. \nhowever, i managed to get myself to explore around and be familiarised with the tools and \nplatforms at the end of the week by seeking guidance from my team members proactively. this \nvaluable experience had taught me that there will unavoidably be some challenges when i first \nstepped into a new space or domain but i believe that with the right learning skills, mentality and \nattitude, there is nothing that could stop me from achieving my goal.  \nupcoming task \nin the next upcoming week, i would be expected to go through an official knowledge transfer session \nafter i have been assigned to a team and a particular project work stream that i will be working on \nthroughout my internship program. i would also be expected to be familiar around the problems \nthat our team is trying to solve and come out with ideas and recommendations on how to approach \nthe problems. \n \n9.3 week 3 \ngoals, activities, outcomes \ngoals: by the end of this week, i would be expected to have a great understanding on the problems \nor issues in my selected work stream and come out with some approaches and solutions to address \neach of the identified issue in the next coming step. \nactivities: early of this week, i was officially assigned to be in the document classification and \nauthentication team. i was being briefed on the problems statements and the objectives that the \nteam were aiming to achieve. after discussion, it was decided that i would be in-charge of the image \nsuperimposition test domain. it would involve carrying out authenticity and verification check on \nthe photo in the identity documents. the main proposed method in tackling the issue was by \nutilising the anomaly detection model to detect any signs of outliers in the photo region. this area of \nwork was initially started by an ex-staff member in truuth. after some arrangements, the knowledge \ntransfer process was conducted, whereby all the materials and previous in-progress work and codes \nwere being passed down to me. hence, i had been going through all the materials that are being \n23 \n \nhanded over to me. in addition, i also spent some time to review various research papers on \nanomaly detection and the effectiveness of it when being applied on image superimposition test. i \nhad also attended my first daily and weekly stand-up session with my team members whereby we \nhad a productive discussion on various ways and techniques to increase the accuracy of features \nextraction being applied on identity documents from different states and countries. \noutcomes: i had successfully gotten myself to be familiar around the work, projects and particularly \nthe problems in document authentication that my team were currently working on. after this week, \ni also had a clear direction on the goal and objective that i am trying to achieve. in addition, i had \nalso done enough research in the area of document authentication and image superimposition test \nto prepare myself in embracing the upcoming work. \nnew knowledge, skills and experiences  \nknowledge: i learnt about the major problems and obstacles in classifying and verifying id \ndocuments. various aspects and dimensions would have to be taken into consideration during the \nworkflow and image superimposition test plays and important role in the document authentication \nprocess \nskills: i had developed researching skills while carrying out in-depth research on image \nsuperimposition test and anomaly detection models. i had also developed communication and \npresentation skills while presenting the findings i had discovered during my research and \ncontributing ideas and insights during the meeting. \nexperience: the valuable experience i had gained was the opportunity to be involved in solving the \nreal-world problems and realised the huge impacts and consequences brought upon by fake id \ndocuments which could easily be done through photo substitution and tampering. this would \neventually lead to identity theft and fraud whereby various type of fraudulent documents would be \ncirculating in the market. \nrewarding experience \ni was extremely happy when i was finally assigned to work on a particular stream that i was very \ninterested in. it was also very rewarding to get to know my team members and understand the \nscope and type of work they were focusing on. i was also extremely grateful to be able to receive \ndirect guidance and mentor from the co-founder of truuth, mike and also my team leader, sai \nduring the daily stand-up and weekly meeting. \nchallenging experience \nit was a bit hard initially to get an understanding and overview on the work passed down by the ex-\ncolleague due to the lack of documentation on the previous work done. however, i managed to \novercome the challenge by consulting my team leader, sai for further clarifications and verifications \non the doubt i had in mind.  \nupcoming task \nin the next upcoming week, my goal is to start diving into the actual work by identifying and \nchoosing the best anomaly detection model to be used in the image superimposition test. \n \n \n24 \n \n9.4 week 4 \ngoals, activities, outcomes \ngoals: by the end of this week, i would be expected to choose the most ideal anomaly detection \nmodel to carry out the image superimposition test.  \nactivities: after doing some research on different types of anomaly detection models, i had chosen \nthe fully convolutional cross-scale-flows (cs-flow) model on image-based defect detection. after \nobtaining approval and support from mike and sai, i then proceeded to extract the codes which was \nprovided by the author of the cs-flow model research paper in github. i learnt from both mike and \nsai that before deciding to adopt a model from the research paper, we had to first replicate the \nresult by executing the codes provided by the author to verify on the model performance as \npublished in the paper. after going through the process, it was discovered that the actual result \nobtained was slightly below the reported result. however, since the overall performance of the \nmodel was still acceptable and decent, we had made the decision to proceed on with our image \nsuperimposition test by adopting the cs-flow model. \noutcomes: i had successfully chosen an ideal anomaly detection model to conduct the image \nsuperimposition test. also, i had managed to replicate the code provided by the author to verify on \nthe reported performance result to ensure the validity and reliability of the cs-flow model. \nnew knowledge, skills and experiences  \nknowledge: i had learnt something new that anomaly detection is an effective model in identifying \nsigns of photo substitution in an id document through the detection of unaligned photo frames, \nedges and boundaries. the other model that i had explored was the copy-paste detection technique \nwhereby the algorithm has the ability to identify signs of copy pasting in tampering the id document. \nskills: i had developed researching skills while carrying out in-depth research on various anomaly \ndetection models. i also learnt to be confident in expressing my thoughts and perspectives while \ncontributing ideas and insights during the meeting. \nexperience: the valuable experience i had gained is the opportunity to present my view points and \nshare some ideas on the ways we could approach the problem. it was really great to hear some \nprecious feedbacks and affirmation from my team members especially from mike and sai. \nrewarding experience \nthe experience that was particularly rewarding was when i had the chance to work together and had \nlots of productive brainstorming and discussion sessions with my team members. it definitely \nopened my eyes on the different approaches that i should make while tackling various kinds of \nproblem. the discussion was very productive as it allowed me to look at the issues differently from \nanother perspective. \nchallenging experience \nit was quite daunting when i was required to find an anomaly detection model to apply on the image \nsuperimposition test. however, i realised that all my previous research work done had finally paid \noff as i now had a deep understanding on various kind of anomaly detection models. with the advice \nand pointers from mike and sai, i managed to shortlist the top three models and finally select the \nbest model, cs-flow model which was also approved by the team.  \n25 \n \nupcoming task \nin the next upcoming week, i would be expected to create some datasets to be fed into the chosen \ncs-flow model while carrying out the image superimposition test. \n \n9.5 week 5 \ngoals, activities, outcomes \ngoals: by the end of this week, i would be expected to create different versions of dataset to be \nused in the image superimposition test. \nactivities: the datasets preparation involved the creation of falsified documents. this could be \nachieved by cropping a portrait image with similar background and pasting it on top of the photo \nregion of a real document. after creating the falsified id documents, i then proceeded in identifying \nthe region of interest (roi) from the id document datasets. after having several discussions with \nmike and sai, we had decided to extract the corners of the border frame as the roi as we were \ninterested to find out whether our anomaly detection model would be able to detect the presence \nof photo substitution via the border frame point of region.  \noutcomes: i had successfully created different types of falsified id documents and identified the \nregion of interest from the datasets that we would be using to test against our chosen model. \nnew knowledge, skills and experiences  \nknowledge: i had learnt different types of approaches and methods that could be used in creating \nfake id documents and had the opportunity to master some of the advanced python packages. \nskills: i had developed problem solving skills from the work that i had done over the week as i was \nrequired to think of the best approach in carrying out document falsification. i also managed to \nbrush up my programming skills throughout the process of creating fake id document datasets. \nexperience: the valuable experience i had gained was the opportunity to present my view and ideas \non the problems that i had identified and later proposed the solutions for each of the problem.  \nrewarding experience \nthe experience was particularly rewarding when i received affirmation and accolade from the team \non the hypothesis claims, problems statements and approaches that i had proposed in the image \nsuperimposition test. \nchallenging experience \nthe creation of falsified id documents was quite challenging as i had to use some of the python \npackages such as pillow and opencv which were totally new to me. also, this was my first time in \ndealing with image data which is an unstructured data as previously, i was always dealing with \nstructured data. instead of seeing this as a challenge or stumbling block, i treated it as a learning \nopportunity for me to pick up something new and to enhance my current skill. \nupcoming task \nin the next upcoming week, i would be expected to carry out the image superimposition test using \nthe selected cs-flow model and the created datasets. \n26 \n \n9.6 week 6 \ngoals, activities, outcomes \ngoals: by the end of this week, my goal is to find out how well is the performance of the cs-flow \nmodel that was retrained using the created id document datasets. \nactivities: after the creation of datasets, i then retrained the current chosen cs-flow model with our \nnewly created id document dataset. the model was only trained on authentic id document and then \nit was used to test on both authentic and fake id documents. there were certain parameters that \nwould need to be tuned during the training process such as the threshold on anomaly score, the \nclassification condition and the number of point extraction on the border frame used. once i had \nobtained the results, i then carried out analysis and evaluation on the accuracy performance of the \nmodel using some evaluation matrices such as precision and recall. \noutcomes: i had successfully retrained the cs-flow model using the created id document datasets \nand conducted an evaluation and analysis on the results obtained. \nnew knowledge, skills and experiences  \nknowledge: i had learnt about how the fully convolutional cross-scale flow model works while \nretraining the model with the id documents datasets. \nskills: i had developed critical thinking and strong analytical skills when i was required to find ways in \nimproving the performance of the current model by identifying and fine tuning the parameters of \nthe model. \nexperience: i had gained the experience in analysing and evaluating the result obtained from the \nmodel after feeding on the authentic and fake id documents as test datasets. this was my first time \nsolving a real industry problem - developing a fraudulent document detection model and this new \nexperience was extremely memorable and satisfying. \nrewarding experience \nthe experience was particularly rewarding when i managed to increase the accuracy performance of \nthe model after countless attempts in fine-tuning some of the key parameters. both mike and sai \nwere satisfied with the accuracy performance of the model which was as high as 97%. \nchallenging experience \nit was quite challenging during the process of fine-tuning the model as lots of factors need to be \ntaken into consideration. however, through my persevered and persistent countless efforts and \nattempts, i managed to increase the accuracy performance of the model up to an acceptable \nconfidence level. \nupcoming task \nin the next upcoming week, i would be expected to test the model again but this time, with increase \nnumber of test data. also, the cs-flow model would also be extended in testing other classes of id \ndocuments. \n \n \n27 \n \n9.7 week 7 \ngoals, activities, outcomes \ngoals: by the end of this week, my goal is to find out how well would the model perform on a larger \nnumber and also on different subclasses of nsw driver license documents.  \n \nactivities: the number of test data had been increased this time from a total of 78 to 798 nsw \ndriver license document. even though the number of test data had increased, we decided to \nmaintain the number of train data: 30 in total that were being fed into our model as per our \nprevious testing for the purpose of comparison. we wanted to investigate whether our previously \ntrained model which generated a high accuracy performance had been overfitted and whether it \ncould generalise well against a variety of datasets. the difficulty of the classification task had also \nbeen increased as we had introduced different subclasses of nsw driver license as our test data, \nnamely, full, heavy, learner and provisional driver license. the test data that were fed into the model \nis comprised of 399 authentic and also 399 fake documents in which i had replicated using the \noriginal documents.  \n \noutcomes: i had successfully reassessed the model using the increasing number and different \nsubclasses of nsw driver license this time. the accuracy performance of the model this time \ndropped from 97% to around 90%. hence, it is suspected that the model might be underfitted. \nnew knowledge, skills and experiences  \nknowledge: i had learnt about the different factors and considerations that i had to account for \nthroughout the entire data preparation and model fitting process such as the coordinates of face \nimage on the document and the contrast colour of the image background while creating falsified \ndocuments from different subclasses of nsw driver license which would create different level of \nfalsification documents. for instance, the substituted photo which has similar background colour \nwith the original background of the photo would be considered as a high-level type of falsification. \n \nskills: i had developed strong analytical skills when evaluating and comparing the result obtained \nfrom the previous and current test. this was when i was required to utilise my critical thinking and \nproblem-solving skills by identifying the reason behind the drop in the accuracy performance and \ncome out with the next steps and approaches to tackle the problems. \n \nexperience: this was my first time dealing with real-life data: original nsw driver license and solving \nreal-life problem in combating fraudulent identity document. this brand-new experience was \nextremely exciting which motivated me to even put in 100% of my effort into this amazing work. \nrewarding experience \nit was particularly rewarding when i was given the chance to fully express my opinions, evaluation \nand analysis on the results obtained. it was even more satisfying when the proposal that i had \nsuggested to further improve on the current performance of the model had been approved and \napplauded by mike and sai.  \nchallenging experience \nit was quite challenging during the process when i had to create falsified documents with extremely \nhigh precision on various subclasses of nsw driver license. i managed to overcome the problem by \ncreating a clear and well-defined document falsification pipeline which i could apply for all \n28 \n \nsubclasses of documents. mike and sai were pretty satisfied with the pipeline that i had created and \nwanted me to document out the entire falsification process to be set as a standardised and agreed \nsteps which could be used by other team members. \nupcoming task  \nin the next upcoming week, i would be expected to retrain the model by increasing the number of \ntrain datasets and evaluate on its performance. \n \n9.8 week 8 \ngoals, activities, outcomes \ngoals: by the end of this week, my goal is to retrain the model with increase number of train dataset \nand to wrap up the testing that i have done on nsw documents to proceed on with the documents \nfrom other states.  \n \nactivities: this time i had retrained the model with around 323 of authentic documents and tested it \non 100 real and fake nsw driver license documents respectively. i had also volunteered to work on \nwith the internship throughout the two weeks of my mid-semester break with the hope that i would \nbe able to make more progress on my work and to contribute more findings on the result obtained \nfrom my testing. before wrapping up on the work done on nsw documents, i had also tidied up my \ncodes and completed all the required documentations. \n \noutcomes: i had successfully created a strong model in identifying falsified documents after \nretraining the cs-flow model with our own documents. the model managed to generate an \nextremely high accuracy performance – 100% in detecting fraudulent nsw driver license and hence, \nwe had all agreed to wrap up the work done on nsw document and proceed on with other states \ndocuments. \nnew knowledge, skills and experiences  \nknowledge: i had utilised the two-weeks break to do some research and study on different type of \nevaluation methods in a binary classification problem so that i could apply it in evaluating and \nanalysing the result obtained from the identification of anomalous nsw driver license.  \n \nskills: i had developed a good time management skill whereby i had a good allocation of my time in \ncatching up with my study load, working on with the internship and also some leisure time for \nmyself when i had decided to work during my mid-semester break. \n \nexperience: i had a full sense of satisfaction after making lots of progress on the model testing while \nspending more time to continue working on the internship during my break. also, i felt that my time \nwas totally well-spent as not only had i contributed some amazing results to the company, i had also \ngained lots of knowledge and experience.  \nrewarding experience \nit was particularly rewarding when i managed to produce an accuracy performance of 100% after \nretraining and fine-tuning the model multiple times. i had also received recognition and affirmation \nfrom both mike and sai on the work i had done for producing such a high accuracy model for the \nnsw documents. \n29 \n \nchallenging experience \nit was quite challenging during the process of fine-tuning the model to obtain the best result as \nthere were a lot of parameters involved. however, i managed to overcome this by consulting sai and \ndoing some in-depth research on different types of threshold selection and evaluation methods. \nupcoming task  \nin the next upcoming week, i would be expected to work on the victoria documents by carrying out \nthe same set of procedures that i had done on nsw documents. \n \n9.9 week 9 \ngoals, activities, outcomes \ngoals: by the end of this week, my goal is to apply the same cs-flow model that i had used for the \nnsw documents testing to the victoria driver license documents and evaluate on the performance \nresult. \n \nactivities: i had created two models for the victoria documents. the first one was trained on 209 \nauthentic victoria driver license documents and tested on 100 authentic and fake documents \nrespectively. i then decided to create the second model whereby this time the model would be \ntrained by both nsw and victoria documents and tested on the victoria documents. with the \nassumption that an increase in the number of train datasets would lead to a better result, i expect \nmodel 2 would perform better than model 1. \n \noutcomes: i had successfully trained the model with the victoria driver license comprising of \ndifferent subclasses such as full, heavy, provisional and learner and performed an analysis on the \nresult obtained. there was a drop in the accuracy performance on victoria documents compared to \nnsw documents. my initial assumption had also been proven wrong as model 1 performed better \nthan model 2. \nnew knowledge, skills and experiences  \nknowledge: i had learnt from both mike and sai in making some assumptions on the model before \ncarrying out the testing in order to be able to set and define some conditions and parameters \nbeforehand.  \n \nskills: i had developed problem solving and analytical skills while doing some investigation on the \nvictoria documents after receiving a slightly low accuracy performance compared to the nsw \nmodel. \n \nexperience: it was quite a fun experience while investigating the factors that potentially contribute \nto the slightly low accuracy performance of the victoria model compared to nsw. sai and i worked \ntogether attempting to identify any unusual characteristics in the extracted images on victoria \ndocuments that were being fed into the model.  \nrewarding experience \nit was particularly rewarding while conducting an analysis and investigation behind the drop in the \nmodel accuracy performance. it made me realised that as a data scientist, our job is not only to \n30 \n \nproduce the results as requested but also to identify the factors behind the poor accuracy \nperformance and to propose solutions to make further refinements on the model. \nchallenging experience \nit was quite challenging and a bit disappointing when i was not able to produce an accuracy result as \nhigh as 100% this time as what i had obtained for the nsw documents. hence, i had proposed a \ndifferent method in identifying the best threshold that would be able to create a balance between \nfalse negative and false positive error. by using the new method, i managed to increase the accuracy \nresult to an acceptable level which is around 95%. \nupcoming task  \nin the next upcoming week, i would be expected to further extend the model on documents from \nqueensland by applying the same set of procedures that i had done earlier on. \n \n9.10 week 10 \ngoals, activities, outcomes \ngoals: by the end of this week, my goal is to apply the same model and the same set of procedures \nthat had been conducted on the nsw and vic documents to qld driver license documents this time. \nalso, i am also expected to implement the newly introduced multiple thresholds evaluation on the \nmodel. \n \nactivities: as usual, i had divided the qld driver license documents in the proportion of 70/30 into \ntrain and test data. the qld driver license is comprised of three subclasses which are full driver \nlicense with the caption of drive safely and card number and also heavy driver license type. \nthe train and test data for each qld driver license subclasses are extracted in such a way that they \nwould fully represent the total sample population of our sample documents. i then proceeded on \nwith the data preparation process such as transformation, cropping, identification of coordinates, \nclassification of document subclasses, image falsification and lastly point of extraction before \ntraining the model with the prepared documents. after the model was trained, i then fed the test \ndata into the model and started to carry out with the classification and evaluation process. \n \noutcomes: i had successfully created and implemented the multiple thresholds evaluation method \nwhich had boosted up the accuracy performance of the qld model by folds. besides the factors on \nclassification condition, anomaly threshold value and number of point extraction, i had also \nintroduced another factor which is the confidence level which could be adjusted according to our \nclient’s requirement and standard. \nnew knowledge, skills and experiences  \nknowledge: i had learnt a new way of identifying the optimal threshold based on the pre-set \nconfidence level and in evaluating the model using multiple thresholds method which had \nsignificantly increased the accuracy performance of the model. \n \nskills: i had developed problem-solving and analytical skills while doing some investigation on the \ndocuments that had been wrongly classified. it was quite rewarding to get some valuable inputs and \ninsights after comparing the misclassified documents with others that had been correctly classified. \n \n31 \n \nexperience: it was quite an exciting experience as this was my first time having an interaction with \nother colleagues outside of my team when i had several consultations with them to learn about the \nmodels that they had been developing. i therefore grabbed this opportunity to learn more about \nwhat they were doing in other team and asked for the sharing of their experiences. \nrewarding experience \nit was particularly rewarding when i managed to increase the accuracy performance of the qld \nmodel after introducing the multiple thresholds evaluation method which would generate three \nlabels which are the real, fake and warning at the end of the classification. i also went beyond what \nwas requested by presenting and analysing the trade-offs we might face between the accuracy \nperformance and the number of documents being labelled as warning and hence was applauded by \nthe team. \nchallenging experience \nit was quite challenging to first come out with the multiple thresholds evaluation and implement it in \nthe qld model as there were a lot of factors and trade-offs which would need to be taken into \nconsideration. however, i managed to overcome the challenge by treating it as a learning \nopportunity and constantly improving my skills and knowledge by doing lots of research and \nreadings. when in doubt, i also reached out and consulted the people not only in my team but also \nother colleagues from other team as well. \nupcoming task  \nin the next upcoming week, i would be expected to extend the same logic and method and applying \nthe multiple thresholds evaluation on western australia driver license and make comparison to the \nresult. \n \n9.11 week 11 \ngoals, activities, outcomes \ngoals: by the end of this week, my aim is to finish the testing on western australia driver license \ndocuments by applying the same falsification, extraction and evaluation methods which were \napplied on the nsw, vic and qld documents. i have also set a target for this week to improve on \nautomating the entire testing procedures which i have been doing constantly while conducting the \ntest on different states.  \n \nactivities:  \ni had applied the same standardised processing on western australia (wa) driver license documents \nduring data preparation before training the anomaly detection model. the wa driver license is \ncomprised of two subclasses, namely the full driver license and heavy driver license. i then carried \nout evaluation on the result obtained using the multiple thresholds method by selecting the two \nbest thresholds that would give us the lowest false positive and false negative rate respectively.  \n \noutcomes: i had successfully created, trained and evaluated the wa model and made comparison \nwith the qld model. also, i had successfully created a standardised automated data pipeline which \ncould be applied across all types of documents from different states. \n \n32 \n \nnew knowledge, skills and experiences  \nknowledge: i had learnt to create a comprehensive and standardised data pipeline process which \nwould be able to automate the entire data preparation and pre-processing workflow while building \nan anomaly detection model in detecting falsified documents. this had also taught me on the \nimportance of creating a complete automated data pipeline. \n \nskills: i had specifically developed and strengthen my programming skills in python when i was \ncreating the standardised data pipeline which could be applied to all the documents regardless of \nthe states and subclasses. as a result, all the manual work had been replaced with automated \nworkflow and this had significantly increased the efficiency and productivity of my work. \n \nexperience: it was quite an exciting experience during the creation of the entire data pipeline \nprocess from scratch without any assistance and i had gained so much in doing so which significantly \nenhanced my skills in python programming while automating the entire process.  \nrewarding experience \nthe most rewarding experience i had gained in this week is when i managed to create and automate \nthe data pipeline process which then increased the efficiency and productivity of my work. initially, it \ntook me around one day to carry out data pre-processing and another day to train and evaluate on \nthe model. however, after creating the data pipeline, i managed to do all the above work mentioned \nwithin one day. as a result, i could spend more time in evaluating and improving the model. \nchallenging experience \nthis was my first time creating a standardised data pipeline to automate the entire data workflow \nwhich at first, sounded challenging and quite intimidating to me. however, i managed to overcome \nthe challenges by having a positive can-do mindset and also doing lots of research independently \nwhenever i had doubts and queries in mind. \nupcoming task  \nin the next upcoming week, i would be expected to carry out testing towards all the remaining states \nin one go since i have now created a data pipeline to automatically process all the documents \nwithout having the need for me to do all the manual work. \n \n9.12 week 12 \ngoals, activities, outcomes \ngoals: by the end of this week, my aim is to finish the testing on all the remaining documents which \ninclude several australian states such as south australia (sa), northern territory (nt), australian \ncapital territory (act) and tasmania (tas) plus documents from other countries such as new \nzealand, indonesia, philippines and united kingdom. since these are the last batch of the \ndocuments, i also aim to summarise all the models that i had created previously on other australian \nstates and make a side-by-side comparisons between the accuracy performance of those models. \n  \nactivities: i applied the data processing pipeline which i had fully developed previously on all of the \nremaining documents. however, due to the limited number of dataset samples for those \ndocuments, i then decided to combine all these documents into one dataset to be fed into the \nmodel as i would not want the small number of datasets to affect the performance of the model. \n33 \n \nthe multiple thresholds evaluation was then being applied to identify the two most ideal thresholds \nin generating the lowest fnr and fpr. i also presented a summary review on the performance of all \nthe models i had developed to my team. it was discovered that the nsw model was so far our best \nmodel.  \n \noutcomes: i had successfully created, trained and evaluated the model on all the documents for the \nremaining states and countries we had in hand. also, i then summarised the results and \nperformance of all the model i had developed and presented them back to mike and sai in order to \ngive them a higher overview of the accuracy performance on all the models i had built so far.   \nnew knowledge, skills and experiences  \nknowledge: i had come to my realisation on the importance of creating a systematic and automated \ndata workflow pipeline. all thanks to the pipeline that i had built, i could now spend more time in \nassessing and evaluating the result and the overall accuracy performance of the model. \n  \nskills: i had specifically developed my critical thinking skills when i did a summary review session by \ncomparing the performance of all the models i had built throughout the course of my internship. \nwhen it was discovered that nsw model was the best modal so far, i was able to do some in-depth \ninvestigation and comparison between nsw documents with the datasets from other regions. i then \ncame out with some hypothesis based on the inference drawn upon by my investigation. \n \nexperience: it was an exciting experience for me while comparing all the models i had built earlier on \nside by-side and based on that, drawing some new inferences, conclusions and generating some new \nhypothesis that could potentially be tested in the next step \nrewarding experience \nthe most rewarding experience i had gained in this week was when i managed to conduct testing on \nnine different document types and completed all the evaluation work on the model’s performance \njust within one day. this was a significant improvement and breakthrough for me as earlier on, it \ntook me one day to process the dataset that only came from one document type, and another day in \ntraining and evaluating the model. however, all thanks to the automation that i had constantly been \nimproving and also the data pipeline which i had built, i had managed to perform testing on multiple \ntype of documents and evaluate on the model’s accuracy performance just within one day. \nfurthermore, it was also extremely satisfying while presenting the summary overview of all the \nmodels i had created as it represented all the hard-work i had put in throughout my internship \ntenure. \nchallenging experience \nat first, it sounded extremely intimidating to complete the training on all the documents coming \nfrom nine different regions plus completing the evaluation on the model’s accuracy performance \njust within a day. this target was actually not requested by mike or sai but instead was being set by \nmyself as i wanted to challenge and prove to myself that the hours long of spending in automating \nthe workflow process and building a data pipeline would be totally worth it and it was the time for \nme to reap what i had sowed. indeed, i had proven myself right! \n \n \n34 \n \nupcoming task  \nin the next upcoming week, i would be invited to a session that would be discussing on the plan i \nhave in mind during the semester break and also the upcoming six months as the company would \nlike to offer me a part-time contract to continue on working with them. \n \n9.13 summary of weekly activities and achievements \nweek \nactivities \n1 \nfinalised and completed truuth’s onboarding process. \n2 \ncompleted training and being introduced to the tools, technologies and platforms used in \nthe company. \n3 \nbeing officially assigned to the document classification and authentication workstream. \nidentified a specific workstream – image superimposition test to work in. \n4 \nchose cs-flow which is an anomaly detection model to carry out image superimposition \ntest. \n5 \ncreated a pipeline in creating falsified documents. \n6 \ntested the model on nsw driver license documents. \n7 \nextended the model on increased number of nsw driver license documents with different \nsubclasses. \n8 \ncontinued fine-tuning the nsw model until reaching 100% accuracy \n9 \ntested the model on vic driver license documents and the combination of nsw and vic \ndocuments.  \n10 \ntested the model on qld driver license documents and introduced multiple thresholds \nevaluation. \n11 \ntested the model on wa driver license document and created an automated data \nprocessing pipeline. \n12 \ntested the model on the combination of sa, act, tas, nt, indonesia, philippines and uk \ndriver license documents. \n13 \ndiscussed on plans and future working opportunity with the company. \n \ntable 2: summary of 13-week activities and achievements \n \n \n \n \n \n \n \n \n \n",
    "page": null,
    "goal": "Reflective journal Entities",
    "children": [
        {
            "id": "1.1",
            "name": "week 1",
            "nodeType": "title",
            "text": "week 1",
            "page": null,
            "goal": "week 1",
            "children": []
        },
        {
            "id": "1.2",
            "name": "week 1 goals,",
            "nodeType": "paragraph",
            "text": "week 1 \ngoals, activities, outcomes \ngoals: my goals for week 1 is to finalise the company that will be sponsoring me for my internship \nprogram, complete all the onboarding process and get to know more about the company. \nactivities: i had done lots of researches on the companies which i was intending to apply and \ncontacted the company to express my interest in joining their internship program. after receiving \nresponse from truuth, i was invited for the first round of interview with sai, who would potentially \nbe my team leader if i were admitted into the program. i passed the first round of interview by \nrelating my previous experiences with the current project - document authentication which i hope i \nwould be given the opportunity to be involved in. i was then invited to the second round of \ninterview whereby i had to present on a given topic – document authentication by doing some \nresearches and reading through some academic papers. after acing both interviews, i was then \ninvited to have a virtual meet-up with nick who is the co-founder of truuth to discuss about the \nonboarding process. i then started to prepare the internship proposal and fill up the mq internship \nform before sending those back to the company to ask for their review and signature.  \noutcomes: i had successfully been admitted into truuth internship program after completing all the \nonboarding process and sending back all the required documents to the unit convener for further \nreview and assessment. after doing researches on the company, i also had a better overview \nunderstanding on the background, visions and goals that truuth is trying to achieve as an \norganisation. \nnew knowledge, skills and experiences \nknowledge: i gained some knowledge on different types of identity falsification method and \ntechniques to overcome each of them after doing some researches on document authentication. in \naddition, i also had a better understanding towards the company’s background, competitors, \nmarkets and customers. \nskills: i had developed researching skills while doing some researches on the assigned topic. i have \nalso developed communication skills while interacting with the company back and forth. \nexperience: i gained some interview experience after going through multiple rounds of interview \nwith truuth. i also had the opportunity to get an overview on the real projects, problems and \nchallenges currently faced by the corporate world. \nrewarding experience \nthe interview experience was particularly rewarding as i managed to enhance my interviewing skills \nand learnt to be more confident with myself. also, it was a good reflection on myself to assess \nwhether my previous experiences and my current knowledge were sufficient to prepare me for \nemployment. \ndifficult experience \nthe topic on identity falsification techniques and methods in fraudulent documents detection were \nrelatively new to me as i was not from a cybersecurity background had never been in touch with this \ntopic before. however, i managed to overcome the challenge by spending a few hours each day to \n21 \n \ncarry out in-depth research and review lots of academic papers to brush up my knowledge in this \nfield. i was really glad that my efforts paid off when i received accolade from my team leader, sai on \nthe writeup that i had voluntarily done to summarise on the document falsification research topic. \nupcoming task \nthe task assigned to me for the upcoming week is to complete the required training and onboarding \nprocedures and also start to get myself familiar with the products and services offered in truuth. \n \n9.2",
            "page": null,
            "goal": "week 1 \ngoals, activities, outcomes \ngoals: my goals for week 1 is to finalise the company that will be sponsoring me for my internship \nprogram, complete all the onboarding process and get to know more about the company. \nactivities: i had done lots of researches on the companies which i was intending to apply and \ncontacted the company to express my interest in joining their internship program. after receiving \nresponse from truuth, i was invited for the first round of interview with sai, who would potentially \nbe my team leader if i were admitted into the program. i passed the first round of interview by \nrelating my previous experiences with the current project - document authentication which i hope i \nwould be given the opportunity to be involved in. i was then invited to the second round of \ninterview whereby i had to present on a given topic – document authentication by doing some \nresearches and reading through some academic papers. after acing both interviews, i was then \ninvited to have a virtual meet-up with nick who is the co-founder of truuth to discuss about the \nonboarding process. i then started to prepare the internship proposal and fill up the mq internship \nform before sending those back to the company to ask for their review and signature.  \noutcomes: i had successfully been admitted into truuth internship program after completing all the \nonboarding process and sending back all the required documents to the unit convener for further \nreview and assessment. after doing researches on the company, i also had a better overview \nunderstanding on the background, visions and goals that truuth is trying to achieve as an \norganisation. \nnew knowledge, skills and experiences \nknowledge: i gained some knowledge on different types of identity falsification method and \ntechniques to overcome each of them after doing some researches on document authentication. in \naddition, i also had a better understanding towards the company’s background, competitors, \nmarkets and customers. \nskills: i had developed researching skills while doing some researches on the assigned topic. i have \nalso developed communication skills while interacting with the company back and forth. \nexperience: i gained some interview experience after going through multiple rounds of interview \nwith truuth. i also had the opportunity to get an overview on the real projects, problems and \nchallenges currently faced by the corporate world. \nrewarding experience \nthe interview experience was particularly rewarding as i managed to enhance my interviewing skills \nand learnt to be more confident with myself. also, it was a good reflection on myself to assess \nwhether my previous experiences and my current knowledge were sufficient to prepare me for \nemployment. \ndifficult experience \nthe topic on identity falsification techniques and methods in fraudulent documents detection were \nrelatively new to me as i was not from a cybersecurity background had never been in touch with this \ntopic before. however, i managed to overcome the challenge by spending a few hours each day to \n21 \n \ncarry out in-depth research and review lots of academic papers to brush up my knowledge in this \nfield. i was really glad that my efforts paid off when i received accolade from my team leader, sai on \nthe writeup that i had voluntarily done to summarise on the document falsification research topic. \nupcoming task \nthe task assigned to me for the upcoming week is to complete the required training and onboarding \nprocedures and also start to get myself familiar with the products and services offered in truuth. \n \n9.2",
            "children": []
        },
        {
            "id": "1.3",
            "name": "week 2",
            "nodeType": "title",
            "text": "week 2",
            "page": null,
            "goal": "week 2",
            "children": []
        },
        {
            "id": "1.4",
            "name": "week 2 goals,",
            "nodeType": "paragraph",
            "text": "week 2 \ngoals, activities, outcomes \ngoals: to complete the required training and onboarding procedures with truuth and have a better \nunderstanding towards the company in terms of the products offered, tools, technology and \nplatforms used at the end of the week. \nactivities: the first thing i had done early of this week is to complete my training and some leftover \nonboarding process. one of my first steps in onboarding was to provide my identity documents for \nverification which could be done via truuth id submission. the truuth id is a product developed by \nthe company itself in carrying out identity document verification. that was a great opportunity for \nme to have a user experience on the product and have a better understanding towards the products \ndeveloped by the company. furthermore, part of the onboarding training process was to undergo \nthe security and awareness training as part of the company’s information security management \nsystem policy. also, i was required to encrypt and install anti-virus on my device as a form of \nprotection towards the company’s confidentiality. the last step of the onboarding process was to get \nmyself familiar with the company’s policies which all the employees should abide by strictly. \nthroughout the week, i was also being introduced on the tools, technologies and platforms used by \nthe company and the products and solution offered by the comapny such as truuth’s kyc, identity, \nbiopass, verify, liveness and facekey. \noutcomes: i had successfully completed all the onboarding process and gotten myself familiarised \naround with different types of tools and technology platforms such as the microsoft teams, \nconfluence and aws platform that i would be actively using throughout my internship program. \nafter completing the security and awareness training, i had also gained some knowledge in \ncybersecurity protection and the standard procedures to comply with in a company during the event \nof cyberattack.  \nnew knowledge, skills and experiences \nknowledge: while completing the security and awareness training, i realised the importance of \nemployees in having some basic fundamental knowledge in the cybersecurity space no matter which \nindustry they are in to prevent any forms of cyberattack such as ransomware, supply chain attacks, \nsocial engineering, business email compromise, watering hole and others. also, i had a better \nunderstanding on how the products and solutions from truuth work and the target customers for \neach of the product. \nskills: throughout the week, i had developed self-learning and problem-solving skills by learning to \novercome and solve challenges independently without being overly reliant and dependent on \nothers. \n22 \n \nexperience: the valuable experience i had gained this week is the opportunity to get to know the \npeople in my team. they are all extremely friendly and helpful in assisting me to get familiar around \nthe work the team was currently working on. \nrewarding experience  \nit was particularly rewarding to be exposed to different types of tools and technology platforms \nbeing used in the company. i was extremely fortunate to have the chance to learn and get my hands \non the confluence platform developed by atlassian which is actively being used in the company to \ncapture project requirements, assign tasks, manage multiple projects simultaneously and most \nimportantly, to collaborate with one another. this made me realised that being a data scientist in \nthe real corporate world, it is not just all about being proficient in technical skills. it is also extremely \nvital to have the skills such as communication, teamwork and collaboration especially while working \nwith a team to complete a project. \nchallenging experience \nthere were quite a lot of tools, technologies and platforms used by the company which i had never \ncome across before especially on the aws platform. it was a bit of a challenge at the start for me. \nhowever, i managed to get myself to explore around and be familiarised with the tools and \nplatforms at the end of the week by seeking guidance from my team members proactively. this \nvaluable experience had taught me that there will unavoidably be some challenges when i first \nstepped into a new space or domain but i believe that with the right learning skills, mentality and \nattitude, there is nothing that could stop me from achieving my goal.  \nupcoming task \nin the next upcoming week, i would be expected to go through an official knowledge transfer session \nafter i have been assigned to a team and a particular project work stream that i will be working on \nthroughout my internship program. i would also be expected to be familiar around the problems \nthat our team is trying to solve and come out with ideas and recommendations on how to approach \nthe problems. \n \n9.3",
            "page": null,
            "goal": "week 2 \ngoals, activities, outcomes \ngoals: to complete the required training and onboarding procedures with truuth and have a better \nunderstanding towards the company in terms of the products offered, tools, technology and \nplatforms used at the end of the week. \nactivities: the first thing i had done early of this week is to complete my training and some leftover \nonboarding process. one of my first steps in onboarding was to provide my identity documents for \nverification which could be done via truuth id submission. the truuth id is a product developed by \nthe company itself in carrying out identity document verification. that was a great opportunity for \nme to have a user experience on the product and have a better understanding towards the products \ndeveloped by the company. furthermore, part of the onboarding training process was to undergo \nthe security and awareness training as part of the company’s information security management \nsystem policy. also, i was required to encrypt and install anti-virus on my device as a form of \nprotection towards the company’s confidentiality. the last step of the onboarding process was to get \nmyself familiar with the company’s policies which all the employees should abide by strictly. \nthroughout the week, i was also being introduced on the tools, technologies and platforms used by \nthe company and the products and solution offered by the comapny such as truuth’s kyc, identity, \nbiopass, verify, liveness and facekey. \noutcomes: i had successfully completed all the onboarding process and gotten myself familiarised \naround with different types of tools and technology platforms such as the microsoft teams, \nconfluence and aws platform that i would be actively using throughout my internship program. \nafter completing the security and awareness training, i had also gained some knowledge in \ncybersecurity protection and the standard procedures to comply with in a company during the event \nof cyberattack.  \nnew knowledge, skills and experiences \nknowledge: while completing the security and awareness training, i realised the importance of \nemployees in having some basic fundamental knowledge in the cybersecurity space no matter which \nindustry they are in to prevent any forms of cyberattack such as ransomware, supply chain attacks, \nsocial engineering, business email compromise, watering hole and others. also, i had a better \nunderstanding on how the products and solutions from truuth work and the target customers for \neach of the product. \nskills: throughout the week, i had developed self-learning and problem-solving skills by learning to \novercome and solve challenges independently without being overly reliant and dependent on \nothers. \n22 \n \nexperience: the valuable experience i had gained this week is the opportunity to get to know the \npeople in my team. they are all extremely friendly and helpful in assisting me to get familiar around \nthe work the team was currently working on. \nrewarding experience  \nit was particularly rewarding to be exposed to different types of tools and technology platforms \nbeing used in the company. i was extremely fortunate to have the chance to learn and get my hands \non the confluence platform developed by atlassian which is actively being used in the company to \ncapture project requirements, assign tasks, manage multiple projects simultaneously and most \nimportantly, to collaborate with one another. this made me realised that being a data scientist in \nthe real corporate world, it is not just all about being proficient in technical skills. it is also extremely \nvital to have the skills such as communication, teamwork and collaboration especially while working \nwith a team to complete a project. \nchallenging experience \nthere were quite a lot of tools, technologies and platforms used by the company which i had never \ncome across before especially on the aws platform. it was a bit of a challenge at the start for me. \nhowever, i managed to get myself to explore around and be familiarised with the tools and \nplatforms at the end of the week by seeking guidance from my team members proactively. this \nvaluable experience had taught me that there will unavoidably be some challenges when i first \nstepped into a new space or domain but i believe that with the right learning skills, mentality and \nattitude, there is nothing that could stop me from achieving my goal.  \nupcoming task \nin the next upcoming week, i would be expected to go through an official knowledge transfer session \nafter i have been assigned to a team and a particular project work stream that i will be working on \nthroughout my internship program. i would also be expected to be familiar around the problems \nthat our team is trying to solve and come out with ideas and recommendations on how to approach \nthe problems. \n \n9.3",
            "children": []
        },
        {
            "id": "1.5",
            "name": "week 3",
            "nodeType": "title",
            "text": "week 3",
            "page": null,
            "goal": "week 3",
            "children": []
        },
        {
            "id": "1.6",
            "name": "week 3 goals,",
            "nodeType": "paragraph",
            "text": "week 3 \ngoals, activities, outcomes \ngoals: by the end of this week, i would be expected to have a great understanding on the problems \nor issues in my selected work stream and come out with some approaches and solutions to address \neach of the identified issue in the next coming step. \nactivities: early of this week, i was officially assigned to be in the document classification and \nauthentication team. i was being briefed on the problems statements and the objectives that the \nteam were aiming to achieve. after discussion, it was decided that i would be in-charge of the image \nsuperimposition test domain. it would involve carrying out authenticity and verification check on \nthe photo in the identity documents. the main proposed method in tackling the issue was by \nutilising the anomaly detection model to detect any signs of outliers in the photo region. this area of \nwork was initially started by an ex-staff member in truuth. after some arrangements, the knowledge \ntransfer process was conducted, whereby all the materials and previous in-progress work and codes \nwere being passed down to me. hence, i had been going through all the materials that are being \n23 \n \nhanded over to me. in addition, i also spent some time to review various research papers on \nanomaly detection and the effectiveness of it when being applied on image superimposition test. i \nhad also attended my first daily and weekly stand-up session with my team members whereby we \nhad a productive discussion on various ways and techniques to increase the accuracy of features \nextraction being applied on identity documents from different states and countries. \noutcomes: i had successfully gotten myself to be familiar around the work, projects and particularly \nthe problems in document authentication that my team were currently working on. after this week, \ni also had a clear direction on the goal and objective that i am trying to achieve. in addition, i had \nalso done enough research in the area of document authentication and image superimposition test \nto prepare myself in embracing the upcoming work. \nnew knowledge, skills and experiences  \nknowledge: i learnt about the major problems and obstacles in classifying and verifying id \ndocuments. various aspects and dimensions would have to be taken into consideration during the \nworkflow and image superimposition test plays and important role in the document authentication \nprocess \nskills: i had developed researching skills while carrying out in-depth research on image \nsuperimposition test and anomaly detection models. i had also developed communication and \npresentation skills while presenting the findings i had discovered during my research and \ncontributing ideas and insights during the meeting. \nexperience: the valuable experience i had gained was the opportunity to be involved in solving the \nreal-world problems and realised the huge impacts and consequences brought upon by fake id \ndocuments which could easily be done through photo substitution and tampering. this would \neventually lead to identity theft and fraud whereby various type of fraudulent documents would be \ncirculating in the market. \nrewarding experience \ni was extremely happy when i was finally assigned to work on a particular stream that i was very \ninterested in. it was also very rewarding to get to know my team members and understand the \nscope and type of work they were focusing on. i was also extremely grateful to be able to receive \ndirect guidance and mentor from the co-founder of truuth, mike and also my team leader, sai \nduring the daily stand-up and weekly meeting. \nchallenging experience \nit was a bit hard initially to get an understanding and overview on the work passed down by the ex-\ncolleague due to the lack of documentation on the previous work done. however, i managed to \novercome the challenge by consulting my team leader, sai for further clarifications and verifications \non the doubt i had in mind.  \nupcoming task \nin the next upcoming week, my goal is to start diving into the actual work by identifying and \nchoosing the best anomaly detection model to be used in the image superimposition test. \n \n \n24 \n \n9.4",
            "page": null,
            "goal": "week 3 \ngoals, activities, outcomes \ngoals: by the end of this week, i would be expected to have a great understanding on the problems \nor issues in my selected work stream and come out with some approaches and solutions to address \neach of the identified issue in the next coming step. \nactivities: early of this week, i was officially assigned to be in the document classification and \nauthentication team. i was being briefed on the problems statements and the objectives that the \nteam were aiming to achieve. after discussion, it was decided that i would be in-charge of the image \nsuperimposition test domain. it would involve carrying out authenticity and verification check on \nthe photo in the identity documents. the main proposed method in tackling the issue was by \nutilising the anomaly detection model to detect any signs of outliers in the photo region. this area of \nwork was initially started by an ex-staff member in truuth. after some arrangements, the knowledge \ntransfer process was conducted, whereby all the materials and previous in-progress work and codes \nwere being passed down to me. hence, i had been going through all the materials that are being \n23 \n \nhanded over to me. in addition, i also spent some time to review various research papers on \nanomaly detection and the effectiveness of it when being applied on image superimposition test. i \nhad also attended my first daily and weekly stand-up session with my team members whereby we \nhad a productive discussion on various ways and techniques to increase the accuracy of features \nextraction being applied on identity documents from different states and countries. \noutcomes: i had successfully gotten myself to be familiar around the work, projects and particularly \nthe problems in document authentication that my team were currently working on. after this week, \ni also had a clear direction on the goal and objective that i am trying to achieve. in addition, i had \nalso done enough research in the area of document authentication and image superimposition test \nto prepare myself in embracing the upcoming work. \nnew knowledge, skills and experiences  \nknowledge: i learnt about the major problems and obstacles in classifying and verifying id \ndocuments. various aspects and dimensions would have to be taken into consideration during the \nworkflow and image superimposition test plays and important role in the document authentication \nprocess \nskills: i had developed researching skills while carrying out in-depth research on image \nsuperimposition test and anomaly detection models. i had also developed communication and \npresentation skills while presenting the findings i had discovered during my research and \ncontributing ideas and insights during the meeting. \nexperience: the valuable experience i had gained was the opportunity to be involved in solving the \nreal-world problems and realised the huge impacts and consequences brought upon by fake id \ndocuments which could easily be done through photo substitution and tampering. this would \neventually lead to identity theft and fraud whereby various type of fraudulent documents would be \ncirculating in the market. \nrewarding experience \ni was extremely happy when i was finally assigned to work on a particular stream that i was very \ninterested in. it was also very rewarding to get to know my team members and understand the \nscope and type of work they were focusing on. i was also extremely grateful to be able to receive \ndirect guidance and mentor from the co-founder of truuth, mike and also my team leader, sai \nduring the daily stand-up and weekly meeting. \nchallenging experience \nit was a bit hard initially to get an understanding and overview on the work passed down by the ex-\ncolleague due to the lack of documentation on the previous work done. however, i managed to \novercome the challenge by consulting my team leader, sai for further clarifications and verifications \non the doubt i had in mind.  \nupcoming task \nin the next upcoming week, my goal is to start diving into the actual work by identifying and \nchoosing the best anomaly detection model to be used in the image superimposition test. \n \n \n24 \n \n9.4",
            "children": []
        },
        {
            "id": "1.7",
            "name": "week 4",
            "nodeType": "title",
            "text": "week 4",
            "page": null,
            "goal": "week 4",
            "children": []
        },
        {
            "id": "1.8",
            "name": "week 4 goals,",
            "nodeType": "paragraph",
            "text": "week 4 \ngoals, activities, outcomes \ngoals: by the end of this week, i would be expected to choose the most ideal anomaly detection \nmodel to carry out the image superimposition test.  \nactivities: after doing some research on different types of anomaly detection models, i had chosen \nthe fully convolutional cross-scale-flows (cs-flow) model on image-based defect detection. after \nobtaining approval and support from mike and sai, i then proceeded to extract the codes which was \nprovided by the author of the cs-flow model research paper in github. i learnt from both mike and \nsai that before deciding to adopt a model from the research paper, we had to first replicate the \nresult by executing the codes provided by the author to verify on the model performance as \npublished in the paper. after going through the process, it was discovered that the actual result \nobtained was slightly below the reported result. however, since the overall performance of the \nmodel was still acceptable and decent, we had made the decision to proceed on with our image \nsuperimposition test by adopting the cs-flow model. \noutcomes: i had successfully chosen an ideal anomaly detection model to conduct the image \nsuperimposition test. also, i had managed to replicate the code provided by the author to verify on \nthe reported performance result to ensure the validity and reliability of the cs-flow model. \nnew knowledge, skills and experiences  \nknowledge: i had learnt something new that anomaly detection is an effective model in identifying \nsigns of photo substitution in an id document through the detection of unaligned photo frames, \nedges and boundaries. the other model that i had explored was the copy-paste detection technique \nwhereby the algorithm has the ability to identify signs of copy pasting in tampering the id document. \nskills: i had developed researching skills while carrying out in-depth research on various anomaly \ndetection models. i also learnt to be confident in expressing my thoughts and perspectives while \ncontributing ideas and insights during the meeting. \nexperience: the valuable experience i had gained is the opportunity to present my view points and \nshare some ideas on the ways we could approach the problem. it was really great to hear some \nprecious feedbacks and affirmation from my team members especially from mike and sai. \nrewarding experience \nthe experience that was particularly rewarding was when i had the chance to work together and had \nlots of productive brainstorming and discussion sessions with my team members. it definitely \nopened my eyes on the different approaches that i should make while tackling various kinds of \nproblem. the discussion was very productive as it allowed me to look at the issues differently from \nanother perspective. \nchallenging experience \nit was quite daunting when i was required to find an anomaly detection model to apply on the image \nsuperimposition test. however, i realised that all my previous research work done had finally paid \noff as i now had a deep understanding on various kind of anomaly detection models. with the advice \nand pointers from mike and sai, i managed to shortlist the top three models and finally select the \nbest model, cs-flow model which was also approved by the team.  \n25 \n \nupcoming task \nin the next upcoming week, i would be expected to create some datasets to be fed into the chosen \ncs-flow model while carrying out the image superimposition test. \n \n9.5",
            "page": null,
            "goal": "week 4 \ngoals, activities, outcomes \ngoals: by the end of this week, i would be expected to choose the most ideal anomaly detection \nmodel to carry out the image superimposition test.  \nactivities: after doing some research on different types of anomaly detection models, i had chosen \nthe fully convolutional cross-scale-flows (cs-flow) model on image-based defect detection. after \nobtaining approval and support from mike and sai, i then proceeded to extract the codes which was \nprovided by the author of the cs-flow model research paper in github. i learnt from both mike and \nsai that before deciding to adopt a model from the research paper, we had to first replicate the \nresult by executing the codes provided by the author to verify on the model performance as \npublished in the paper. after going through the process, it was discovered that the actual result \nobtained was slightly below the reported result. however, since the overall performance of the \nmodel was still acceptable and decent, we had made the decision to proceed on with our image \nsuperimposition test by adopting the cs-flow model. \noutcomes: i had successfully chosen an ideal anomaly detection model to conduct the image \nsuperimposition test. also, i had managed to replicate the code provided by the author to verify on \nthe reported performance result to ensure the validity and reliability of the cs-flow model. \nnew knowledge, skills and experiences  \nknowledge: i had learnt something new that anomaly detection is an effective model in identifying \nsigns of photo substitution in an id document through the detection of unaligned photo frames, \nedges and boundaries. the other model that i had explored was the copy-paste detection technique \nwhereby the algorithm has the ability to identify signs of copy pasting in tampering the id document. \nskills: i had developed researching skills while carrying out in-depth research on various anomaly \ndetection models. i also learnt to be confident in expressing my thoughts and perspectives while \ncontributing ideas and insights during the meeting. \nexperience: the valuable experience i had gained is the opportunity to present my view points and \nshare some ideas on the ways we could approach the problem. it was really great to hear some \nprecious feedbacks and affirmation from my team members especially from mike and sai. \nrewarding experience \nthe experience that was particularly rewarding was when i had the chance to work together and had \nlots of productive brainstorming and discussion sessions with my team members. it definitely \nopened my eyes on the different approaches that i should make while tackling various kinds of \nproblem. the discussion was very productive as it allowed me to look at the issues differently from \nanother perspective. \nchallenging experience \nit was quite daunting when i was required to find an anomaly detection model to apply on the image \nsuperimposition test. however, i realised that all my previous research work done had finally paid \noff as i now had a deep understanding on various kind of anomaly detection models. with the advice \nand pointers from mike and sai, i managed to shortlist the top three models and finally select the \nbest model, cs-flow model which was also approved by the team.  \n25 \n \nupcoming task \nin the next upcoming week, i would be expected to create some datasets to be fed into the chosen \ncs-flow model while carrying out the image superimposition test. \n \n9.5",
            "children": []
        },
        {
            "id": "1.9",
            "name": "week 5",
            "nodeType": "title",
            "text": "week 5",
            "page": null,
            "goal": "week 5",
            "children": []
        },
        {
            "id": "1.10",
            "name": "week 5 goals,",
            "nodeType": "paragraph",
            "text": "week 5 \ngoals, activities, outcomes \ngoals: by the end of this week, i would be expected to create different versions of dataset to be \nused in the image superimposition test. \nactivities: the datasets preparation involved the creation of falsified documents. this could be \nachieved by cropping a portrait image with similar background and pasting it on top of the photo \nregion of a real document. after creating the falsified id documents, i then proceeded in identifying \nthe region of interest (roi) from the id document datasets. after having several discussions with \nmike and sai, we had decided to extract the corners of the border frame as the roi as we were \ninterested to find out whether our anomaly detection model would be able to detect the presence \nof photo substitution via the border frame point of region.  \noutcomes: i had successfully created different types of falsified id documents and identified the \nregion of interest from the datasets that we would be using to test against our chosen model. \nnew knowledge, skills and experiences  \nknowledge: i had learnt different types of approaches and methods that could be used in creating \nfake id documents and had the opportunity to master some of the advanced python packages. \nskills: i had developed problem solving skills from the work that i had done over the week as i was \nrequired to think of the best approach in carrying out document falsification. i also managed to \nbrush up my programming skills throughout the process of creating fake id document datasets. \nexperience: the valuable experience i had gained was the opportunity to present my view and ideas \non the problems that i had identified and later proposed the solutions for each of the problem.  \nrewarding experience \nthe experience was particularly rewarding when i received affirmation and accolade from the team \non the hypothesis claims, problems statements and approaches that i had proposed in the image \nsuperimposition test. \nchallenging experience \nthe creation of falsified id documents was quite challenging as i had to use some of the python \npackages such as pillow and opencv which were totally new to me. also, this was my first time in \ndealing with image data which is an unstructured data as previously, i was always dealing with \nstructured data. instead of seeing this as a challenge or stumbling block, i treated it as a learning \nopportunity for me to pick up something new and to enhance my current skill. \nupcoming task \nin the next upcoming week, i would be expected to carry out the image superimposition test using \nthe selected cs-flow model and the created datasets. \n26 \n \n9.6",
            "page": null,
            "goal": "week 5 \ngoals, activities, outcomes \ngoals: by the end of this week, i would be expected to create different versions of dataset to be \nused in the image superimposition test. \nactivities: the datasets preparation involved the creation of falsified documents. this could be \nachieved by cropping a portrait image with similar background and pasting it on top of the photo \nregion of a real document. after creating the falsified id documents, i then proceeded in identifying \nthe region of interest (roi) from the id document datasets. after having several discussions with \nmike and sai, we had decided to extract the corners of the border frame as the roi as we were \ninterested to find out whether our anomaly detection model would be able to detect the presence \nof photo substitution via the border frame point of region.  \noutcomes: i had successfully created different types of falsified id documents and identified the \nregion of interest from the datasets that we would be using to test against our chosen model. \nnew knowledge, skills and experiences  \nknowledge: i had learnt different types of approaches and methods that could be used in creating \nfake id documents and had the opportunity to master some of the advanced python packages. \nskills: i had developed problem solving skills from the work that i had done over the week as i was \nrequired to think of the best approach in carrying out document falsification. i also managed to \nbrush up my programming skills throughout the process of creating fake id document datasets. \nexperience: the valuable experience i had gained was the opportunity to present my view and ideas \non the problems that i had identified and later proposed the solutions for each of the problem.  \nrewarding experience \nthe experience was particularly rewarding when i received affirmation and accolade from the team \non the hypothesis claims, problems statements and approaches that i had proposed in the image \nsuperimposition test. \nchallenging experience \nthe creation of falsified id documents was quite challenging as i had to use some of the python \npackages such as pillow and opencv which were totally new to me. also, this was my first time in \ndealing with image data which is an unstructured data as previously, i was always dealing with \nstructured data. instead of seeing this as a challenge or stumbling block, i treated it as a learning \nopportunity for me to pick up something new and to enhance my current skill. \nupcoming task \nin the next upcoming week, i would be expected to carry out the image superimposition test using \nthe selected cs-flow model and the created datasets. \n26 \n \n9.6",
            "children": []
        },
        {
            "id": "1.11",
            "name": "week 6",
            "nodeType": "title",
            "text": "week 6",
            "page": null,
            "goal": "week 6",
            "children": []
        },
        {
            "id": "1.12",
            "name": "week 6 goals,",
            "nodeType": "paragraph",
            "text": "week 6 \ngoals, activities, outcomes \ngoals: by the end of this week, my goal is to find out how well is the performance of the cs-flow \nmodel that was retrained using the created id document datasets. \nactivities: after the creation of datasets, i then retrained the current chosen cs-flow model with our \nnewly created id document dataset. the model was only trained on authentic id document and then \nit was used to test on both authentic and fake id documents. there were certain parameters that \nwould need to be tuned during the training process such as the threshold on anomaly score, the \nclassification condition and the number of point extraction on the border frame used. once i had \nobtained the results, i then carried out analysis and evaluation on the accuracy performance of the \nmodel using some evaluation matrices such as precision and recall. \noutcomes: i had successfully retrained the cs-flow model using the created id document datasets \nand conducted an evaluation and analysis on the results obtained. \nnew knowledge, skills and experiences  \nknowledge: i had learnt about how the fully convolutional cross-scale flow model works while \nretraining the model with the id documents datasets. \nskills: i had developed critical thinking and strong analytical skills when i was required to find ways in \nimproving the performance of the current model by identifying and fine tuning the parameters of \nthe model. \nexperience: i had gained the experience in analysing and evaluating the result obtained from the \nmodel after feeding on the authentic and fake id documents as test datasets. this was my first time \nsolving a real industry problem - developing a fraudulent document detection model and this new \nexperience was extremely memorable and satisfying. \nrewarding experience \nthe experience was particularly rewarding when i managed to increase the accuracy performance of \nthe model after countless attempts in fine-tuning some of the key parameters. both mike and sai \nwere satisfied with the accuracy performance of the model which was as high as 97%. \nchallenging experience \nit was quite challenging during the process of fine-tuning the model as lots of factors need to be \ntaken into consideration. however, through my persevered and persistent countless efforts and \nattempts, i managed to increase the accuracy performance of the model up to an acceptable \nconfidence level. \nupcoming task \nin the next upcoming week, i would be expected to test the model again but this time, with increase \nnumber of test data. also, the cs-flow model would also be extended in testing other classes of id \ndocuments. \n \n \n27 \n \n9.7",
            "page": null,
            "goal": "week 6 \ngoals, activities, outcomes \ngoals: by the end of this week, my goal is to find out how well is the performance of the cs-flow \nmodel that was retrained using the created id document datasets. \nactivities: after the creation of datasets, i then retrained the current chosen cs-flow model with our \nnewly created id document dataset. the model was only trained on authentic id document and then \nit was used to test on both authentic and fake id documents. there were certain parameters that \nwould need to be tuned during the training process such as the threshold on anomaly score, the \nclassification condition and the number of point extraction on the border frame used. once i had \nobtained the results, i then carried out analysis and evaluation on the accuracy performance of the \nmodel using some evaluation matrices such as precision and recall. \noutcomes: i had successfully retrained the cs-flow model using the created id document datasets \nand conducted an evaluation and analysis on the results obtained. \nnew knowledge, skills and experiences  \nknowledge: i had learnt about how the fully convolutional cross-scale flow model works while \nretraining the model with the id documents datasets. \nskills: i had developed critical thinking and strong analytical skills when i was required to find ways in \nimproving the performance of the current model by identifying and fine tuning the parameters of \nthe model. \nexperience: i had gained the experience in analysing and evaluating the result obtained from the \nmodel after feeding on the authentic and fake id documents as test datasets. this was my first time \nsolving a real industry problem - developing a fraudulent document detection model and this new \nexperience was extremely memorable and satisfying. \nrewarding experience \nthe experience was particularly rewarding when i managed to increase the accuracy performance of \nthe model after countless attempts in fine-tuning some of the key parameters. both mike and sai \nwere satisfied with the accuracy performance of the model which was as high as 97%. \nchallenging experience \nit was quite challenging during the process of fine-tuning the model as lots of factors need to be \ntaken into consideration. however, through my persevered and persistent countless efforts and \nattempts, i managed to increase the accuracy performance of the model up to an acceptable \nconfidence level. \nupcoming task \nin the next upcoming week, i would be expected to test the model again but this time, with increase \nnumber of test data. also, the cs-flow model would also be extended in testing other classes of id \ndocuments. \n \n \n27 \n \n9.7",
            "children": []
        },
        {
            "id": "1.13",
            "name": "week 7",
            "nodeType": "title",
            "text": "week 7",
            "page": null,
            "goal": "week 7",
            "children": []
        },
        {
            "id": "1.14",
            "name": "week 7 goals,",
            "nodeType": "paragraph",
            "text": "week 7 \ngoals, activities, outcomes \ngoals: by the end of this week, my goal is to find out how well would the model perform on a larger \nnumber and also on different subclasses of nsw driver license documents.  \n \nactivities: the number of test data had been increased this time from a total of 78 to 798 nsw \ndriver license document. even though the number of test data had increased, we decided to \nmaintain the number of train data: 30 in total that were being fed into our model as per our \nprevious testing for the purpose of comparison. we wanted to investigate whether our previously \ntrained model which generated a high accuracy performance had been overfitted and whether it \ncould generalise well against a variety of datasets. the difficulty of the classification task had also \nbeen increased as we had introduced different subclasses of nsw driver license as our test data, \nnamely, full, heavy, learner and provisional driver license. the test data that were fed into the model \nis comprised of 399 authentic and also 399 fake documents in which i had replicated using the \noriginal documents.  \n \noutcomes: i had successfully reassessed the model using the increasing number and different \nsubclasses of nsw driver license this time. the accuracy performance of the model this time \ndropped from 97% to around 90%. hence, it is suspected that the model might be underfitted. \nnew knowledge, skills and experiences  \nknowledge: i had learnt about the different factors and considerations that i had to account for \nthroughout the entire data preparation and model fitting process such as the coordinates of face \nimage on the document and the contrast colour of the image background while creating falsified \ndocuments from different subclasses of nsw driver license which would create different level of \nfalsification documents. for instance, the substituted photo which has similar background colour \nwith the original background of the photo would be considered as a high-level type of falsification. \n \nskills: i had developed strong analytical skills when evaluating and comparing the result obtained \nfrom the previous and current test. this was when i was required to utilise my critical thinking and \nproblem-solving skills by identifying the reason behind the drop in the accuracy performance and \ncome out with the next steps and approaches to tackle the problems. \n \nexperience: this was my first time dealing with real-life data: original nsw driver license and solving \nreal-life problem in combating fraudulent identity document. this brand-new experience was \nextremely exciting which motivated me to even put in 100% of my effort into this amazing work. \nrewarding experience \nit was particularly rewarding when i was given the chance to fully express my opinions, evaluation \nand analysis on the results obtained. it was even more satisfying when the proposal that i had \nsuggested to further improve on the current performance of the model had been approved and \napplauded by mike and sai.  \nchallenging experience \nit was quite challenging during the process when i had to create falsified documents with extremely \nhigh precision on various subclasses of nsw driver license. i managed to overcome the problem by \ncreating a clear and well-defined document falsification pipeline which i could apply for all \n28 \n \nsubclasses of documents. mike and sai were pretty satisfied with the pipeline that i had created and \nwanted me to document out the entire falsification process to be set as a standardised and agreed \nsteps which could be used by other team members. \nupcoming task  \nin the next upcoming week, i would be expected to retrain the model by increasing the number of \ntrain datasets and evaluate on its performance. \n \n9.8",
            "page": null,
            "goal": "week 7 \ngoals, activities, outcomes \ngoals: by the end of this week, my goal is to find out how well would the model perform on a larger \nnumber and also on different subclasses of nsw driver license documents.  \n \nactivities: the number of test data had been increased this time from a total of 78 to 798 nsw \ndriver license document. even though the number of test data had increased, we decided to \nmaintain the number of train data: 30 in total that were being fed into our model as per our \nprevious testing for the purpose of comparison. we wanted to investigate whether our previously \ntrained model which generated a high accuracy performance had been overfitted and whether it \ncould generalise well against a variety of datasets. the difficulty of the classification task had also \nbeen increased as we had introduced different subclasses of nsw driver license as our test data, \nnamely, full, heavy, learner and provisional driver license. the test data that were fed into the model \nis comprised of 399 authentic and also 399 fake documents in which i had replicated using the \noriginal documents.  \n \noutcomes: i had successfully reassessed the model using the increasing number and different \nsubclasses of nsw driver license this time. the accuracy performance of the model this time \ndropped from 97% to around 90%. hence, it is suspected that the model might be underfitted. \nnew knowledge, skills and experiences  \nknowledge: i had learnt about the different factors and considerations that i had to account for \nthroughout the entire data preparation and model fitting process such as the coordinates of face \nimage on the document and the contrast colour of the image background while creating falsified \ndocuments from different subclasses of nsw driver license which would create different level of \nfalsification documents. for instance, the substituted photo which has similar background colour \nwith the original background of the photo would be considered as a high-level type of falsification. \n \nskills: i had developed strong analytical skills when evaluating and comparing the result obtained \nfrom the previous and current test. this was when i was required to utilise my critical thinking and \nproblem-solving skills by identifying the reason behind the drop in the accuracy performance and \ncome out with the next steps and approaches to tackle the problems. \n \nexperience: this was my first time dealing with real-life data: original nsw driver license and solving \nreal-life problem in combating fraudulent identity document. this brand-new experience was \nextremely exciting which motivated me to even put in 100% of my effort into this amazing work. \nrewarding experience \nit was particularly rewarding when i was given the chance to fully express my opinions, evaluation \nand analysis on the results obtained. it was even more satisfying when the proposal that i had \nsuggested to further improve on the current performance of the model had been approved and \napplauded by mike and sai.  \nchallenging experience \nit was quite challenging during the process when i had to create falsified documents with extremely \nhigh precision on various subclasses of nsw driver license. i managed to overcome the problem by \ncreating a clear and well-defined document falsification pipeline which i could apply for all \n28 \n \nsubclasses of documents. mike and sai were pretty satisfied with the pipeline that i had created and \nwanted me to document out the entire falsification process to be set as a standardised and agreed \nsteps which could be used by other team members. \nupcoming task  \nin the next upcoming week, i would be expected to retrain the model by increasing the number of \ntrain datasets and evaluate on its performance. \n \n9.8",
            "children": []
        },
        {
            "id": "1.15",
            "name": "week 8",
            "nodeType": "title",
            "text": "week 8",
            "page": null,
            "goal": "week 8",
            "children": []
        },
        {
            "id": "1.16",
            "name": "week 8 goals,",
            "nodeType": "paragraph",
            "text": "week 8 \ngoals, activities, outcomes \ngoals: by the end of this week, my goal is to retrain the model with increase number of train dataset \nand to wrap up the testing that i have done on nsw documents to proceed on with the documents \nfrom other states.  \n \nactivities: this time i had retrained the model with around 323 of authentic documents and tested it \non 100 real and fake nsw driver license documents respectively. i had also volunteered to work on \nwith the internship throughout the two weeks of my mid-semester break with the hope that i would \nbe able to make more progress on my work and to contribute more findings on the result obtained \nfrom my testing. before wrapping up on the work done on nsw documents, i had also tidied up my \ncodes and completed all the required documentations. \n \noutcomes: i had successfully created a strong model in identifying falsified documents after \nretraining the cs-flow model with our own documents. the model managed to generate an \nextremely high accuracy performance – 100% in detecting fraudulent nsw driver license and hence, \nwe had all agreed to wrap up the work done on nsw document and proceed on with other states \ndocuments. \nnew knowledge, skills and experiences  \nknowledge: i had utilised the two-weeks break to do some research and study on different type of \nevaluation methods in a binary classification problem so that i could apply it in evaluating and \nanalysing the result obtained from the identification of anomalous nsw driver license.  \n \nskills: i had developed a good time management skill whereby i had a good allocation of my time in \ncatching up with my study load, working on with the internship and also some leisure time for \nmyself when i had decided to work during my mid-semester break. \n \nexperience: i had a full sense of satisfaction after making lots of progress on the model testing while \nspending more time to continue working on the internship during my break. also, i felt that my time \nwas totally well-spent as not only had i contributed some amazing results to the company, i had also \ngained lots of knowledge and experience.  \nrewarding experience \nit was particularly rewarding when i managed to produce an accuracy performance of 100% after \nretraining and fine-tuning the model multiple times. i had also received recognition and affirmation \nfrom both mike and sai on the work i had done for producing such a high accuracy model for the \nnsw documents. \n29 \n \nchallenging experience \nit was quite challenging during the process of fine-tuning the model to obtain the best result as \nthere were a lot of parameters involved. however, i managed to overcome this by consulting sai and \ndoing some in-depth research on different types of threshold selection and evaluation methods. \nupcoming task  \nin the next upcoming week, i would be expected to work on the victoria documents by carrying out \nthe same set of procedures that i had done on nsw documents. \n \n9.9",
            "page": null,
            "goal": "week 8 \ngoals, activities, outcomes \ngoals: by the end of this week, my goal is to retrain the model with increase number of train dataset \nand to wrap up the testing that i have done on nsw documents to proceed on with the documents \nfrom other states.  \n \nactivities: this time i had retrained the model with around 323 of authentic documents and tested it \non 100 real and fake nsw driver license documents respectively. i had also volunteered to work on \nwith the internship throughout the two weeks of my mid-semester break with the hope that i would \nbe able to make more progress on my work and to contribute more findings on the result obtained \nfrom my testing. before wrapping up on the work done on nsw documents, i had also tidied up my \ncodes and completed all the required documentations. \n \noutcomes: i had successfully created a strong model in identifying falsified documents after \nretraining the cs-flow model with our own documents. the model managed to generate an \nextremely high accuracy performance – 100% in detecting fraudulent nsw driver license and hence, \nwe had all agreed to wrap up the work done on nsw document and proceed on with other states \ndocuments. \nnew knowledge, skills and experiences  \nknowledge: i had utilised the two-weeks break to do some research and study on different type of \nevaluation methods in a binary classification problem so that i could apply it in evaluating and \nanalysing the result obtained from the identification of anomalous nsw driver license.  \n \nskills: i had developed a good time management skill whereby i had a good allocation of my time in \ncatching up with my study load, working on with the internship and also some leisure time for \nmyself when i had decided to work during my mid-semester break. \n \nexperience: i had a full sense of satisfaction after making lots of progress on the model testing while \nspending more time to continue working on the internship during my break. also, i felt that my time \nwas totally well-spent as not only had i contributed some amazing results to the company, i had also \ngained lots of knowledge and experience.  \nrewarding experience \nit was particularly rewarding when i managed to produce an accuracy performance of 100% after \nretraining and fine-tuning the model multiple times. i had also received recognition and affirmation \nfrom both mike and sai on the work i had done for producing such a high accuracy model for the \nnsw documents. \n29 \n \nchallenging experience \nit was quite challenging during the process of fine-tuning the model to obtain the best result as \nthere were a lot of parameters involved. however, i managed to overcome this by consulting sai and \ndoing some in-depth research on different types of threshold selection and evaluation methods. \nupcoming task  \nin the next upcoming week, i would be expected to work on the victoria documents by carrying out \nthe same set of procedures that i had done on nsw documents. \n \n9.9",
            "children": []
        },
        {
            "id": "1.17",
            "name": "week 9",
            "nodeType": "title",
            "text": "week 9",
            "page": null,
            "goal": "week 9",
            "children": []
        },
        {
            "id": "1.18",
            "name": "week 9 goals,",
            "nodeType": "paragraph",
            "text": "week 9 \ngoals, activities, outcomes \ngoals: by the end of this week, my goal is to apply the same cs-flow model that i had used for the \nnsw documents testing to the victoria driver license documents and evaluate on the performance \nresult. \n \nactivities: i had created two models for the victoria documents. the first one was trained on 209 \nauthentic victoria driver license documents and tested on 100 authentic and fake documents \nrespectively. i then decided to create the second model whereby this time the model would be \ntrained by both nsw and victoria documents and tested on the victoria documents. with the \nassumption that an increase in the number of train datasets would lead to a better result, i expect \nmodel 2 would perform better than model 1. \n \noutcomes: i had successfully trained the model with the victoria driver license comprising of \ndifferent subclasses such as full, heavy, provisional and learner and performed an analysis on the \nresult obtained. there was a drop in the accuracy performance on victoria documents compared to \nnsw documents. my initial assumption had also been proven wrong as model 1 performed better \nthan model 2. \nnew knowledge, skills and experiences  \nknowledge: i had learnt from both mike and sai in making some assumptions on the model before \ncarrying out the testing in order to be able to set and define some conditions and parameters \nbeforehand.  \n \nskills: i had developed problem solving and analytical skills while doing some investigation on the \nvictoria documents after receiving a slightly low accuracy performance compared to the nsw \nmodel. \n \nexperience: it was quite a fun experience while investigating the factors that potentially contribute \nto the slightly low accuracy performance of the victoria model compared to nsw. sai and i worked \ntogether attempting to identify any unusual characteristics in the extracted images on victoria \ndocuments that were being fed into the model.  \nrewarding experience \nit was particularly rewarding while conducting an analysis and investigation behind the drop in the \nmodel accuracy performance. it made me realised that as a data scientist, our job is not only to \n30 \n \nproduce the results as requested but also to identify the factors behind the poor accuracy \nperformance and to propose solutions to make further refinements on the model. \nchallenging experience \nit was quite challenging and a bit disappointing when i was not able to produce an accuracy result as \nhigh as 100% this time as what i had obtained for the nsw documents. hence, i had proposed a \ndifferent method in identifying the best threshold that would be able to create a balance between \nfalse negative and false positive error. by using the new method, i managed to increase the accuracy \nresult to an acceptable level which is around 95%. \nupcoming task  \nin the next upcoming week, i would be expected to further extend the model on documents from \nqueensland by applying the same set of procedures that i had done earlier on. \n \n9.10",
            "page": null,
            "goal": "week 9 \ngoals, activities, outcomes \ngoals: by the end of this week, my goal is to apply the same cs-flow model that i had used for the \nnsw documents testing to the victoria driver license documents and evaluate on the performance \nresult. \n \nactivities: i had created two models for the victoria documents. the first one was trained on 209 \nauthentic victoria driver license documents and tested on 100 authentic and fake documents \nrespectively. i then decided to create the second model whereby this time the model would be \ntrained by both nsw and victoria documents and tested on the victoria documents. with the \nassumption that an increase in the number of train datasets would lead to a better result, i expect \nmodel 2 would perform better than model 1. \n \noutcomes: i had successfully trained the model with the victoria driver license comprising of \ndifferent subclasses such as full, heavy, provisional and learner and performed an analysis on the \nresult obtained. there was a drop in the accuracy performance on victoria documents compared to \nnsw documents. my initial assumption had also been proven wrong as model 1 performed better \nthan model 2. \nnew knowledge, skills and experiences  \nknowledge: i had learnt from both mike and sai in making some assumptions on the model before \ncarrying out the testing in order to be able to set and define some conditions and parameters \nbeforehand.  \n \nskills: i had developed problem solving and analytical skills while doing some investigation on the \nvictoria documents after receiving a slightly low accuracy performance compared to the nsw \nmodel. \n \nexperience: it was quite a fun experience while investigating the factors that potentially contribute \nto the slightly low accuracy performance of the victoria model compared to nsw. sai and i worked \ntogether attempting to identify any unusual characteristics in the extracted images on victoria \ndocuments that were being fed into the model.  \nrewarding experience \nit was particularly rewarding while conducting an analysis and investigation behind the drop in the \nmodel accuracy performance. it made me realised that as a data scientist, our job is not only to \n30 \n \nproduce the results as requested but also to identify the factors behind the poor accuracy \nperformance and to propose solutions to make further refinements on the model. \nchallenging experience \nit was quite challenging and a bit disappointing when i was not able to produce an accuracy result as \nhigh as 100% this time as what i had obtained for the nsw documents. hence, i had proposed a \ndifferent method in identifying the best threshold that would be able to create a balance between \nfalse negative and false positive error. by using the new method, i managed to increase the accuracy \nresult to an acceptable level which is around 95%. \nupcoming task  \nin the next upcoming week, i would be expected to further extend the model on documents from \nqueensland by applying the same set of procedures that i had done earlier on. \n \n9.10",
            "children": []
        },
        {
            "id": "1.19",
            "name": "week 10",
            "nodeType": "title",
            "text": "week 10",
            "page": null,
            "goal": "week 10",
            "children": []
        },
        {
            "id": "1.20",
            "name": "week 10 goals,",
            "nodeType": "paragraph",
            "text": "week 10 \ngoals, activities, outcomes \ngoals: by the end of this week, my goal is to apply the same model and the same set of procedures \nthat had been conducted on the nsw and vic documents to qld driver license documents this time. \nalso, i am also expected to implement the newly introduced multiple thresholds evaluation on the \nmodel. \n \nactivities: as usual, i had divided the qld driver license documents in the proportion of 70/30 into \ntrain and test data. the qld driver license is comprised of three subclasses which are full driver \nlicense with the caption of drive safely and card number and also heavy driver license type. \nthe train and test data for each qld driver license subclasses are extracted in such a way that they \nwould fully represent the total sample population of our sample documents. i then proceeded on \nwith the data preparation process such as transformation, cropping, identification of coordinates, \nclassification of document subclasses, image falsification and lastly point of extraction before \ntraining the model with the prepared documents. after the model was trained, i then fed the test \ndata into the model and started to carry out with the classification and evaluation process. \n \noutcomes: i had successfully created and implemented the multiple thresholds evaluation method \nwhich had boosted up the accuracy performance of the qld model by folds. besides the factors on \nclassification condition, anomaly threshold value and number of point extraction, i had also \nintroduced another factor which is the confidence level which could be adjusted according to our \nclient’s requirement and standard. \nnew knowledge, skills and experiences  \nknowledge: i had learnt a new way of identifying the optimal threshold based on the pre-set \nconfidence level and in evaluating the model using multiple thresholds method which had \nsignificantly increased the accuracy performance of the model. \n \nskills: i had developed problem-solving and analytical skills while doing some investigation on the \ndocuments that had been wrongly classified. it was quite rewarding to get some valuable inputs and \ninsights after comparing the misclassified documents with others that had been correctly classified. \n \n31 \n \nexperience: it was quite an exciting experience as this was my first time having an interaction with \nother colleagues outside of my team when i had several consultations with them to learn about the \nmodels that they had been developing. i therefore grabbed this opportunity to learn more about \nwhat they were doing in other team and asked for the sharing of their experiences. \nrewarding experience \nit was particularly rewarding when i managed to increase the accuracy performance of the qld \nmodel after introducing the multiple thresholds evaluation method which would generate three \nlabels which are the real, fake and warning at the end of the classification. i also went beyond what \nwas requested by presenting and analysing the trade-offs we might face between the accuracy \nperformance and the number of documents being labelled as warning and hence was applauded by \nthe team. \nchallenging experience \nit was quite challenging to first come out with the multiple thresholds evaluation and implement it in \nthe qld model as there were a lot of factors and trade-offs which would need to be taken into \nconsideration. however, i managed to overcome the challenge by treating it as a learning \nopportunity and constantly improving my skills and knowledge by doing lots of research and \nreadings. when in doubt, i also reached out and consulted the people not only in my team but also \nother colleagues from other team as well. \nupcoming task  \nin the next upcoming week, i would be expected to extend the same logic and method and applying \nthe multiple thresholds evaluation on western australia driver license and make comparison to the \nresult. \n \n9.11",
            "page": null,
            "goal": "week 10 \ngoals, activities, outcomes \ngoals: by the end of this week, my goal is to apply the same model and the same set of procedures \nthat had been conducted on the nsw and vic documents to qld driver license documents this time. \nalso, i am also expected to implement the newly introduced multiple thresholds evaluation on the \nmodel. \n \nactivities: as usual, i had divided the qld driver license documents in the proportion of 70/30 into \ntrain and test data. the qld driver license is comprised of three subclasses which are full driver \nlicense with the caption of drive safely and card number and also heavy driver license type. \nthe train and test data for each qld driver license subclasses are extracted in such a way that they \nwould fully represent the total sample population of our sample documents. i then proceeded on \nwith the data preparation process such as transformation, cropping, identification of coordinates, \nclassification of document subclasses, image falsification and lastly point of extraction before \ntraining the model with the prepared documents. after the model was trained, i then fed the test \ndata into the model and started to carry out with the classification and evaluation process. \n \noutcomes: i had successfully created and implemented the multiple thresholds evaluation method \nwhich had boosted up the accuracy performance of the qld model by folds. besides the factors on \nclassification condition, anomaly threshold value and number of point extraction, i had also \nintroduced another factor which is the confidence level which could be adjusted according to our \nclient’s requirement and standard. \nnew knowledge, skills and experiences  \nknowledge: i had learnt a new way of identifying the optimal threshold based on the pre-set \nconfidence level and in evaluating the model using multiple thresholds method which had \nsignificantly increased the accuracy performance of the model. \n \nskills: i had developed problem-solving and analytical skills while doing some investigation on the \ndocuments that had been wrongly classified. it was quite rewarding to get some valuable inputs and \ninsights after comparing the misclassified documents with others that had been correctly classified. \n \n31 \n \nexperience: it was quite an exciting experience as this was my first time having an interaction with \nother colleagues outside of my team when i had several consultations with them to learn about the \nmodels that they had been developing. i therefore grabbed this opportunity to learn more about \nwhat they were doing in other team and asked for the sharing of their experiences. \nrewarding experience \nit was particularly rewarding when i managed to increase the accuracy performance of the qld \nmodel after introducing the multiple thresholds evaluation method which would generate three \nlabels which are the real, fake and warning at the end of the classification. i also went beyond what \nwas requested by presenting and analysing the trade-offs we might face between the accuracy \nperformance and the number of documents being labelled as warning and hence was applauded by \nthe team. \nchallenging experience \nit was quite challenging to first come out with the multiple thresholds evaluation and implement it in \nthe qld model as there were a lot of factors and trade-offs which would need to be taken into \nconsideration. however, i managed to overcome the challenge by treating it as a learning \nopportunity and constantly improving my skills and knowledge by doing lots of research and \nreadings. when in doubt, i also reached out and consulted the people not only in my team but also \nother colleagues from other team as well. \nupcoming task  \nin the next upcoming week, i would be expected to extend the same logic and method and applying \nthe multiple thresholds evaluation on western australia driver license and make comparison to the \nresult. \n \n9.11",
            "children": []
        },
        {
            "id": "1.21",
            "name": "week 11",
            "nodeType": "title",
            "text": "week 11",
            "page": null,
            "goal": "week 11",
            "children": []
        },
        {
            "id": "1.22",
            "name": "week 11 goals,",
            "nodeType": "paragraph",
            "text": "week 11 \ngoals, activities, outcomes \ngoals: by the end of this week, my aim is to finish the testing on western australia driver license \ndocuments by applying the same falsification, extraction and evaluation methods which were \napplied on the nsw, vic and qld documents. i have also set a target for this week to improve on \nautomating the entire testing procedures which i have been doing constantly while conducting the \ntest on different states.  \n \nactivities:  \ni had applied the same standardised processing on western australia (wa) driver license documents \nduring data preparation before training the anomaly detection model. the wa driver license is \ncomprised of two subclasses, namely the full driver license and heavy driver license. i then carried \nout evaluation on the result obtained using the multiple thresholds method by selecting the two \nbest thresholds that would give us the lowest false positive and false negative rate respectively.  \n \noutcomes: i had successfully created, trained and evaluated the wa model and made comparison \nwith the qld model. also, i had successfully created a standardised automated data pipeline which \ncould be applied across all types of documents from different states. \n \n32 \n \nnew knowledge, skills and experiences  \nknowledge: i had learnt to create a comprehensive and standardised data pipeline process which \nwould be able to automate the entire data preparation and pre-processing workflow while building \nan anomaly detection model in detecting falsified documents. this had also taught me on the \nimportance of creating a complete automated data pipeline. \n \nskills: i had specifically developed and strengthen my programming skills in python when i was \ncreating the standardised data pipeline which could be applied to all the documents regardless of \nthe states and subclasses. as a result, all the manual work had been replaced with automated \nworkflow and this had significantly increased the efficiency and productivity of my work. \n \nexperience: it was quite an exciting experience during the creation of the entire data pipeline \nprocess from scratch without any assistance and i had gained so much in doing so which significantly \nenhanced my skills in python programming while automating the entire process.  \nrewarding experience \nthe most rewarding experience i had gained in this week is when i managed to create and automate \nthe data pipeline process which then increased the efficiency and productivity of my work. initially, it \ntook me around one day to carry out data pre-processing and another day to train and evaluate on \nthe model. however, after creating the data pipeline, i managed to do all the above work mentioned \nwithin one day. as a result, i could spend more time in evaluating and improving the model. \nchallenging experience \nthis was my first time creating a standardised data pipeline to automate the entire data workflow \nwhich at first, sounded challenging and quite intimidating to me. however, i managed to overcome \nthe challenges by having a positive can-do mindset and also doing lots of research independently \nwhenever i had doubts and queries in mind. \nupcoming task  \nin the next upcoming week, i would be expected to carry out testing towards all the remaining states \nin one go since i have now created a data pipeline to automatically process all the documents \nwithout having the need for me to do all the manual work. \n \n9.12",
            "page": null,
            "goal": "week 11 \ngoals, activities, outcomes \ngoals: by the end of this week, my aim is to finish the testing on western australia driver license \ndocuments by applying the same falsification, extraction and evaluation methods which were \napplied on the nsw, vic and qld documents. i have also set a target for this week to improve on \nautomating the entire testing procedures which i have been doing constantly while conducting the \ntest on different states.  \n \nactivities:  \ni had applied the same standardised processing on western australia (wa) driver license documents \nduring data preparation before training the anomaly detection model. the wa driver license is \ncomprised of two subclasses, namely the full driver license and heavy driver license. i then carried \nout evaluation on the result obtained using the multiple thresholds method by selecting the two \nbest thresholds that would give us the lowest false positive and false negative rate respectively.  \n \noutcomes: i had successfully created, trained and evaluated the wa model and made comparison \nwith the qld model. also, i had successfully created a standardised automated data pipeline which \ncould be applied across all types of documents from different states. \n \n32 \n \nnew knowledge, skills and experiences  \nknowledge: i had learnt to create a comprehensive and standardised data pipeline process which \nwould be able to automate the entire data preparation and pre-processing workflow while building \nan anomaly detection model in detecting falsified documents. this had also taught me on the \nimportance of creating a complete automated data pipeline. \n \nskills: i had specifically developed and strengthen my programming skills in python when i was \ncreating the standardised data pipeline which could be applied to all the documents regardless of \nthe states and subclasses. as a result, all the manual work had been replaced with automated \nworkflow and this had significantly increased the efficiency and productivity of my work. \n \nexperience: it was quite an exciting experience during the creation of the entire data pipeline \nprocess from scratch without any assistance and i had gained so much in doing so which significantly \nenhanced my skills in python programming while automating the entire process.  \nrewarding experience \nthe most rewarding experience i had gained in this week is when i managed to create and automate \nthe data pipeline process which then increased the efficiency and productivity of my work. initially, it \ntook me around one day to carry out data pre-processing and another day to train and evaluate on \nthe model. however, after creating the data pipeline, i managed to do all the above work mentioned \nwithin one day. as a result, i could spend more time in evaluating and improving the model. \nchallenging experience \nthis was my first time creating a standardised data pipeline to automate the entire data workflow \nwhich at first, sounded challenging and quite intimidating to me. however, i managed to overcome \nthe challenges by having a positive can-do mindset and also doing lots of research independently \nwhenever i had doubts and queries in mind. \nupcoming task  \nin the next upcoming week, i would be expected to carry out testing towards all the remaining states \nin one go since i have now created a data pipeline to automatically process all the documents \nwithout having the need for me to do all the manual work. \n \n9.12",
            "children": []
        },
        {
            "id": "1.23",
            "name": "week 12",
            "nodeType": "title",
            "text": "week 12",
            "page": null,
            "goal": "week 12",
            "children": []
        },
        {
            "id": "1.24",
            "name": "week 12 goals,",
            "nodeType": "paragraph",
            "text": "week 12 \ngoals, activities, outcomes \ngoals: by the end of this week, my aim is to finish the testing on all the remaining documents which \ninclude several australian states such as south australia (sa), northern territory (nt), australian \ncapital territory (act) and tasmania (tas) plus documents from other countries such as new \nzealand, indonesia, philippines and united kingdom. since these are the last batch of the \ndocuments, i also aim to summarise all the models that i had created previously on other australian \nstates and make a side-by-side comparisons between the accuracy performance of those models. \n  \nactivities: i applied the data processing pipeline which i had fully developed previously on all of the \nremaining documents. however, due to the limited number of dataset samples for those \ndocuments, i then decided to combine all these documents into one dataset to be fed into the \nmodel as i would not want the small number of datasets to affect the performance of the model. \n33 \n \nthe multiple thresholds evaluation was then being applied to identify the two most ideal thresholds \nin generating the lowest fnr and fpr. i also presented a summary review on the performance of all \nthe models i had developed to my team. it was discovered that the nsw model was so far our best \nmodel.  \n \noutcomes: i had successfully created, trained and evaluated the model on all the documents for the \nremaining states and countries we had in hand. also, i then summarised the results and \nperformance of all the model i had developed and presented them back to mike and sai in order to \ngive them a higher overview of the accuracy performance on all the models i had built so far.   \nnew knowledge, skills and experiences  \nknowledge: i had come to my realisation on the importance of creating a systematic and automated \ndata workflow pipeline. all thanks to the pipeline that i had built, i could now spend more time in \nassessing and evaluating the result and the overall accuracy performance of the model. \n  \nskills: i had specifically developed my critical thinking skills when i did a summary review session by \ncomparing the performance of all the models i had built throughout the course of my internship. \nwhen it was discovered that nsw model was the best modal so far, i was able to do some in-depth \ninvestigation and comparison between nsw documents with the datasets from other regions. i then \ncame out with some hypothesis based on the inference drawn upon by my investigation. \n \nexperience: it was an exciting experience for me while comparing all the models i had built earlier on \nside by-side and based on that, drawing some new inferences, conclusions and generating some new \nhypothesis that could potentially be tested in the next step \nrewarding experience \nthe most rewarding experience i had gained in this week was when i managed to conduct testing on \nnine different document types and completed all the evaluation work on the model’s performance \njust within one day. this was a significant improvement and breakthrough for me as earlier on, it \ntook me one day to process the dataset that only came from one document type, and another day in \ntraining and evaluating the model. however, all thanks to the automation that i had constantly been \nimproving and also the data pipeline which i had built, i had managed to perform testing on multiple \ntype of documents and evaluate on the model’s accuracy performance just within one day. \nfurthermore, it was also extremely satisfying while presenting the summary overview of all the \nmodels i had created as it represented all the hard-work i had put in throughout my internship \ntenure. \nchallenging experience \nat first, it sounded extremely intimidating to complete the training on all the documents coming \nfrom nine different regions plus completing the evaluation on the model’s accuracy performance \njust within a day. this target was actually not requested by mike or sai but instead was being set by \nmyself as i wanted to challenge and prove to myself that the hours long of spending in automating \nthe workflow process and building a data pipeline would be totally worth it and it was the time for \nme to reap what i had sowed. indeed, i had proven myself right! \n \n \n34 \n \nupcoming task  \nin the next upcoming week, i would be invited to a session that would be discussing on the plan i \nhave in mind during the semester break and also the upcoming six months as the company would \nlike to offer me a part-time contract to continue on working with them. \n \n9.13 summary of weekly activities and achievements \nweek \nactivities \n1 \nfinalised and completed truuth’s onboarding process. \n2 \ncompleted training and being introduced to the tools, technologies and platforms used in \nthe company. \n3 \nbeing officially assigned to the document classification and authentication workstream. \nidentified a specific workstream – image superimposition test to work in. \n4 \nchose cs-flow which is an anomaly detection model to carry out image superimposition \ntest. \n5 \ncreated a pipeline in creating falsified documents. \n6 \ntested the model on nsw driver license documents. \n7 \nextended the model on increased number of nsw driver license documents with different \nsubclasses. \n8 \ncontinued fine-tuning the nsw model until reaching 100% accuracy \n9 \ntested the model on vic driver license documents and the combination of nsw and vic \ndocuments.  \n10 \ntested the model on qld driver license documents and introduced multiple thresholds \nevaluation. \n11 \ntested the model on wa driver license document and created an automated data \nprocessing pipeline. \n12 \ntested the model on the combination of sa, act, tas, nt, indonesia, philippines and uk \ndriver license documents. \n13 \ndiscussed on plans and future working opportunity with the company. \n \ntable 2: summary of 13-week activities and achievements",
            "page": null,
            "goal": "week 12 \ngoals, activities, outcomes \ngoals: by the end of this week, my aim is to finish the testing on all the remaining documents which \ninclude several australian states such as south australia (sa), northern territory (nt), australian \ncapital territory (act) and tasmania (tas) plus documents from other countries such as new \nzealand, indonesia, philippines and united kingdom. since these are the last batch of the \ndocuments, i also aim to summarise all the models that i had created previously on other australian \nstates and make a side-by-side comparisons between the accuracy performance of those models. \n  \nactivities: i applied the data processing pipeline which i had fully developed previously on all of the \nremaining documents. however, due to the limited number of dataset samples for those \ndocuments, i then decided to combine all these documents into one dataset to be fed into the \nmodel as i would not want the small number of datasets to affect the performance of the model. \n33 \n \nthe multiple thresholds evaluation was then being applied to identify the two most ideal thresholds \nin generating the lowest fnr and fpr. i also presented a summary review on the performance of all \nthe models i had developed to my team. it was discovered that the nsw model was so far our best \nmodel.  \n \noutcomes: i had successfully created, trained and evaluated the model on all the documents for the \nremaining states and countries we had in hand. also, i then summarised the results and \nperformance of all the model i had developed and presented them back to mike and sai in order to \ngive them a higher overview of the accuracy performance on all the models i had built so far.   \nnew knowledge, skills and experiences  \nknowledge: i had come to my realisation on the importance of creating a systematic and automated \ndata workflow pipeline. all thanks to the pipeline that i had built, i could now spend more time in \nassessing and evaluating the result and the overall accuracy performance of the model. \n  \nskills: i had specifically developed my critical thinking skills when i did a summary review session by \ncomparing the performance of all the models i had built throughout the course of my internship. \nwhen it was discovered that nsw model was the best modal so far, i was able to do some in-depth \ninvestigation and comparison between nsw documents with the datasets from other regions. i then \ncame out with some hypothesis based on the inference drawn upon by my investigation. \n \nexperience: it was an exciting experience for me while comparing all the models i had built earlier on \nside by-side and based on that, drawing some new inferences, conclusions and generating some new \nhypothesis that could potentially be tested in the next step \nrewarding experience \nthe most rewarding experience i had gained in this week was when i managed to conduct testing on \nnine different document types and completed all the evaluation work on the model’s performance \njust within one day. this was a significant improvement and breakthrough for me as earlier on, it \ntook me one day to process the dataset that only came from one document type, and another day in \ntraining and evaluating the model. however, all thanks to the automation that i had constantly been \nimproving and also the data pipeline which i had built, i had managed to perform testing on multiple \ntype of documents and evaluate on the model’s accuracy performance just within one day. \nfurthermore, it was also extremely satisfying while presenting the summary overview of all the \nmodels i had created as it represented all the hard-work i had put in throughout my internship \ntenure. \nchallenging experience \nat first, it sounded extremely intimidating to complete the training on all the documents coming \nfrom nine different regions plus completing the evaluation on the model’s accuracy performance \njust within a day. this target was actually not requested by mike or sai but instead was being set by \nmyself as i wanted to challenge and prove to myself that the hours long of spending in automating \nthe workflow process and building a data pipeline would be totally worth it and it was the time for \nme to reap what i had sowed. indeed, i had proven myself right! \n \n \n34 \n \nupcoming task  \nin the next upcoming week, i would be invited to a session that would be discussing on the plan i \nhave in mind during the semester break and also the upcoming six months as the company would \nlike to offer me a part-time contract to continue on working with them. \n \n9.13 summary of weekly activities and achievements \nweek \nactivities \n1 \nfinalised and completed truuth’s onboarding process. \n2 \ncompleted training and being introduced to the tools, technologies and platforms used in \nthe company. \n3 \nbeing officially assigned to the document classification and authentication workstream. \nidentified a specific workstream – image superimposition test to work in. \n4 \nchose cs-flow which is an anomaly detection model to carry out image superimposition \ntest. \n5 \ncreated a pipeline in creating falsified documents. \n6 \ntested the model on nsw driver license documents. \n7 \nextended the model on increased number of nsw driver license documents with different \nsubclasses. \n8 \ncontinued fine-tuning the nsw model until reaching 100% accuracy \n9 \ntested the model on vic driver license documents and the combination of nsw and vic \ndocuments.  \n10 \ntested the model on qld driver license documents and introduced multiple thresholds \nevaluation. \n11 \ntested the model on wa driver license document and created an automated data \nprocessing pipeline. \n12 \ntested the model on the combination of sa, act, tas, nt, indonesia, philippines and uk \ndriver license documents. \n13 \ndiscussed on plans and future working opportunity with the company. \n \ntable 2: summary of 13-week activities and achievements",
            "children": []
        }
    ]
}